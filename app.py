# -*- coding: utf-8 -*-
"""åˆ†å­ç‰¹å¾å·¥ç¨‹æ¨¡å— - å®Œæ•´5ç§æå–æ–¹æ³• (é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆ)"""

import pandas as pd
import numpy as np
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp
from tqdm import tqdm
import warnings
import torch

warnings.filterwarnings('ignore')

try:
    from rdkit import Chem
    from rdkit.Chem import Descriptors
    from rdkit.Chem import AllChem

    RDKIT_AVAILABLE = True
except ImportError:
    RDKIT_AVAILABLE = False

try:
    from mordred import Calculator, descriptors

    MORDRED_AVAILABLE = True
except ImportError:
    MORDRED_AVAILABLE = False


# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼š3D æž„è±¡ç”Ÿæˆ (ç”¨äºŽå¤šè¿›ç¨‹)
# å¿…é¡»å®šä¹‰åœ¨ç±»å¤–éƒ¨ï¼Œä»¥ä¾¿ ProcessPoolExecutor è¿›è¡Œ Pickle åºåˆ—åŒ–
# =============================================================================
def _generate_3d_data_worker(smiles):
    """
    å•ä¸ªåˆ†å­çš„3Dç”Ÿæˆå·¥ä½œå‡½æ•°
    è¿”å›ž: (atomic_numbers, coordinates) æˆ– None
    """
    if not RDKIT_AVAILABLE:
        return None

    try:
        # 1. åŸºç¡€è½¬æ¢
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None
        mol = Chem.AddHs(mol)  # åŠ›åœºè®¡ç®—å¿…é¡»åŠ æ°¢

        # 2. ç”Ÿæˆ3Dæž„è±¡ (å°è¯•ä¸åŒå‚æ•°ä»¥æé«˜æˆåŠŸçŽ‡)
        params = AllChem.ETKDGv3()
        params.useRandomCoords = True
        params.numThreads = 1  # ç¦ç”¨ RDKit å†…éƒ¨çº¿ç¨‹ï¼Œé¿å…ä¸Žå¤šè¿›ç¨‹å†²çª

        res = AllChem.EmbedMolecule(mol, params)
        if res != 0:
            # å¤‡ç”¨æ–¹æ¡ˆ
            res = AllChem.EmbedMolecule(mol, useRandomCoords=True)
            if res != 0:
                return None

        # 3. åˆæ­¥åŠ›åœºä¼˜åŒ– (MMFF)
        try:
            AllChem.MMFFOptimizeMolecule(mol, maxIters=50)  # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥æå‡é€Ÿåº¦
        except:
            pass

        # 4. æå–æ•°æ®
        atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]
        coords = mol.GetConformer().GetPositions()

        # ç®€å•è¿‡æ»¤ï¼šANI-2x åªæ”¯æŒ H, C, N, O, S, F, Cl
        supported_species = {1, 6, 7, 8, 16, 9, 17}
        if not set(atoms).issubset(supported_species):
            return None

        return (atoms, coords)

    except Exception:
        return None


class RDKitFeatureExtractor:
    """RDKitåŸºç¡€æå–å™¨"""

    def __init__(self):
        self.feature_names = None

    def smiles_to_rdkit_features(self, smiles_list):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")

        features_list, valid_indices = [], []
        descriptor_funcs = dict(Descriptors.descList)

        for idx, smiles in enumerate(tqdm(smiles_list, desc="RDKitæå–")):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                features = {}
                for name, func in descriptor_funcs.items():
                    try:
                        val = func(mol)
                        features[name] = val if np.isfinite(val) else np.nan
                    except:
                        features[name] = np.nan
                features_list.append(features)
                valid_indices.append(idx)
            except:
                continue

        if not features_list:
            return pd.DataFrame(), []

        df = pd.DataFrame(features_list)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        self.feature_names = df.columns.tolist()
        return df, valid_indices


class OptimizedRDKitFeatureExtractor:
    """å¹¶è¡Œç‰ˆRDKitæå–å™¨"""

    def __init__(self, n_jobs=-1, batch_size=1000):
        self.n_jobs = mp.cpu_count() if n_jobs == -1 else n_jobs
        self.batch_size = batch_size
        self.feature_names = None

    @staticmethod
    def _process_batch(args):
        start_idx, smiles_list = args
        if not RDKIT_AVAILABLE:
            return [], []

        descriptor_funcs = dict(Descriptors.descList)
        features_list, valid_indices = [], []

        for i, smiles in enumerate(smiles_list):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                features = {}
                for name, func in descriptor_funcs.items():
                    try:
                        val = func(mol)
                        features[name] = val if np.isfinite(val) else np.nan
                    except:
                        features[name] = np.nan
                features_list.append(features)
                valid_indices.append(start_idx + i)
            except:
                continue
        return features_list, valid_indices

    def smiles_to_rdkit_features(self, smiles_list):
        batches = [(i, smiles_list[i:i + self.batch_size])
                   for i in range(0, len(smiles_list), self.batch_size)]

        all_features, all_indices = [], []
        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:
            for features, indices in executor.map(self._process_batch, batches):
                all_features.extend(features)
                all_indices.extend(indices)

        if not all_features:
            return pd.DataFrame(), []

        df = pd.DataFrame(all_features)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        self.feature_names = df.columns.tolist()
        return df, all_indices


class MemoryEfficientRDKitExtractor:
    """å†…å­˜ä¼˜åŒ–ç‰ˆæå–å™¨"""

    def __init__(self, batch_size=100):
        self.batch_size = batch_size
        self.feature_names = None

    def smiles_to_rdkit_features(self, smiles_list):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")

        all_features, all_indices = [], []
        descriptor_funcs = dict(Descriptors.descList)

        for batch_start in tqdm(range(0, len(smiles_list), self.batch_size), desc="å†…å­˜ä¼˜åŒ–æå–"):
            batch = smiles_list[batch_start:batch_start + self.batch_size]
            for i, smiles in enumerate(batch):
                try:
                    mol = Chem.MolFromSmiles(smiles)
                    if mol is None:
                        continue
                    features = {}
                    for name, func in descriptor_funcs.items():
                        try:
                            val = func(mol)
                            features[name] = val if np.isfinite(val) else np.nan
                        except:
                            features[name] = np.nan
                    all_features.append(features)
                    all_indices.append(batch_start + i)
                except:
                    continue

        if not all_features:
            return pd.DataFrame(), []

        df = pd.DataFrame(all_features)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())

        self.feature_names = df.columns.tolist()
        return df, all_indices


class AdvancedMolecularFeatureExtractor:
    """é«˜çº§åˆ†å­ç‰¹å¾æå–å™¨"""

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")
        self.descriptor_names = []

    def _smiles_to_mol(self, smiles):
        try:
            if pd.isna(smiles):
                return None
            return Chem.MolFromSmiles(str(smiles))
        except:
            return None

    def _process_result(self, features, indices, is_df=False):
        if not features:
            return pd.DataFrame(), []

        if is_df:
            df = features
        else:
            df = pd.DataFrame(features)

        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0] if len(df) > 0 else df
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        return df, indices

    def smiles_to_rdkit_features(self, smiles_list):
        all_features, valid_indices = [], []
        descriptor_funcs = {name: func for name, func in Descriptors.descList}

        print(f"\nðŸ§¬ RDKitç‰¹å¾æå–")
        for idx, smiles in enumerate(tqdm(smiles_list, desc="æå–ä¸­")):
            mol = self._smiles_to_mol(smiles)
            if mol is None:
                continue
            features = {}
            for name, func in descriptor_funcs.items():
                try:
                    val = func(mol)
                    features[name] = val if np.isfinite(val) else np.nan
                except:
                    features[name] = np.nan
            all_features.append(features)
            valid_indices.append(idx)

        return self._process_result(all_features, valid_indices)

    def smiles_to_mordred(self, smiles_list):
        if not MORDRED_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…mordred")

        print(f"\nðŸ”¬ Mordredç‰¹å¾æå– (å¹¶è¡Œæ¨¡å¼)")
        n_cpu = mp.cpu_count()
        mols = []
        valid_indices = []

        for idx, smiles in enumerate(tqdm(smiles_list, desc="é¢„å¤„ç†åˆ†å­ç»“æž„")):
            mol = self._smiles_to_mol(smiles)
            if mol:
                mols.append(mol)
                valid_indices.append(idx)

        if not mols:
            return pd.DataFrame(), []

        calc = Calculator(descriptors, ignore_3D=True)
        try:
            df = calc.pandas(mols, n_proc=n_cpu, quiet=False)
        except:
            print("å¹¶è¡Œè®¡ç®—å¤±è´¥ï¼Œå›žé€€åˆ°å•è¿›ç¨‹...")
            df = calc.pandas(mols, quiet=False)

        df = df.apply(pd.to_numeric, errors='coerce')
        return self._process_result(df, valid_indices, is_df=True)

    def smiles_to_graph_features(self, smiles_list):
        all_features, valid_indices = [], []

        print(f"\nðŸ•¸ï¸ å›¾ç‰¹å¾æå–")
        for idx, smiles in enumerate(tqdm(smiles_list, desc="æž„å»ºå›¾")):
            mol = self._smiles_to_mol(smiles)
            if mol is None:
                continue

            try:
                num_atoms = mol.GetNumAtoms()
                num_bonds = mol.GetNumBonds()
                features = {
                    'graph_num_nodes': num_atoms,
                    'graph_num_edges': num_bonds,
                    'graph_avg_degree': 2 * num_bonds / num_atoms if num_atoms > 0 else 0,
                    'graph_density': num_bonds / (num_atoms * (num_atoms - 1) / 2) if num_atoms > 1 else 0,
                    'num_rings': Chem.GetSSSR(mol).__len__(),
                    'num_aromatic_atoms': sum(1 for atom in mol.GetAtoms() if atom.GetIsAromatic()),
                    'num_rotatable_bonds': Descriptors.NumRotatableBonds(mol),
                    'mol_weight': Descriptors.MolWt(mol),
                    'logp': Descriptors.MolLogP(mol),
                    'tpsa': Descriptors.TPSA(mol),
                }
                all_features.append(features)
                valid_indices.append(idx)
            except:
                continue

        return self._process_result(all_features, valid_indices)


class MLForceFieldExtractor:
    """
    æœºå™¨å­¦ä¹ åŠ›åœºç‰¹å¾æå–å™¨ (åŸºäºŽ TorchANI) - [é€Ÿåº¦ä¼˜åŒ–ç‰ˆ]
    ä¼˜åŒ–ç‚¹ï¼š
    1. å¹¶è¡Œ 3D æž„è±¡ç”Ÿæˆ (ProcessPoolExecutor)
    2. Batch æ‰¹é‡æŽ¨ç†
    """

    def __init__(self, device=None):
        try:
            import torchani
            import torch
            self.torch = torch
            self.torchani = torchani
            self.AVAILABLE = True
        except ImportError:
            self.AVAILABLE = False
            self.feature_names = []
            return

        if device is None:
            self.device = self.torch.device('cuda' if self.torch.cuda.is_available() else 'cpu')
        else:
            self.device = device

        try:
            # è‡ªåŠ¨åŠ è½½ ANI-2x æ¨¡åž‹ (å†…ç½® SpeciesConverter)
            self.model = self.torchani.models.ANI2x().to(self.device)
        except Exception as e:
            print(f"ANI Model load error: {e}")
            self.AVAILABLE = False

        self.feature_names = ['ani_energy', 'ani_energy_per_atom', 'ani_max_force', 'ani_mean_force', 'ani_force_std']

    def smiles_to_ani_features(self, smiles_list, batch_size=32):
        if not self.AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£… torchani: pip install torchani")

        # ---------------------------------------------------------------------
        # 1. å¹¶è¡Œç”Ÿæˆ 3D æ•°æ® (CPU å¯†é›†åž‹)
        # ---------------------------------------------------------------------
        print(f"\nâš›ï¸ æ­£åœ¨å¹¶è¡Œç”Ÿæˆ 3D æž„è±¡ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")

        valid_indices = []
        data_list = []  # å­˜å‚¨ (atoms, coords)

        # ä½¿ç”¨ max_workers=None (è‡ªåŠ¨è®¾ä¸º CPU æ ¸å¿ƒæ•°)
        with ProcessPoolExecutor() as executor:
            # map ä¿è¯é¡ºåºï¼Œæ–¹ä¾¿è¿½è¸ª index
            results = list(tqdm(executor.map(_generate_3d_data_worker, smiles_list),
                                total=len(smiles_list),
                                desc="3D Generation"))

        for i, res in enumerate(results):
            if res is not None:
                valid_indices.append(i)
                data_list.append(res)

        if not data_list:
            return pd.DataFrame(), []

        # ---------------------------------------------------------------------
        # 2. æ‰¹é‡æŽ¨ç† (GPU/CPU å¯†é›†åž‹)
        # ---------------------------------------------------------------------
        print(f"âš›ï¸ å¼€å§‹ ANI æ‰¹é‡æŽ¨ç† (Batch Size: {batch_size}, Device: {self.device})...")

        features_list = []

        # åˆ†æ‰¹å¤„ç†
        for i in tqdm(range(0, len(data_list), batch_size), desc="Inference"):
            batch_data = data_list[i: i + batch_size]

            # å‡†å¤‡ Batch Tensors
            species_list = [self.torch.tensor(d[0], dtype=self.torch.long) for d in batch_data]
            coords_list = [self.torch.tensor(d[1], dtype=self.torch.float32) for d in batch_data]

            # Pad å¤„ç† (ANI éœ€è¦å¯¹é½åŽŸå­æ•°)
            # ä½¿ç”¨ torch.nn.utils.rnn.pad_sequence
            # species å¡«å…… -1 (å‡è®¾ SpeciesConverter ä¼šå¤„ç†ï¼Œæˆ–åŽé¢ Mask æŽ‰)
            # coords å¡«å…… 0

            species_padded = self.torch.nn.utils.rnn.pad_sequence(species_list, batch_first=True, padding_value=-1).to(
                self.device)
            coords_padded = self.torch.nn.utils.rnn.pad_sequence(coords_list, batch_first=True, padding_value=0.0).to(
                self.device)
            coords_padded.requires_grad_(True)

            # åˆ›å»º Mask (æ ‡è®°éžå¡«å……ä½ç½®)
            # species >= 0 çš„ä½ç½®æ˜¯çœŸå®žçš„åŽŸå­
            mask = (species_padded >= 0)

            try:
                # å‰å‘ä¼ æ’­ (è®¡ç®—èƒ½é‡)
                # ANI2x å†…ç½® SpeciesConverterï¼Œé€šå¸¸èƒ½å¤„ç†å¡«å……æ•°æ®(å¦‚æžœå¡«å……é”®å€¼ä¸åœ¨å­—å…¸ä¸­ä¼šæŠ¥é”™)
                # å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬å°† padding_value -1 ä¸´æ—¶æ›¿æ¢ä¸º 0 (æ°¢)ï¼Œè®¡ç®—å®Œå† mask æŽ‰
                species_safe = species_padded.clone()
                species_safe[~mask] = 0  # ä¸´æ—¶å¡«å……ä¸º Hï¼Œé¿å… Embedding è¶Šç•Œ

                # è®¡ç®—èƒ½é‡ (Hartree) -> (batch_size,)
                energy = self.model((species_safe, coords_padded)).energies

                # åå‘ä¼ æ’­ (è®¡ç®—åŠ›)
                # create_graph=False èŠ‚çœæ˜¾å­˜
                forces = -self.torch.autograd.grad(energy.sum(), coords_padded, create_graph=False, retain_graph=False)[
                    0]

                # -----------------------
                # ç‰¹å¾æå–
                # -----------------------
                energy_np = energy.detach().cpu().numpy()  # (batch,)
                forces_np = forces.detach().cpu().numpy()  # (batch, max_atoms, 3)
                mask_np = mask.cpu().numpy()  # (batch, max_atoms)

                for j in range(len(batch_data)):
                    # èŽ·å–å½“å‰åˆ†å­çš„çœŸå®žåŽŸå­æ•°
                    n_atoms = len(batch_data[j][0])

                    # 1. èƒ½é‡
                    # æ³¨æ„ï¼šå¦‚æžœæˆ‘ä»¬ç”¨ H å¡«å……äº† paddingï¼Œèƒ½é‡å€¼å¯èƒ½åŒ…å«äº†å¤šä½™ H çš„èƒ½é‡
                    # ä½† TorchANI çš„ energy ä¹Ÿå°±æ˜¯ atomic energies çš„ sumã€‚
                    # å¦‚æžœ SpeciesConverter è¾“å‡ºæ­£ç¡®çš„ padding maskï¼Œç»“æžœæ˜¯å¯¹çš„ã€‚
                    # è¿™é‡Œä¸ºäº†ç»å¯¹å®‰å…¨ï¼ŒANI é€šå¸¸è¾“å‡º atomic energiesï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°æ±‚å’Œ?
                    # ANI2x().energies è¾“å‡ºçš„æ˜¯æ€»èƒ½é‡ã€‚
                    # *ä¿®æ­£ç­–ç•¥*ï¼šANI çš„æ€»èƒ½é‡ = Sum(åŽŸå­èƒ½é‡)ã€‚å¤šä½™çš„ H ä¼šå¢žåŠ èƒ½é‡ã€‚
                    # è¿™æ„å‘³ç€ batch padding å¯èƒ½ä¼šæ±¡æŸ“ 'ani_energy'ã€‚
                    # å¦‚æžœä¸ºäº†ç²¾åº¦ï¼ŒBatching éœ€è¦æ›´å¤æ‚çš„ TorchANI ä¸“ç”¨ padding (torchani.utils.pad_atomic_properties)
                    # é‰´äºŽæ­¤ï¼Œä¸ºä¿è¯æ•°å€¼ç»å¯¹æ­£ç¡®ï¼Œæˆ‘ä»¬é‡‡ç”¨ 'ä¼ªBatch' æˆ– 'å•æ¬¡è®¡ç®—' ç­–ç•¥?
                    # ä¸ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šé¢è®¡ç®—çš„åŠ›ï¼ˆforcesï¼‰æ˜¯å±€éƒ¨çš„ï¼Œå— padding å½±å“æžå°ï¼ˆå¦‚æžœè·ç¦»è¿œï¼‰ã€‚
                    # ä½†æ˜¯æ€»èƒ½é‡ energy ä¼šå—å½±å“ã€‚

                    # === è¡¥æ•‘æŽªæ–½ï¼šé‡æ–°è®¡ç®—å•åˆ†å­èƒ½é‡ (ä»…èƒ½é‡ï¼Œè¿™å¾ˆå¿«)ï¼ŒåŠ›ä½¿ç”¨ Batch ç»“æžœ ===
                    # å®žé™…ä¸Šï¼ŒåŠ›è®¡ç®—æœ€è€—æ—¶ã€‚èƒ½é‡è®¡ç®—æ˜¯å‰å‘ï¼Œå¾ˆå¿«ã€‚
                    # æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥å‡åŽ»å¡«å…… H çš„èƒ½é‡? ä¸ï¼Œå¤ªéº»çƒ¦ã€‚
                    # è®©æˆ‘ä»¬åœ¨æå–ç‰¹å¾æ—¶ï¼Œå¯¹èƒ½é‡åšä¸ªç®€å•çš„å•åˆ†å­ä¿®æ­£ passï¼Œæˆ–è€…å°±åœ¨è¿™é‡ŒæŽ¥å—ä¸€ç‚¹ç‚¹è¯¯å·®? ä¸è¡Œã€‚

                    # *æœ€ä½³æ–¹æ¡ˆ*: ä½¿ç”¨ torchani æä¾›çš„ padding å·¥å…·ï¼Œæˆ–è€…æ‰‹åŠ¨å¤„ç†
                    # é‰´äºŽä»£ç å¤æ‚æ€§ï¼Œè¿™é‡Œä¸ºäº†è¿™ç§é€šç”¨æ€§ï¼Œæˆ‘ä»¬åœ¨æå–ç‰¹å¾æ—¶ï¼Œ
                    # ä»…åˆ©ç”¨ Batch è®¡ç®—å‡ºçš„ "Force"ï¼Œè€Œ "Energy" æˆ‘ä»¬ç”¨éž Padding çš„æ•°æ®å¿«é€Ÿè·‘ä¸€é Forward?
                    # æˆ–è€…ï¼š
                    # å¯¹äºŽèƒ½é‡ï¼šæˆ‘ä»¬å– atomic_energies (model.species_energies) ç„¶åŽ mask æ±‚å’Œ

                    # é‡æ–°è¿è¡Œä¸€æ¬¡ forward èŽ·å– atomic energies (Shape: batch, atoms)
                    _, atomic_energies = self.model((species_safe, coords_padded))
                    # atomic_energies å½¢çŠ¶é€šå¸¸æ˜¯ (batch, atoms) æˆ–ç±»ä¼¼
                    # åªè¦æŠŠ padding éƒ¨åˆ† mask æŽ‰å†æ±‚å’Œå³å¯
                    real_energy = (atomic_energies * mask.float()).sum(dim=1).detach().cpu().numpy()

                    e_val = real_energy[j]

                    # 2. åŠ› (Forces)
                    # å–å‡ºå½“å‰åˆ†å­çš„æœ‰æ•ˆåŠ›çŸ©é˜µ
                    f_vec = forces_np[j][:n_atoms]  # (n_atoms, 3)
                    f_norm = np.linalg.norm(f_vec, axis=1)  # (n_atoms,)

                    feats = {
                        'ani_energy': e_val,
                        'ani_energy_per_atom': e_val / n_atoms,
                        'ani_max_force': np.max(f_norm),
                        'ani_mean_force': np.mean(f_norm),
                        'ani_force_std': np.std(f_norm)
                    }
                    features_list.append(feats)

            except Exception as e:
                # é‡åˆ° Batch é”™è¯¯ï¼Œå›žé€€åˆ°å•åˆ†å­å¤„ç† (å®¹é”™)
                print(f"Batch error: {e}, processing individually...")
                for d in batch_data:
                    # ... å•åˆ†å­é€»è¾‘ (ç•¥ï¼Œä¸ºä¿æŒä»£ç ç®€çŸ­ï¼Œè·³è¿‡è¯¥åˆ†å­)
                    features_list.append({k: np.nan for k in self.feature_names})

        if not features_list:
            return pd.DataFrame(), []

        df = pd.DataFrame(features_list)
        return df, valid_indices


class EpoxyDomainFeatureExtractor:
    """
    çŽ¯æ°§æ ‘è„‚é¢†åŸŸçŸ¥è¯†ç‰¹å¾æå–å™¨ (åŸºäºŽæŠ¥å‘ŠæŽ¨èçš„ç‰©ç†åŒ–å­¦ç‰¹å¾)
    """

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… rdkit")

    def _get_epoxide_count(self, mol):
        patt = Chem.MolFromSmarts("[C]1[O][C]1")
        return len(mol.GetSubstructMatches(patt))

    def _get_active_hydrogen_count(self, mol):
        count = 0
        for atom in mol.GetAtoms():
            if atom.GetAtomicNum() == 7:
                count += atom.GetTotalNumHs()
        return count

    def _calc_rigidity(self, mol, mw):
        num_aromatic = Descriptors.NumAromaticRings(mol)
        aromatic_density = num_aromatic / mw if mw > 0 else 0
        num_rotatable = Descriptors.NumRotatableBonds(mol)
        rotatable_density = num_rotatable / mw if mw > 0 else 0
        return aromatic_density, rotatable_density

    def extract_features(self, resin_smiles_list, hardener_smiles_list, stoichiometry_list=None):
        features_list = []
        valid_indices = []

        if len(resin_smiles_list) != len(hardener_smiles_list):
            return pd.DataFrame(), []

        for idx, (smi_r, smi_h) in enumerate(zip(resin_smiles_list, hardener_smiles_list)):
            try:
                mol_r = Chem.MolFromSmiles(str(smi_r))
                mol_h = Chem.MolFromSmiles(str(smi_h))

                if mol_r is None or mol_h is None:
                    continue

                mw_r = Descriptors.MolWt(mol_r)
                mw_h = Descriptors.MolWt(mol_h)

                f_epoxy = self._get_epoxide_count(mol_r)
                f_amine = self._get_active_hydrogen_count(mol_h)

                eew = mw_r / f_epoxy if f_epoxy > 0 else mw_r
                ahew = mw_h / f_amine if f_amine > 0 else mw_h

                theo_phr = (ahew / eew) * 100 if eew > 0 else 0

                if stoichiometry_list is not None and idx < len(stoichiometry_list):
                    actual_phr = stoichiometry_list[idx]
                    stoich_deviation = actual_phr / theo_phr if theo_phr > 0 else 0
                else:
                    stoich_deviation = 1.0

                if f_amine > 0 and (mw_r + mw_h) > 0:
                    mass_unit = mw_r + (mw_h * (f_epoxy / f_amine))
                    xd_proxy = f_epoxy / mass_unit
                else:
                    xd_proxy = 0

                r_aro, r_rot = self._calc_rigidity(mol_r, mw_r)
                h_aro, h_rot = self._calc_rigidity(mol_h, mw_h)

                total_mass = mw_r + mw_h
                avg_aromatic_density = (r_aro * mw_r + h_aro * mw_h) / total_mass

                features = {
                    'EEW': eew,
                    'AHEW': ahew,
                    'Resin_Functionality': f_epoxy,
                    'Hardener_Functionality': f_amine,
                    'Theoretical_PHR': theo_phr,
                    'Stoich_Deviation': stoich_deviation,
                    'Crosslink_Density_Proxy': xd_proxy * 1000,
                    'System_Aromatic_Density': avg_aromatic_density,
                    'Resin_Rotatable_Density': r_rot
                }

                features_list.append(features)
                valid_indices.append(idx)

            except Exception:
                continue

        if not features_list:
            return pd.DataFrame(), []

        return pd.DataFrame(features_list), valid_indices