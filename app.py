# -*- coding: utf-8 -*-
<<<<<<< HEAD
"""
ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å° v1.2.0
(ä¸»åº”ç”¨ç¨‹åº - ä¿®å¤ç‰ˆ)
"""

# [å…³é”®ä¿®å¤] ç§»é™¤é¡¶å±‚å¯èƒ½å¯¼è‡´æ­»é”çš„å¯¼å…¥ï¼Œæ”¹ä¸ºå®‰å…¨æ£€æŸ¥
try:
    import torchani

    TORCHANI_AVAILABLE = True
except ImportError:
    TORCHANI_AVAILABLE = False

import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
# import torch  <-- [å®‰å…¨] ç§»é™¤é¡¶å±‚ torchï¼Œé˜²æ­¢ Windows å¤šè¿›ç¨‹æ­»é”
import traceback
import io
=======
"""åˆ†å­ç‰¹å¾å·¥ç¨‹æ¨¡å— - å®Œæ•´5ç§æå–æ–¹æ³• (é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆ)"""

import pandas as pd
import numpy as np
from concurrent.futures import ProcessPoolExecutor
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321
import multiprocessing as mp
from tqdm import tqdm
import warnings
<<<<<<< HEAD
import psutil
=======
import torch
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321

warnings.filterwarnings('ignore')

try:
<<<<<<< HEAD
    from core.molecular_features import OptimizedRDKitFeatureExtractor, MemoryEfficientRDKitExtractor

    OPTIMIZED_EXTRACTOR_AVAILABLE = True
=======
    from rdkit import Chem
    from rdkit.Chem import Descriptors
    from rdkit.Chem import AllChem

    RDKIT_AVAILABLE = True
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321
except ImportError:
    RDKIT_AVAILABLE = False

try:
<<<<<<< HEAD
    from core.ann_model import ANNRegressor

    ANN_AVAILABLE = True
except ImportError:
    ANN_AVAILABLE = False


@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨è¯»å–æ•°æ®æ–‡ä»¶...")
def load_data_file(uploaded_file):
    """å¸¦ç¼“å­˜çš„æ•°æ®åŠ è½½å‡½æ•°"""
    uploaded_file.seek(0)
    if uploaded_file.name.endswith('.csv'):
        return pd.read_csv(uploaded_file)
    else:
        return pd.read_excel(uploaded_file)


# --- è‡ªå®šä¹‰ CSS æ ·å¼ ---
CUSTOM_CSS = """
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 12px;
        padding: 20px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        margin: 8px 0;
    }
    .metric-value { font-size: 2.2rem; font-weight: 700; margin: 8px 0; }
    .metric-label { font-size: 0.9rem; opacity: 0.9; text-transform: uppercase; }
    .feature-badge {
        display: inline-block; background: #E0E7FF; color: #4338CA;
        padding: 4px 12px; border-radius: 16px; font-size: 0.85rem; margin: 2px;
    }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)


# ============================================================
# Session State åˆå§‹åŒ–
# ============================================================
def init_session_state():
    defaults = {
        'data': None, 'processed_data': None, 'molecular_features': None,
        'target_col': None, 'feature_cols': [],
        'model': None, 'model_name': None, 'train_result': None,
        'scaler': None, 'pipeline': None,
        'X_train': None, 'X_test': None, 'y_train': None, 'y_test': None,
        'optimization_history': [], 'best_params': None,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value
=======
    from mordred import Calculator, descriptors

    MORDRED_AVAILABLE = True
except ImportError:
    MORDRED_AVAILABLE = False


# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼š3D æ„è±¡ç”Ÿæˆ (ç”¨äºå¤šè¿›ç¨‹)
# å¿…é¡»å®šä¹‰åœ¨ç±»å¤–éƒ¨ï¼Œä»¥ä¾¿ ProcessPoolExecutor è¿›è¡Œ Pickle åºåˆ—åŒ–
# =============================================================================
def _generate_3d_data_worker(smiles):
    """
    å•ä¸ªåˆ†å­çš„3Dç”Ÿæˆå·¥ä½œå‡½æ•°
    è¿”å›: (atomic_numbers, coordinates) æˆ– None
    """
    if not RDKIT_AVAILABLE:
        return None

    try:
        # 1. åŸºç¡€è½¬æ¢
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None
        mol = Chem.AddHs(mol)  # åŠ›åœºè®¡ç®—å¿…é¡»åŠ æ°¢

        # 2. ç”Ÿæˆ3Dæ„è±¡ (å°è¯•ä¸åŒå‚æ•°ä»¥æé«˜æˆåŠŸç‡)
        params = AllChem.ETKDGv3()
        params.useRandomCoords = True
        params.numThreads = 1  # ç¦ç”¨ RDKit å†…éƒ¨çº¿ç¨‹ï¼Œé¿å…ä¸å¤šè¿›ç¨‹å†²çª

        res = AllChem.EmbedMolecule(mol, params)
        if res != 0:
            # å¤‡ç”¨æ–¹æ¡ˆ
            res = AllChem.EmbedMolecule(mol, useRandomCoords=True)
            if res != 0:
                return None

        # 3. åˆæ­¥åŠ›åœºä¼˜åŒ– (MMFF)
        try:
            AllChem.MMFFOptimizeMolecule(mol, maxIters=50)  # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥æå‡é€Ÿåº¦
        except:
            pass

        # 4. æå–æ•°æ®
        atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]
        coords = mol.GetConformer().GetPositions()

        # ç®€å•è¿‡æ»¤ï¼šANI-2x åªæ”¯æŒ H, C, N, O, S, F, Cl
        supported_species = {1, 6, 7, 8, 16, 9, 17}
        if not set(atoms).issubset(supported_species):
            return None

        return (atoms, coords)

    except Exception:
        return None


class RDKitFeatureExtractor:
    """RDKitåŸºç¡€æå–å™¨"""
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321

    def __init__(self):
        self.feature_names = None

    def smiles_to_rdkit_features(self, smiles_list):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")

        features_list, valid_indices = [], []
        descriptor_funcs = dict(Descriptors.descList)

<<<<<<< HEAD
# ============================================================
# ä¾§è¾¹æ æ¸²æŸ“
# ============================================================
def render_sidebar():
    with st.sidebar:
        st.title(f"ğŸ”¬ {APP_NAME}")
        st.caption(f"ç‰ˆæœ¬ {VERSION}")
        st.markdown("---")

        page = st.radio(
            "ğŸ“Œ åŠŸèƒ½å¯¼èˆª",
            ["ğŸ  é¦–é¡µ", "ğŸ“¤ æ•°æ®ä¸Šä¼ ", "ğŸ” æ•°æ®æ¢ç´¢", "ğŸ§¹ æ•°æ®æ¸…æ´—", "âœ¨ æ•°æ®å¢å¼º",
             "ğŸ§¬ åˆ†å­ç‰¹å¾", "ğŸ¯ ç‰¹å¾é€‰æ‹©", "ğŸ¤– æ¨¡å‹è®­ç»ƒ", "ğŸ“Š æ¨¡å‹è§£é‡Š",
             "ğŸ”® é¢„æµ‹åº”ç”¨", "âš™ï¸ è¶…å‚ä¼˜åŒ–"],
            label_visibility="collapsed"
        )

        st.markdown("---")
        st.markdown("### ğŸ“Š æ•°æ®çŠ¶æ€")

        current_df = st.session_state.get('processed_data')
        original_df = st.session_state.get('data')
        display_df = current_df if current_df is not None else original_df

        if display_df is not None:
            status_label = "âœ… å½“å‰æ•°æ® (å·²æ¸…æ´—)" if current_df is not None else "âœ… åŸå§‹æ•°æ®"
            st.success(f"{status_label}\n\n**{display_df.shape[0]} è¡Œ Ã— {display_df.shape[1]} åˆ—**")

            if st.session_state.get('molecular_features') is not None:
                st.info(f"ğŸ§¬ åˆ†å­ç‰¹å¾: {st.session_state.molecular_features.shape[1]} ä¸ª")

            if st.session_state.get('feature_cols'):
                st.info(f"ğŸ¯ å·²é€‰ç‰¹å¾: {len(st.session_state.feature_cols)} ä¸ª")
        else:
            st.warning("âš ï¸ æœªåŠ è½½æ•°æ®")

        if st.session_state.model is not None:
            st.success(f"ğŸ¤– å·²è®­ç»ƒ: {st.session_state.model_name}")

        return page


# ============================================================
# é¡µé¢åŠŸèƒ½å‡½æ•°
# ============================================================

def page_home():
    st.title("ğŸ”¬ ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å°")
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(
            '<div class="metric-card"><div class="metric-label">æ•°æ®å¤„ç†</div><div class="metric-value">ğŸ“Š</div></div>',
            unsafe_allow_html=True)
    with col2:
        st.markdown(
            '<div class="metric-card" style="background:linear-gradient(135deg, #11998e 0%, #38ef7d 100%)"><div class="metric-label">åˆ†å­ç‰¹å¾</div><div class="metric-value">ğŸ§¬</div></div>',
            unsafe_allow_html=True)
    with col3:
        st.markdown(
            '<div class="metric-card" style="background:linear-gradient(135deg, #f093fb 0%, #f5576c 100%)"><div class="metric-label">æ¨¡å‹è®­ç»ƒ</div><div class="metric-value">ğŸ¤–</div></div>',
            unsafe_allow_html=True)
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼è¯·ä»å·¦ä¾§å¯¼èˆªæ å¼€å§‹æ“ä½œã€‚")


def page_data_upload():
    st.title("ğŸ“¤ æ•°æ®ä¸Šä¼ ")
    tab1, tab2 = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç”Ÿæˆç¤ºä¾‹æ•°æ®"])

    with tab1:
        uploaded_file = st.file_uploader("é€‰æ‹©æ•°æ®æ–‡ä»¶ (CSV/Excel)", type=['csv', 'xlsx'])
        if uploaded_file:
            try:
                df = load_data_file(uploaded_file)
                # è‡ªåŠ¨å»é‡ååˆ—
                df = df.loc[:, ~df.columns.duplicated()]
                st.session_state.data = df
                st.session_state.processed_data = df.copy()
                st.success(f"âœ… åŠ è½½æˆåŠŸ: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
                st.dataframe(df.head())
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {e}")

    with tab2:
        if st.button("ç”Ÿæˆæ··åˆæ•°æ®é›†"):
            df = generate_hybrid_dataset()
            st.session_state.data = df
            st.session_state.processed_data = df.copy()
            st.success("âœ… å·²ç”Ÿæˆç¤ºä¾‹æ•°æ®")
            st.dataframe(df.head())


def page_data_explore():
    st.title("ğŸ” æ•°æ®æ¢ç´¢")
    if st.session_state.data is None: return st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®")

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    explorer = EnhancedDataExplorer(df)

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ç»Ÿè®¡", "ğŸ”— ç›¸å…³æ€§", "ğŸ“ˆ åˆ†å¸ƒ"])
    with tab1:
        st.dataframe(df.describe(), use_container_width=True)
    with tab2:
        fig = explorer.plot_correlation_matrix()
        if fig: st.plotly_chart(fig, use_container_width=True)
    with tab3:
        fig = explorer.plot_distributions()
        if fig: st.plotly_chart(fig, use_container_width=True)
=======
        for idx, smiles in enumerate(tqdm(smiles_list, desc="RDKitæå–")):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                features = {}
                for name, func in descriptor_funcs.items():
                    try:
                        val = func(mol)
                        features[name] = val if np.isfinite(val) else np.nan
                    except:
                        features[name] = np.nan
                features_list.append(features)
                valid_indices.append(idx)
            except:
                continue

        if not features_list:
            return pd.DataFrame(), []

        df = pd.DataFrame(features_list)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        self.feature_names = df.columns.tolist()
        return df, valid_indices


class OptimizedRDKitFeatureExtractor:
    """å¹¶è¡Œç‰ˆRDKitæå–å™¨"""
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321

    def __init__(self, n_jobs=-1, batch_size=1000):
        self.n_jobs = mp.cpu_count() if n_jobs == -1 else n_jobs
        self.batch_size = batch_size
        self.feature_names = None

<<<<<<< HEAD
def page_data_cleaning():
    st.title("ğŸ§¹ æ•°æ®æ¸…æ´—")
    if st.session_state.data is None: return st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®")

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    cleaner = AdvancedDataCleaner(df)

    tab1, tab2, tab3 = st.tabs(["â“ ç¼ºå¤±å€¼", "ğŸ“Š å¼‚å¸¸å€¼", "ğŸ”„ å»é‡ä¸ä¼˜åŒ–"])

    with tab1:
        st.markdown("### ç¼ºå¤±å€¼å¤„ç†")
        if df.isnull().sum().sum() > 0:
            strategy = st.selectbox("å¡«å……ç­–ç•¥", ["median", "mean", "knn", "drop_rows"])
            if st.button("æ‰§è¡Œå¡«å……"):
                st.session_state.processed_data = cleaner.handle_missing_values(strategy)
                st.success("âœ… å®Œæˆ")
                st.rerun()
        else:
            st.success("æ— ç¼ºå¤±å€¼")

    with tab3:
        st.markdown("### ğŸ”„ æ•°æ®å»é‡ä¸åˆ†å¸ƒä¼˜åŒ–")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### 1. è¡Œå»é‡")
            dup = df.duplicated().sum()
            st.metric("é‡å¤è¡Œ", dup)
            if dup > 0 and st.button("åˆ é™¤é‡å¤è¡Œ"):
                st.session_state.processed_data = cleaner.remove_duplicates()
                st.success("âœ… å·²å»é‡")
                st.rerun()

        with col2:
            st.markdown("#### 2. ç‰¹å¾åˆ†å¸ƒä¼˜åŒ–")
            st.caption("é™ä½æŸä¸€ç‰¹å¾ä¸­ä¼—æ•°çš„æ¯”ä¾‹")
            threshold = st.slider("é«˜é‡å¤ç‡æ£€æµ‹é˜ˆå€¼", 0.5, 0.99, 0.8)
            high_rep_cols = cleaner.detect_high_repetition_columns(threshold)

            if high_rep_cols:
                target_col = st.selectbox("é€‰æ‹©è¦ä¼˜åŒ–çš„ç‰¹å¾", list(high_rep_cols.keys()))
                target_rate = st.slider("ç›®æ ‡å æ¯”", 0.1, 0.8, 0.5)
                if st.button(f"ğŸ“‰ ä¼˜åŒ– '{target_col}'"):
                    st.session_state.processed_data = cleaner.reduce_feature_repetition(target_col, target_rate)
                    st.success("âœ… ä¼˜åŒ–å®Œæˆ")
                    st.rerun()
            else:
                st.success("æœªæ£€æµ‹åˆ°é«˜é‡å¤ç‡ç‰¹å¾")


def page_data_enhancement():
    st.title("âœ¨ æ•°æ®å¢å¼º")
    if st.session_state.data is None: return st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®")

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    enhancer = DataEnhancer(df)

    if st.button("æ‰§è¡Œ KNN æ™ºèƒ½å¡«å……", type="primary"):
        st.session_state.processed_data = enhancer.knn_impute()
        st.success("âœ… å¡«å……å®Œæˆ")


def page_molecular_features():
    st.title("ğŸ§¬ åˆ†å­ç‰¹å¾æå–")
    if st.session_state.data is None: return st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®")

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    text_cols = df.select_dtypes(include=['object']).columns.tolist()

    if not text_cols: return st.error("æœªæ£€æµ‹åˆ° SMILES åˆ—")

    smiles_col = st.selectbox("é€‰æ‹© SMILES åˆ—", text_cols)

    # [ä¿®å¤] é€—å·ä¿®å¤ï¼Œç¡®ä¿é€‰é¡¹ç‹¬ç«‹
    method_options = [
        "ğŸ”¹ RDKit æ ‡å‡†ç‰ˆ (æ¨èæ–°æ‰‹)",
        "ğŸš€ RDKit å¹¶è¡Œç‰ˆ (å¤§æ•°æ®é›†)",
        "ğŸ’¾ RDKit å†…å­˜ä¼˜åŒ–ç‰ˆ (ä½å†…å­˜)",
        "ğŸ”¬ Mordred æè¿°ç¬¦ (1600+ç‰¹å¾)",
        "ğŸ•¸ï¸ å›¾ç¥ç»ç½‘ç»œç‰¹å¾ (æ‹“æ‰‘ç»“æ„)",
        "âš›ï¸ MLåŠ›åœºç‰¹å¾ (ANIèƒ½é‡/åŠ›)",
        "âš—ï¸ ç¯æ°§æ ‘è„‚ååº”ç‰¹å¾ (åŸºäºé¢†åŸŸçŸ¥è¯†)"
    ]

    extraction_method = st.radio("é€‰æ‹©æå–æ–¹æ³•", method_options)

    # [æ–°å¢] ç¯æ°§æ ‘è„‚ä¸“ç”¨UI
    hardener_col = None
    phr_col = None
    if "ç¯æ°§æ ‘è„‚" in extraction_method:
        st.info("éœ€æä¾›æ ‘è„‚å’Œå›ºåŒ–å‰‚ç»“æ„ã€‚")
        col_h, col_p = st.columns(2)
        with col_h:
            hardener_col = st.selectbox("é€‰æ‹©ã€å›ºåŒ–å‰‚ã€‘åˆ—", [c for c in text_cols if c != smiles_col])
        with col_p:
            num_cols = df.select_dtypes(include=np.number).columns.tolist()
            phr_col = st.selectbox("é€‰æ‹©ã€PHR/é…æ¯”ã€‘åˆ— (å¯é€‰)", ["æ—  (é»˜è®¤1:1)"] + num_cols)

    if st.button("ğŸš€ å¼€å§‹æå–", type="primary"):
        smiles_list = df[smiles_col].tolist()
        status_text = st.empty()
        status_text.text("æ­£åœ¨æå–...")

        try:
            features_df = pd.DataFrame()
            valid_indices = []

            if "æ ‡å‡†ç‰ˆ" in extraction_method:
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)

            elif "å¹¶è¡Œç‰ˆ" in extraction_method:
                # è‡ªåŠ¨é™çº§å¤„ç†ï¼Œé˜²æ­¢ Windows æ­»é”
                if OPTIMIZED_EXTRACTOR_AVAILABLE:
                    extractor = OptimizedRDKitFeatureExtractor()
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                else:
                    st.warning("å¹¶è¡Œç‰ˆä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†ç‰ˆ")
                    extractor = AdvancedMolecularFeatureExtractor()
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)

            elif "å†…å­˜ä¼˜åŒ–" in extraction_method:
                extractor = MemoryEfficientRDKitExtractor()
                features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)

            elif "Mordred" in extraction_method:
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_mordred(smiles_list)

            elif "å›¾ç¥ç»ç½‘ç»œ" in extraction_method:
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_graph_features(smiles_list)

            elif "MLåŠ›åœº" in extraction_method:
                from core.molecular_features import MLForceFieldExtractor
                status_text.text("æ­£åœ¨è®¡ç®—ANIåŠ›åœºç‰¹å¾ (å•çº¿ç¨‹ç¨³å®šæ¨¡å¼)...")
                extractor = MLForceFieldExtractor()
                if not extractor.AVAILABLE:
                    st.error("TorchANI æœªå®‰è£…æˆ–åˆå§‹åŒ–å¤±è´¥")
                    return
                features_df, valid_indices = extractor.smiles_to_ani_features(smiles_list)

            elif "ç¯æ°§æ ‘è„‚" in extraction_method:
                from core.molecular_features import EpoxyDomainFeatureExtractor
                status_text.text("è®¡ç®— EEWã€äº¤è”å¯†åº¦ç­‰ç‰©ç†ç‰¹å¾...")

                if not hardener_col: return st.error("éœ€é€‰æ‹©å›ºåŒ–å‰‚åˆ—")

                r_list = df[smiles_col].tolist()
                h_list = df[hardener_col].tolist()
                p_list = df[phr_col].tolist() if phr_col != "æ—  (é»˜è®¤1:1)" else None

                extractor = EpoxyDomainFeatureExtractor()
                features_df, valid_indices = extractor.extract_features(r_list, h_list, p_list)

            if not features_df.empty:
                st.session_state.molecular_features = features_df
                # åˆå¹¶æ•°æ®
                features_df = features_df.add_prefix(f"{smiles_col}_")
                df_valid = df.iloc[valid_indices].reset_index(drop=True)
                features_df = features_df.reset_index(drop=True)

                # æ™ºèƒ½å»é‡åˆå¹¶
                cols_to_drop = [c for c in features_df.columns if c in df_valid.columns]
                if cols_to_drop: df_valid = df_valid.drop(columns=cols_to_drop)

                merged = pd.concat([df_valid, features_df], axis=1)
                st.session_state.processed_data = merged
                st.success(f"âœ… æå–æˆåŠŸ: {features_df.shape[1]} ä¸ªç‰¹å¾")
                st.dataframe(features_df.head())
            else:
                st.error("âŒ æå–å¤±è´¥æˆ–æ— æœ‰æ•ˆç»“æœ")

        except Exception as e:
            st.error(f"é”™è¯¯: {e}")
            st.code(traceback.format_exc())


def page_feature_selection():
    show_robust_feature_selection()


def page_model_training():
    st.title("ğŸ¤– æ¨¡å‹è®­ç»ƒ")
    if st.session_state.data is None: return st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®")
    if not st.session_state.feature_cols: return st.warning("è¯·å…ˆé€‰æ‹©ç‰¹å¾")

    df = st.session_state.processed_data
    X = df[st.session_state.feature_cols]
    y = df[st.session_state.target_col]

    col1, col2 = st.columns([1, 2])
    with col1:
        trainer = EnhancedModelTrainer()
        models = trainer.get_available_models()
        model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", models)
        test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.4, 0.2)

    if st.button("ğŸš€ è®­ç»ƒæ¨¡å‹", type="primary"):
        with st.spinner("è®­ç»ƒä¸­..."):
            try:
                # è·å–å‚æ•° (è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯æ¥æ‰‹åŠ¨è°ƒå‚é¢æ¿)
                params = MODEL_PARAMETERS.get(model_name, {})
                result = trainer.train_model(X, y, model_name, test_size=test_size, **params)

                st.session_state.model = result['model']
                st.session_state.model_name = model_name
                st.session_state.train_result = result
                st.session_state.X_train = result['X_train']

                st.success(f"âœ… è®­ç»ƒå®Œæˆ! RÂ²: {result['r2']:.4f}")

                # [å¯è§†åŒ–] ä¼˜å…ˆä½¿ç”¨ Parity Plot (Train vs Test)
                visualizer = Visualizer()
                if 'y_pred_train' in result:
                    st.markdown("### ğŸ“ˆ å®éªŒå€¼ vs é¢„æµ‹å€¼")
                    fig = visualizer.plot_parity_train_test(
                        result['y_train'], result['y_pred_train'],
                        result['y_test'], result['y_pred_test'],
                        target_name=st.session_state.target_col
                    )
                    st.pyplot(fig)
                else:
                    fig, _ = visualizer.plot_predictions_vs_true(result['y_test'], result['y_pred'], model_name)
                    st.pyplot(fig)

            except Exception as e:
                st.error(f"è®­ç»ƒå¤±è´¥: {e}")
                st.code(traceback.format_exc())


def page_model_interpretation():
    st.title("ğŸ“Š æ¨¡å‹è§£é‡Š")
    if st.session_state.model is None: return st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")

    model = st.session_state.model
    X_test = st.session_state.train_result['X_test']

    if st.button("è®¡ç®— SHAP å€¼"):
        try:
            explainer = shap.Explainer(model, X_test)
            shap_values = explainer(X_test)
            fig, ax = plt.subplots()
            shap.summary_plot(shap_values, X_test, show=False)
            st.pyplot(fig)
        except Exception as e:
            st.error(f"SHAP è®¡ç®—å¤±è´¥: {e}")


def page_prediction():
    st.title("ğŸ”® é¢„æµ‹åº”ç”¨")
    if st.session_state.model is None: return st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    st.info("åœ¨æ­¤ä¸Šä¼ æ–°æ•°æ®è¿›è¡Œé¢„æµ‹...")


def page_hyperparameter_optimization():
    st.title("âš™ï¸ è¶…å‚ä¼˜åŒ–")
    st.info("Optuna è‡ªåŠ¨è°ƒå‚æ¨¡å—...")


# ============================================================
# ä¸»å…¥å£
# ============================================================
def main():
    page = render_sidebar()
    if page == "ğŸ  é¦–é¡µ":
        page_home()
    elif page == "ğŸ“¤ æ•°æ®ä¸Šä¼ ":
        page_data_upload()
    elif page == "ğŸ” æ•°æ®æ¢ç´¢":
        page_data_explore()
    elif page == "ğŸ§¹ æ•°æ®æ¸…æ´—":
        page_data_cleaning()
    elif page == "âœ¨ æ•°æ®å¢å¼º":
        page_data_enhancement()
    elif page == "ğŸ§¬ åˆ†å­ç‰¹å¾":
        page_molecular_features()
    elif page == "ğŸ¯ ç‰¹å¾é€‰æ‹©":
        page_feature_selection()
    elif page == "ğŸ¤– æ¨¡å‹è®­ç»ƒ":
        page_model_training()
    elif page == "ğŸ“Š æ¨¡å‹è§£é‡Š":
        page_model_interpretation()
    elif page == "ğŸ”® é¢„æµ‹åº”ç”¨":
        page_prediction()
    elif page == "âš™ï¸ è¶…å‚ä¼˜åŒ–":
        page_hyperparameter_optimization()
=======
    @staticmethod
    def _process_batch(args):
        start_idx, smiles_list = args
        if not RDKIT_AVAILABLE:
            return [], []

        descriptor_funcs = dict(Descriptors.descList)
        features_list, valid_indices = [], []

        for i, smiles in enumerate(smiles_list):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                features = {}
                for name, func in descriptor_funcs.items():
                    try:
                        val = func(mol)
                        features[name] = val if np.isfinite(val) else np.nan
                    except:
                        features[name] = np.nan
                features_list.append(features)
                valid_indices.append(start_idx + i)
            except:
                continue
        return features_list, valid_indices

    def smiles_to_rdkit_features(self, smiles_list):
        batches = [(i, smiles_list[i:i + self.batch_size])
                   for i in range(0, len(smiles_list), self.batch_size)]

        all_features, all_indices = [], []
        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:
            for features, indices in executor.map(self._process_batch, batches):
                all_features.extend(features)
                all_indices.extend(indices)

        if not all_features:
            return pd.DataFrame(), []

        df = pd.DataFrame(all_features)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        self.feature_names = df.columns.tolist()
        return df, all_indices


class MemoryEfficientRDKitExtractor:
    """å†…å­˜ä¼˜åŒ–ç‰ˆæå–å™¨"""

    def __init__(self, batch_size=100):
        self.batch_size = batch_size
        self.feature_names = None

    def smiles_to_rdkit_features(self, smiles_list):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")

        all_features, all_indices = [], []
        descriptor_funcs = dict(Descriptors.descList)

        for batch_start in tqdm(range(0, len(smiles_list), self.batch_size), desc="å†…å­˜ä¼˜åŒ–æå–"):
            batch = smiles_list[batch_start:batch_start + self.batch_size]
            for i, smiles in enumerate(batch):
                try:
                    mol = Chem.MolFromSmiles(smiles)
                    if mol is None:
                        continue
                    features = {}
                    for name, func in descriptor_funcs.items():
                        try:
                            val = func(mol)
                            features[name] = val if np.isfinite(val) else np.nan
                        except:
                            features[name] = np.nan
                    all_features.append(features)
                    all_indices.append(batch_start + i)
                except:
                    continue

        if not all_features:
            return pd.DataFrame(), []

        df = pd.DataFrame(all_features)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())

        self.feature_names = df.columns.tolist()
        return df, all_indices


class AdvancedMolecularFeatureExtractor:
    """é«˜çº§åˆ†å­ç‰¹å¾æå–å™¨"""

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")
        self.descriptor_names = []

    def _smiles_to_mol(self, smiles):
        try:
            if pd.isna(smiles):
                return None
            return Chem.MolFromSmiles(str(smiles))
        except:
            return None

    def _process_result(self, features, indices, is_df=False):
        if not features:
            return pd.DataFrame(), []

        if is_df:
            df = features
        else:
            df = pd.DataFrame(features)

        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0] if len(df) > 0 else df
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        return df, indices

    def smiles_to_rdkit_features(self, smiles_list):
        all_features, valid_indices = [], []
        descriptor_funcs = {name: func for name, func in Descriptors.descList}

        print(f"\nğŸ§¬ RDKitç‰¹å¾æå–")
        for idx, smiles in enumerate(tqdm(smiles_list, desc="æå–ä¸­")):
            mol = self._smiles_to_mol(smiles)
            if mol is None:
                continue
            features = {}
            for name, func in descriptor_funcs.items():
                try:
                    val = func(mol)
                    features[name] = val if np.isfinite(val) else np.nan
                except:
                    features[name] = np.nan
            all_features.append(features)
            valid_indices.append(idx)

        return self._process_result(all_features, valid_indices)

    def smiles_to_mordred(self, smiles_list):
        if not MORDRED_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…mordred")

        print(f"\nğŸ”¬ Mordredç‰¹å¾æå– (å¹¶è¡Œæ¨¡å¼)")
        n_cpu = mp.cpu_count()
        mols = []
        valid_indices = []

        for idx, smiles in enumerate(tqdm(smiles_list, desc="é¢„å¤„ç†åˆ†å­ç»“æ„")):
            mol = self._smiles_to_mol(smiles)
            if mol:
                mols.append(mol)
                valid_indices.append(idx)

        if not mols:
            return pd.DataFrame(), []

        calc = Calculator(descriptors, ignore_3D=True)
        try:
            df = calc.pandas(mols, n_proc=n_cpu, quiet=False)
        except:
            print("å¹¶è¡Œè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°å•è¿›ç¨‹...")
            df = calc.pandas(mols, quiet=False)

        df = df.apply(pd.to_numeric, errors='coerce')
        return self._process_result(df, valid_indices, is_df=True)

    def smiles_to_graph_features(self, smiles_list):
        all_features, valid_indices = [], []

        print(f"\nğŸ•¸ï¸ å›¾ç‰¹å¾æå–")
        for idx, smiles in enumerate(tqdm(smiles_list, desc="æ„å»ºå›¾")):
            mol = self._smiles_to_mol(smiles)
            if mol is None:
                continue

            try:
                num_atoms = mol.GetNumAtoms()
                num_bonds = mol.GetNumBonds()
                features = {
                    'graph_num_nodes': num_atoms,
                    'graph_num_edges': num_bonds,
                    'graph_avg_degree': 2 * num_bonds / num_atoms if num_atoms > 0 else 0,
                    'graph_density': num_bonds / (num_atoms * (num_atoms - 1) / 2) if num_atoms > 1 else 0,
                    'num_rings': Chem.GetSSSR(mol).__len__(),
                    'num_aromatic_atoms': sum(1 for atom in mol.GetAtoms() if atom.GetIsAromatic()),
                    'num_rotatable_bonds': Descriptors.NumRotatableBonds(mol),
                    'mol_weight': Descriptors.MolWt(mol),
                    'logp': Descriptors.MolLogP(mol),
                    'tpsa': Descriptors.TPSA(mol),
                }
                all_features.append(features)
                valid_indices.append(idx)
            except:
                continue

        return self._process_result(all_features, valid_indices)


class MLForceFieldExtractor:
    """
    æœºå™¨å­¦ä¹ åŠ›åœºç‰¹å¾æå–å™¨ (åŸºäº TorchANI) - [é€Ÿåº¦ä¼˜åŒ–ç‰ˆ]
    ä¼˜åŒ–ç‚¹ï¼š
    1. å¹¶è¡Œ 3D æ„è±¡ç”Ÿæˆ (ProcessPoolExecutor)
    2. Batch æ‰¹é‡æ¨ç†
    """

    def __init__(self, device=None):
        try:
            import torchani
            import torch
            self.torch = torch
            self.torchani = torchani
            self.AVAILABLE = True
        except ImportError:
            self.AVAILABLE = False
            self.feature_names = []
            return

        if device is None:
            self.device = self.torch.device('cuda' if self.torch.cuda.is_available() else 'cpu')
        else:
            self.device = device

        try:
            # è‡ªåŠ¨åŠ è½½ ANI-2x æ¨¡å‹ (å†…ç½® SpeciesConverter)
            self.model = self.torchani.models.ANI2x().to(self.device)
        except Exception as e:
            print(f"ANI Model load error: {e}")
            self.AVAILABLE = False

        self.feature_names = ['ani_energy', 'ani_energy_per_atom', 'ani_max_force', 'ani_mean_force', 'ani_force_std']

    def smiles_to_ani_features(self, smiles_list, batch_size=32):
        if not self.AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£… torchani: pip install torchani")

        # ---------------------------------------------------------------------
        # 1. å¹¶è¡Œç”Ÿæˆ 3D æ•°æ® (CPU å¯†é›†å‹)
        # ---------------------------------------------------------------------
        print(f"\nâš›ï¸ æ­£åœ¨å¹¶è¡Œç”Ÿæˆ 3D æ„è±¡ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")

        valid_indices = []
        data_list = []  # å­˜å‚¨ (atoms, coords)

        # ä½¿ç”¨ max_workers=None (è‡ªåŠ¨è®¾ä¸º CPU æ ¸å¿ƒæ•°)
        with ProcessPoolExecutor() as executor:
            # map ä¿è¯é¡ºåºï¼Œæ–¹ä¾¿è¿½è¸ª index
            results = list(tqdm(executor.map(_generate_3d_data_worker, smiles_list),
                                total=len(smiles_list),
                                desc="3D Generation"))

        for i, res in enumerate(results):
            if res is not None:
                valid_indices.append(i)
                data_list.append(res)

        if not data_list:
            return pd.DataFrame(), []

        # ---------------------------------------------------------------------
        # 2. æ‰¹é‡æ¨ç† (GPU/CPU å¯†é›†å‹)
        # ---------------------------------------------------------------------
        print(f"âš›ï¸ å¼€å§‹ ANI æ‰¹é‡æ¨ç† (Batch Size: {batch_size}, Device: {self.device})...")

        features_list = []

        # åˆ†æ‰¹å¤„ç†
        for i in tqdm(range(0, len(data_list), batch_size), desc="Inference"):
            batch_data = data_list[i: i + batch_size]

            # å‡†å¤‡ Batch Tensors
            species_list = [self.torch.tensor(d[0], dtype=self.torch.long) for d in batch_data]
            coords_list = [self.torch.tensor(d[1], dtype=self.torch.float32) for d in batch_data]

            # Pad å¤„ç† (ANI éœ€è¦å¯¹é½åŸå­æ•°)
            # ä½¿ç”¨ torch.nn.utils.rnn.pad_sequence
            # species å¡«å…… -1 (å‡è®¾ SpeciesConverter ä¼šå¤„ç†ï¼Œæˆ–åé¢ Mask æ‰)
            # coords å¡«å…… 0

            species_padded = self.torch.nn.utils.rnn.pad_sequence(species_list, batch_first=True, padding_value=-1).to(
                self.device)
            coords_padded = self.torch.nn.utils.rnn.pad_sequence(coords_list, batch_first=True, padding_value=0.0).to(
                self.device)
            coords_padded.requires_grad_(True)

            # åˆ›å»º Mask (æ ‡è®°éå¡«å……ä½ç½®)
            # species >= 0 çš„ä½ç½®æ˜¯çœŸå®çš„åŸå­
            mask = (species_padded >= 0)

            try:
                # å‰å‘ä¼ æ’­ (è®¡ç®—èƒ½é‡)
                # ANI2x å†…ç½® SpeciesConverterï¼Œé€šå¸¸èƒ½å¤„ç†å¡«å……æ•°æ®(å¦‚æœå¡«å……é”®å€¼ä¸åœ¨å­—å…¸ä¸­ä¼šæŠ¥é”™)
                # å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬å°† padding_value -1 ä¸´æ—¶æ›¿æ¢ä¸º 0 (æ°¢)ï¼Œè®¡ç®—å®Œå† mask æ‰
                species_safe = species_padded.clone()
                species_safe[~mask] = 0  # ä¸´æ—¶å¡«å……ä¸º Hï¼Œé¿å… Embedding è¶Šç•Œ

                # è®¡ç®—èƒ½é‡ (Hartree) -> (batch_size,)
                energy = self.model((species_safe, coords_padded)).energies

                # åå‘ä¼ æ’­ (è®¡ç®—åŠ›)
                # create_graph=False èŠ‚çœæ˜¾å­˜
                forces = -self.torch.autograd.grad(energy.sum(), coords_padded, create_graph=False, retain_graph=False)[
                    0]

                # -----------------------
                # ç‰¹å¾æå–
                # -----------------------
                energy_np = energy.detach().cpu().numpy()  # (batch,)
                forces_np = forces.detach().cpu().numpy()  # (batch, max_atoms, 3)
                mask_np = mask.cpu().numpy()  # (batch, max_atoms)

                for j in range(len(batch_data)):
                    # è·å–å½“å‰åˆ†å­çš„çœŸå®åŸå­æ•°
                    n_atoms = len(batch_data[j][0])

                    # 1. èƒ½é‡
                    # æ³¨æ„ï¼šå¦‚æœæˆ‘ä»¬ç”¨ H å¡«å……äº† paddingï¼Œèƒ½é‡å€¼å¯èƒ½åŒ…å«äº†å¤šä½™ H çš„èƒ½é‡
                    # ä½† TorchANI çš„ energy ä¹Ÿå°±æ˜¯ atomic energies çš„ sumã€‚
                    # å¦‚æœ SpeciesConverter è¾“å‡ºæ­£ç¡®çš„ padding maskï¼Œç»“æœæ˜¯å¯¹çš„ã€‚
                    # è¿™é‡Œä¸ºäº†ç»å¯¹å®‰å…¨ï¼ŒANI é€šå¸¸è¾“å‡º atomic energiesï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°æ±‚å’Œ?
                    # ANI2x().energies è¾“å‡ºçš„æ˜¯æ€»èƒ½é‡ã€‚
                    # *ä¿®æ­£ç­–ç•¥*ï¼šANI çš„æ€»èƒ½é‡ = Sum(åŸå­èƒ½é‡)ã€‚å¤šä½™çš„ H ä¼šå¢åŠ èƒ½é‡ã€‚
                    # è¿™æ„å‘³ç€ batch padding å¯èƒ½ä¼šæ±¡æŸ“ 'ani_energy'ã€‚
                    # å¦‚æœä¸ºäº†ç²¾åº¦ï¼ŒBatching éœ€è¦æ›´å¤æ‚çš„ TorchANI ä¸“ç”¨ padding (torchani.utils.pad_atomic_properties)
                    # é‰´äºæ­¤ï¼Œä¸ºä¿è¯æ•°å€¼ç»å¯¹æ­£ç¡®ï¼Œæˆ‘ä»¬é‡‡ç”¨ 'ä¼ªBatch' æˆ– 'å•æ¬¡è®¡ç®—' ç­–ç•¥?
                    # ä¸ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šé¢è®¡ç®—çš„åŠ›ï¼ˆforcesï¼‰æ˜¯å±€éƒ¨çš„ï¼Œå— padding å½±å“æå°ï¼ˆå¦‚æœè·ç¦»è¿œï¼‰ã€‚
                    # ä½†æ˜¯æ€»èƒ½é‡ energy ä¼šå—å½±å“ã€‚

                    # === è¡¥æ•‘æªæ–½ï¼šé‡æ–°è®¡ç®—å•åˆ†å­èƒ½é‡ (ä»…èƒ½é‡ï¼Œè¿™å¾ˆå¿«)ï¼ŒåŠ›ä½¿ç”¨ Batch ç»“æœ ===
                    # å®é™…ä¸Šï¼ŒåŠ›è®¡ç®—æœ€è€—æ—¶ã€‚èƒ½é‡è®¡ç®—æ˜¯å‰å‘ï¼Œå¾ˆå¿«ã€‚
                    # æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥å‡å»å¡«å…… H çš„èƒ½é‡? ä¸ï¼Œå¤ªéº»çƒ¦ã€‚
                    # è®©æˆ‘ä»¬åœ¨æå–ç‰¹å¾æ—¶ï¼Œå¯¹èƒ½é‡åšä¸ªç®€å•çš„å•åˆ†å­ä¿®æ­£ passï¼Œæˆ–è€…å°±åœ¨è¿™é‡Œæ¥å—ä¸€ç‚¹ç‚¹è¯¯å·®? ä¸è¡Œã€‚

                    # *æœ€ä½³æ–¹æ¡ˆ*: ä½¿ç”¨ torchani æä¾›çš„ padding å·¥å…·ï¼Œæˆ–è€…æ‰‹åŠ¨å¤„ç†
                    # é‰´äºä»£ç å¤æ‚æ€§ï¼Œè¿™é‡Œä¸ºäº†è¿™ç§é€šç”¨æ€§ï¼Œæˆ‘ä»¬åœ¨æå–ç‰¹å¾æ—¶ï¼Œ
                    # ä»…åˆ©ç”¨ Batch è®¡ç®—å‡ºçš„ "Force"ï¼Œè€Œ "Energy" æˆ‘ä»¬ç”¨é Padding çš„æ•°æ®å¿«é€Ÿè·‘ä¸€é Forward?
                    # æˆ–è€…ï¼š
                    # å¯¹äºèƒ½é‡ï¼šæˆ‘ä»¬å– atomic_energies (model.species_energies) ç„¶å mask æ±‚å’Œ

                    # é‡æ–°è¿è¡Œä¸€æ¬¡ forward è·å– atomic energies (Shape: batch, atoms)
                    _, atomic_energies = self.model((species_safe, coords_padded))
                    # atomic_energies å½¢çŠ¶é€šå¸¸æ˜¯ (batch, atoms) æˆ–ç±»ä¼¼
                    # åªè¦æŠŠ padding éƒ¨åˆ† mask æ‰å†æ±‚å’Œå³å¯
                    real_energy = (atomic_energies * mask.float()).sum(dim=1).detach().cpu().numpy()

                    e_val = real_energy[j]

                    # 2. åŠ› (Forces)
                    # å–å‡ºå½“å‰åˆ†å­çš„æœ‰æ•ˆåŠ›çŸ©é˜µ
                    f_vec = forces_np[j][:n_atoms]  # (n_atoms, 3)
                    f_norm = np.linalg.norm(f_vec, axis=1)  # (n_atoms,)

                    feats = {
                        'ani_energy': e_val,
                        'ani_energy_per_atom': e_val / n_atoms,
                        'ani_max_force': np.max(f_norm),
                        'ani_mean_force': np.mean(f_norm),
                        'ani_force_std': np.std(f_norm)
                    }
                    features_list.append(feats)

            except Exception as e:
                # é‡åˆ° Batch é”™è¯¯ï¼Œå›é€€åˆ°å•åˆ†å­å¤„ç† (å®¹é”™)
                print(f"Batch error: {e}, processing individually...")
                for d in batch_data:
                    # ... å•åˆ†å­é€»è¾‘ (ç•¥ï¼Œä¸ºä¿æŒä»£ç ç®€çŸ­ï¼Œè·³è¿‡è¯¥åˆ†å­)
                    features_list.append({k: np.nan for k in self.feature_names})

        if not features_list:
            return pd.DataFrame(), []

        df = pd.DataFrame(features_list)
        return df, valid_indices


class EpoxyDomainFeatureExtractor:
    """
    ç¯æ°§æ ‘è„‚é¢†åŸŸçŸ¥è¯†ç‰¹å¾æå–å™¨ (åŸºäºæŠ¥å‘Šæ¨èçš„ç‰©ç†åŒ–å­¦ç‰¹å¾)
    """
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… rdkit")

<<<<<<< HEAD
if __name__ == "__main__":
    main()
=======
    def _get_epoxide_count(self, mol):
        patt = Chem.MolFromSmarts("[C]1[O][C]1")
        return len(mol.GetSubstructMatches(patt))

    def _get_active_hydrogen_count(self, mol):
        count = 0
        for atom in mol.GetAtoms():
            if atom.GetAtomicNum() == 7:
                count += atom.GetTotalNumHs()
        return count

    def _calc_rigidity(self, mol, mw):
        num_aromatic = Descriptors.NumAromaticRings(mol)
        aromatic_density = num_aromatic / mw if mw > 0 else 0
        num_rotatable = Descriptors.NumRotatableBonds(mol)
        rotatable_density = num_rotatable / mw if mw > 0 else 0
        return aromatic_density, rotatable_density

    def extract_features(self, resin_smiles_list, hardener_smiles_list, stoichiometry_list=None):
        features_list = []
        valid_indices = []

        if len(resin_smiles_list) != len(hardener_smiles_list):
            return pd.DataFrame(), []

        for idx, (smi_r, smi_h) in enumerate(zip(resin_smiles_list, hardener_smiles_list)):
            try:
                mol_r = Chem.MolFromSmiles(str(smi_r))
                mol_h = Chem.MolFromSmiles(str(smi_h))

                if mol_r is None or mol_h is None:
                    continue

                mw_r = Descriptors.MolWt(mol_r)
                mw_h = Descriptors.MolWt(mol_h)

                f_epoxy = self._get_epoxide_count(mol_r)
                f_amine = self._get_active_hydrogen_count(mol_h)

                eew = mw_r / f_epoxy if f_epoxy > 0 else mw_r
                ahew = mw_h / f_amine if f_amine > 0 else mw_h

                theo_phr = (ahew / eew) * 100 if eew > 0 else 0

                if stoichiometry_list is not None and idx < len(stoichiometry_list):
                    actual_phr = stoichiometry_list[idx]
                    stoich_deviation = actual_phr / theo_phr if theo_phr > 0 else 0
                else:
                    stoich_deviation = 1.0

                if f_amine > 0 and (mw_r + mw_h) > 0:
                    mass_unit = mw_r + (mw_h * (f_epoxy / f_amine))
                    xd_proxy = f_epoxy / mass_unit
                else:
                    xd_proxy = 0

                r_aro, r_rot = self._calc_rigidity(mol_r, mw_r)
                h_aro, h_rot = self._calc_rigidity(mol_h, mw_h)

                total_mass = mw_r + mw_h
                avg_aromatic_density = (r_aro * mw_r + h_aro * mw_h) / total_mass

                features = {
                    'EEW': eew,
                    'AHEW': ahew,
                    'Resin_Functionality': f_epoxy,
                    'Hardener_Functionality': f_amine,
                    'Theoretical_PHR': theo_phr,
                    'Stoich_Deviation': stoich_deviation,
                    'Crosslink_Density_Proxy': xd_proxy * 1000,
                    'System_Aromatic_Density': avg_aromatic_density,
                    'Resin_Rotatable_Density': r_rot
                }

                features_list.append(features)
                valid_indices.append(idx)

            except Exception:
                continue

        if not features_list:
            return pd.DataFrame(), []

        return pd.DataFrame(features_list), valid_indices
>>>>>>> 81ea74364be7cc033d76d6bb16b95c9823eaa321
