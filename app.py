# -*- coding: utf-8 -*-
"""
ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å° v1.2.8
æ›´æ–°å†…å®¹ï¼š
1. ä¿®å¤æ•°æ®æ¢ç´¢é¡µé¢ä¸æ˜¾ç¤ºæœ€æ–°ï¼ˆå¤„ç†åï¼‰æ•°æ®çš„é—®é¢˜
2. ä¿®å¤å¯¼å‡ºåŠŸèƒ½åªå¯¼å‡ºåŸå§‹æ•°æ®çš„é—®é¢˜
"""
try:
    import torchani

    TORCHANI_AVAILABLE = True
except ImportError:
    TORCHANI_AVAILABLE = False
import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import torch
import traceback
import json
import io
from datetime import datetime
import multiprocessing as mp
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core.data_processor import AdvancedDataCleaner, SparseDataHandler, DataEnhancer
from core.data_explorer import EnhancedDataExplorer
from core.model_trainer import EnhancedModelTrainer
from core.model_interpreter import ModelInterpreter, EnhancedModelInterpreter
from core.molecular_features import AdvancedMolecularFeatureExtractor, RDKitFeatureExtractor
from core.feature_selector import SmartFeatureSelector, SmartSparseDataSelector, show_robust_feature_selection
from core.optimizer import HyperparameterOptimizer, InverseDesigner, generate_tuning_suggestions
from core.visualizer import Visualizer
from core.applicability_domain import ApplicabilityDomainAnalyzer
from core.ui_config import (
    MANUAL_TUNING_PARAMS,
    MODEL_PARAMETERS,
    DEFAULT_OPTUNA_TRIALS,
    DEFAULT_TEST_SIZE,
    DEFAULT_RANDOM_STATE
)

from config import APP_NAME, VERSION, DATA_DIR
from generate_sample_data import generate_hybrid_dataset, generate_pure_numeric_dataset

# å¯é€‰æ¨¡å—å¯¼å…¥
try:
    from core.molecular_features import OptimizedRDKitFeatureExtractor, MemoryEfficientRDKitExtractor, \
        FingerprintExtractor

    OPTIMIZED_EXTRACTOR_AVAILABLE = True
except ImportError:
    OPTIMIZED_EXTRACTOR_AVAILABLE = False

try:
    from core.graph_utils import GNNFeaturizer, smiles_to_pyg_graph

    GNN_AVAILABLE = True
except ImportError:
    GNN_AVAILABLE = False

try:
    from core.ann_model import ANNRegressor

    ANN_AVAILABLE = True
except ImportError:
    ANN_AVAILABLE = False

try:
    import psutil

    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False


@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨è¯»å–æ•°æ®æ–‡ä»¶...")
def load_data_file(uploaded_file):
    """å¸¦ç¼“å­˜çš„æ•°æ®åŠ è½½å‡½æ•°ï¼Œé¿å…æ¯æ¬¡äº¤äº’éƒ½é‡æ–°è¯»å–æ–‡ä»¶"""
    # å¿…é¡»é‡ç½®æ–‡ä»¶æŒ‡é’ˆåˆ°å¼€å¤´ï¼Œå› ä¸ºStreamlitå¯èƒ½ä¼šå¤šæ¬¡è¯»å–åŒä¸€ä¸ªæ–‡ä»¶å¯¹è±¡
    uploaded_file.seek(0)

    if uploaded_file.name.endswith('.csv'):
        return pd.read_csv(uploaded_file)
    else:
        return pd.read_excel(uploaded_file)


# --- å…¨å±€å¸¸é‡ ---
USER_DATA_DB = "datasets/user_data.csv"

# --- è‡ªå®šä¹‰ CSS æ ·å¼ ---
CUSTOM_CSS = """
<style>
    :root {
        --primary-color: #4F46E5;
        --success-color: #10B981;
        --warning-color: #F59E0B;
        --error-color: #EF4444;
        --bg-card: #F8FAFC;
        --border-color: #E2E8F0;
    }

    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 12px;
        padding: 20px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        margin: 8px 0;
    }

    .metric-card-success {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
    }

    .metric-card-warning {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    }

    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        margin: 8px 0;
    }

    .metric-label {
        font-size: 0.9rem;
        opacity: 0.9;
        text-transform: uppercase;
        letter-spacing: 1px;
    }

    .result-panel {
        background: var(--bg-card);
        border: 1px solid var(--border-color);
        border-radius: 8px;
        padding: 16px;
        margin: 8px 0;
    }

    .feature-badge {
        display: inline-block;
        background: #E0E7FF;
        color: #4338CA;
        padding: 4px 12px;
        border-radius: 16px;
        font-size: 0.85rem;
        margin: 2px;
    }

    .status-success {
        color: var(--success-color);
        font-weight: 600;
    }

    .status-warning {
        color: var(--warning-color);
        font-weight: 600;
    }

    .status-error {
        color: var(--error-color);
        font-weight: 600;
    }
</style>
"""

st.markdown(CUSTOM_CSS, unsafe_allow_html=True)


# ============================================================
# Session State åˆå§‹åŒ–
# ============================================================
def init_session_state():
    """åˆå§‹åŒ–æ‰€æœ‰session stateå˜é‡"""
    defaults = {
        'data': None,
        'processed_data': None,
        'molecular_features': None,
        'target_col': None,
        'feature_cols': [],
        'model': None,
        'model_name': None,
        'train_result': None,
        'scaler': None,
        'pipeline': None,
        'X_train': None,
        'X_test': None,
        'y_train': None,
        'y_test': None,
        'optimization_history': [],
        'best_params': None,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


init_session_state()


# ============================================================
# ä¾§è¾¹æ æ¸²æŸ“
# ============================================================
def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ å¯¼èˆª"""
    with st.sidebar:
        st.title(f"ğŸ”¬ {APP_NAME}")
        st.caption(f"ç‰ˆæœ¬ {VERSION}")
        st.markdown("---")

        page = st.radio(
            "ğŸ“Œ åŠŸèƒ½å¯¼èˆª",
            [
                "ğŸ  é¦–é¡µ",
                "ğŸ“¤ æ•°æ®ä¸Šä¼ ",
                "ğŸ” æ•°æ®æ¢ç´¢",
                "ğŸ§¹ æ•°æ®æ¸…æ´—",
                "âœ¨ æ•°æ®å¢å¼º",
                "ğŸ§¬ åˆ†å­ç‰¹å¾",
                "ğŸ¯ ç‰¹å¾é€‰æ‹©",
                "ğŸ¤– æ¨¡å‹è®­ç»ƒ",
                "ğŸ“Š æ¨¡å‹è§£é‡Š",
                "ğŸ”® é¢„æµ‹åº”ç”¨",
                "âš™ï¸ è¶…å‚ä¼˜åŒ–",
            ],
            label_visibility="collapsed"
        )

        st.markdown("---")
        st.markdown("### ğŸ“Š æ•°æ®çŠ¶æ€")

        # ä¼˜å…ˆè·å– processed_data (æ¸…æ´—/å¤„ç†åçš„æ•°æ®)
        current_df = st.session_state.get('processed_data')
        original_df = st.session_state.get('data')

        # ç¡®å®šè¦æ˜¾ç¤ºå“ªä¸ªæ•°æ®çš„ä¿¡æ¯
        display_df = current_df if current_df is not None else original_df

        if display_df is not None:
            # 1. æ˜¾ç¤ºè¡Œ/åˆ—æ•°
            status_label = "âœ… å½“å‰æ•°æ® (å·²æ¸…æ´—)" if current_df is not None else "âœ… åŸå§‹æ•°æ®"
            st.success(f"{status_label}\n\n**{display_df.shape[0]} è¡Œ Ã— {display_df.shape[1]} åˆ—**")

            # 2. æ˜¾ç¤ºåˆ†å­ç‰¹å¾çŠ¶æ€
            if st.session_state.get('molecular_features') is not None:
                mf = st.session_state.molecular_features
                st.info(f"ğŸ§¬ åˆ†å­ç‰¹å¾: {mf.shape[1]} ä¸ª")

            # 3. æ˜¾ç¤ºç‰¹å¾é€‰æ‹©çŠ¶æ€
            feature_cols = st.session_state.get('feature_cols')
            target_col = st.session_state.get('target_col')

            if feature_cols:
                st.info(f"ğŸ¯ å·²é€‰ç‰¹å¾ (X): {len(feature_cols)} ä¸ª")

            if target_col:
                st.caption(f"ğŸ¯ ç›®æ ‡å˜é‡ (Y): {target_col}")

        else:
            st.warning("âš ï¸ æœªåŠ è½½æ•°æ®")

        if st.session_state.model is not None:
            st.success(f"ğŸ¤– å·²è®­ç»ƒ: {st.session_state.model_name}")
            # å¦‚æœæœ‰è®­ç»ƒç»“æœï¼Œä¹Ÿå¯ä»¥æ˜¾ç¤ºR2
            if st.session_state.get('train_result'):
                r2 = st.session_state.train_result.get('r2', 0)
                st.caption(f"å½“å‰ RÂ²: {r2:.4f}")

        st.markdown("---")
        st.markdown("### ğŸ”§ ç³»ç»Ÿä¿¡æ¯")
        st.caption(f"CPUæ ¸å¿ƒ: {mp.cpu_count()}")
        if PSUTIL_AVAILABLE:
            mem = psutil.virtual_memory()
            st.caption(f"å†…å­˜ä½¿ç”¨: {mem.percent}%")

        return page


# ============================================================
# é¡µé¢ï¼šé¦–é¡µ
# ============================================================
def page_home():
    """é¦–é¡µ"""
    st.title("ğŸ”¬ ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å°")
    st.markdown(f"**ç‰ˆæœ¬ {VERSION}** ")

    st.markdown("---")

    # åŠŸèƒ½å¡ç‰‡
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="metric-card">
            <div class="metric-label">æ•°æ®å¤„ç†</div>
            <div class="metric-value">ğŸ“Š</div>
            <p>æ™ºèƒ½æ¸…æ´— Â· VAEå¢å¼º Â· ç±»åˆ«å¹³è¡¡</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="metric-card metric-card-success">
            <div class="metric-label">åˆ†å­ç‰¹å¾</div>
            <div class="metric-value">ğŸ§¬</div>
            <p>RDKit Â· æŒ‡çº¹(MACCS) Â· å›¾ç‰¹å¾</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="metric-card metric-card-warning">
            <div class="metric-label">æ¨¡å‹è®­ç»ƒ</div>
            <div class="metric-value">ğŸ¤–</div>
            <p>15+æ¨¡å‹ Â· æ‰‹åŠ¨è°ƒå‚ Â· Optunaä¼˜åŒ–</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # æ ¸å¿ƒåŠŸèƒ½ä»‹ç»
    st.markdown("## ğŸš€ æ ¸å¿ƒåŠŸèƒ½")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        ### ğŸ“Š æ•°æ®å¤„ç†
        - **æ™ºèƒ½æ•°æ®æ¸…æ´—**: ç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼æ£€æµ‹ã€æ•°æ®ç±»å‹ä¿®å¤
        - **VAEæ•°æ®å¢å¼º**: åŸºäºå˜åˆ†è‡ªç¼–ç å™¨çš„è¡¨æ ¼æ•°æ®ç”Ÿæˆ
        - **ç±»åˆ«å¹³è¡¡**: **(æ–°)** è§£å†³åŒ–å­¦å•ä½“æ ·æœ¬ä¸å¹³è¡¡é—®é¢˜

        ### ğŸ§¬ åˆ†å­ç‰¹å¾æå–
        - **åˆ†å­æŒ‡çº¹**: **(æ–°)** MACCS Keys, Morgan (ECFP) æŒ‡çº¹
        - **RDKitæ ‡å‡†ç‰ˆ**: 200+åˆ†å­æè¿°ç¬¦
        - **å›¾ç¥ç»ç½‘ç»œç‰¹å¾**: åˆ†å­æ‹“æ‰‘ç»“æ„ç‰¹å¾
        - **MLåŠ›åœºç‰¹å¾**: ANI-2x é«˜ç²¾åº¦èƒ½é‡/åŠ›
        """)

    with col2:
        st.markdown("""
        ### ğŸ¤– æ¨¡å‹è®­ç»ƒ
        - **ä¼ ç»Ÿæ¨¡å‹**: çº¿æ€§å›å½’ã€SVRã€å†³ç­–æ ‘ç­‰
        - **é›†æˆæ¨¡å‹**: éšæœºæ£®æ—ã€XGBoostã€LightGBMã€CatBoost
        - **æ·±åº¦å­¦ä¹ **: è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ(ANN)
        - **AutoML**: TabPFNã€AutoGluon
        - **æ‰‹åŠ¨è°ƒå‚**: å¯è§†åŒ–å‚æ•°é…ç½®ç•Œé¢

        ### ğŸ“Š æ¨¡å‹è§£é‡Š
        - **SHAPåˆ†æ**: ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
        - **å­¦ä¹ æ›²çº¿**: æ¨¡å‹æ”¶æ•›åˆ†æ
        - **é€‚ç”¨åŸŸåˆ†æ**: PCAå‡¸åŒ…è¾¹ç•Œæ£€æµ‹
        """)

    st.markdown("---")

    # å¿«é€Ÿå¼€å§‹
    st.markdown("## âš¡ å¿«é€Ÿå¼€å§‹")
    st.info("""
    1. **ä¸Šä¼ æ•°æ®** â†’ æ”¯æŒCSVã€Excelæ ¼å¼
    2. **æ•°æ®æ¸…æ´—** â†’ ä½¿ç”¨â€œç±»åˆ«å¹³è¡¡â€å¤„ç†é«˜é¢‘å•ä½“
    3. **åˆ†å­ç‰¹å¾** â†’ æå–SMILESæŒ‡çº¹æˆ–æè¿°ç¬¦
    4. **ç‰¹å¾é€‰æ‹©** â†’ é€‰æ‹©ç›®æ ‡å˜é‡å’Œè¾“å…¥ç‰¹å¾
    5. **æ¨¡å‹è®­ç»ƒ** â†’ é€‰æ‹©æ¨¡å‹å¹¶è°ƒæ•´å‚æ•°
    6. **æ¨¡å‹è§£é‡Š** â†’ SHAPåˆ†æå’Œæ€§èƒ½è¯„ä¼°
    """)


# ============================================================
# é¡µé¢ï¼šæ•°æ®ä¸Šä¼ 
# ============================================================
def page_data_upload():
    """æ•°æ®ä¸Šä¼ é¡µé¢"""
    st.title("ğŸ“¤ æ•°æ®ä¸Šä¼ ")

    tab1, tab2 = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç”Ÿæˆç¤ºä¾‹æ•°æ®"])

    with tab1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            help="æ”¯æŒCSVå’ŒExcelæ ¼å¼"
        )

        if uploaded_file is not None:
            try:
                # ä½¿ç”¨ç¼“å­˜å‡½æ•°åŠ è½½æ•°æ®
                df = load_data_file(uploaded_file)

                # å»é‡ååˆ—
                if df.columns.duplicated().any():
                    st.warning("âš ï¸ æ£€æµ‹åˆ°é‡ååˆ—ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨é‡å‘½åå¤„ç†")
                    df = df.loc[:, ~df.columns.duplicated()]

                st.session_state.data = df
                st.session_state.processed_data = df.copy()

                st.success(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")

                # æ•°æ®é¢„è§ˆ
                st.markdown("### ğŸ“‹ æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head(10), use_container_width=True)

                # åˆ—ä¿¡æ¯
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("#### æ•°å€¼åˆ—")
                    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
                    for col in numeric_cols[:10]:
                        st.markdown(f"<span class='feature-badge'>{col}</span>", unsafe_allow_html=True)
                    if len(numeric_cols) > 10:
                        st.caption(f"... ç­‰å…± {len(numeric_cols)} ä¸ªæ•°å€¼åˆ—")

                with col2:
                    st.markdown("#### æ–‡æœ¬åˆ—")
                    text_cols = df.select_dtypes(include=['object']).columns.tolist()
                    for col in text_cols[:10]:
                        st.markdown(f"<span class='feature-badge'>{col}</span>", unsafe_allow_html=True)
                    if len(text_cols) > 10:
                        st.caption(f"... ç­‰å…± {len(text_cols)} ä¸ªæ–‡æœ¬åˆ—")

            except Exception as e:
                st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")

    with tab2:
        st.markdown("### ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ§ª æ··åˆæ•°æ®é›†")
            st.caption("åŒ…å«å·¥è‰ºå‚æ•°å’ŒSMILESåˆ†å­ç»“æ„")
            n_samples_hybrid = st.number_input("æ ·æœ¬æ•°é‡", 100, 2000, 500, key="n_hybrid")
            if st.button("ç”Ÿæˆæ··åˆæ•°æ®é›†", type="primary"):
                df = generate_hybrid_dataset(n_samples=n_samples_hybrid)
                st.session_state.data = df
                st.session_state.processed_data = df.copy()
                st.success(f"âœ… å·²ç”Ÿæˆæ··åˆæ•°æ®é›†: {df.shape}")
                st.dataframe(df.head(), use_container_width=True)

        with col2:
            st.markdown("#### ğŸ“Š çº¯æ•°å€¼æ•°æ®é›†")
            st.caption("ä»…åŒ…å«æ•°å€¼å‹å·¥è‰ºå‚æ•°")
            n_samples_numeric = st.number_input("æ ·æœ¬æ•°é‡", 100, 2000, 500, key="n_numeric")
            if st.button("ç”Ÿæˆçº¯æ•°å€¼æ•°æ®é›†", type="primary"):
                df = generate_pure_numeric_dataset(n_samples=n_samples_numeric)
                st.session_state.data = df
                st.session_state.processed_data = df.copy()
                st.success(f"âœ… å·²ç”Ÿæˆçº¯æ•°å€¼æ•°æ®é›†: {df.shape}")
                st.dataframe(df.head(), use_container_width=True)


# ============================================================
# é¡µé¢ï¼šæ•°æ®æ¢ç´¢ (ä¿®å¤ç‰ˆ)
# ============================================================
def page_data_explore():
    """æ•°æ®æ¢ç´¢é¡µé¢ - ä¿®å¤ç‰ˆ"""
    st.title("ğŸ” æ•°æ®æ¢ç´¢")

    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return

    # [å…³é”®ä¿®å¤] ä¼˜å…ˆä½¿ç”¨å¤„ç†åçš„æ•°æ®(processed_data)
    # è¿™æ ·æå–ç‰¹å¾ã€æ¸…æ´—åçš„æ•°æ®æ‰èƒ½æ˜¾ç¤ºå‡ºæ¥
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data

    explorer = EnhancedDataExplorer(df)

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š æè¿°ç»Ÿè®¡", "ğŸ”— ç›¸å…³æ€§åˆ†æ", "ğŸ“ˆ åˆ†å¸ƒå›¾", "â“ ç¼ºå¤±å€¼", "ğŸ’¾ å¯¼å‡º"
    ])

    with tab1:
        stats = explorer.generate_summary_stats()

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("æ€»è¡Œæ•°", stats['basic_info']['total_rows'])
        col2.metric("æ€»åˆ—æ•°", stats['basic_info']['total_columns'])
        col3.metric("æ•°å€¼åˆ—", stats['basic_info']['numeric_columns'])
        col4.metric("ç¼ºå¤±å€¼", stats['basic_info']['missing_values'])

        st.markdown("### æ•°å€¼ç‰¹å¾ç»Ÿè®¡")
        if explorer.numeric_cols:
            st.dataframe(df[explorer.numeric_cols].describe(), use_container_width=True)

    with tab2:
        st.markdown("### ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ")
        fig = explorer.plot_correlation_matrix()
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—")

        # é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
        pairs = explorer.get_high_correlation_pairs(threshold=0.8)
        if pairs:
            st.markdown("### âš ï¸ é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > 0.8)")
            for p in pairs[:10]:
                st.write(f"- **{p['feature1']}** â†” **{p['feature2']}**: {p['correlation']:.3f}")

    with tab3:
        st.markdown("### æ•°å€¼ç‰¹å¾åˆ†å¸ƒ")
        fig = explorer.plot_distributions()
        if fig:
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("### ç®±çº¿å›¾")
        fig_box = explorer.plot_boxplots()
        if fig_box:
            st.plotly_chart(fig_box, use_container_width=True)

    with tab4:
        st.markdown("### ç¼ºå¤±å€¼åˆ†æ")
        fig_missing = explorer.plot_missing_values()
        if fig_missing:
            st.plotly_chart(fig_missing, use_container_width=True)
        else:
            st.success("âœ… æ•°æ®æ— ç¼ºå¤±å€¼")

    with tab5:
        st.markdown("### å¯¼å‡ºæ•°æ® (æœ€æ–°)")
        col1, col2 = st.columns(2)

        with col1:
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "ğŸ“¥ ä¸‹è½½CSV",
                csv,
                "data_export.csv",
                "text/csv"
            )

        with col2:
            buffer = io.BytesIO()
            df.to_excel(buffer, index=False)
            st.download_button(
                "ğŸ“¥ ä¸‹è½½Excel",
                buffer.getvalue(),
                "data_export.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )


# ============================================================
# é¡µé¢ï¼šæ•°æ®æ¸…æ´—
# ============================================================
def page_data_cleaning():
    """æ•°æ®æ¸…æ´—é¡µé¢"""
    st.title("ğŸ§¹ æ•°æ®æ¸…æ´—")

    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    cleaner = AdvancedDataCleaner(df)

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "â“ ç¼ºå¤±å€¼å¤„ç†", "ğŸ“Š å¼‚å¸¸å€¼æ£€æµ‹", "ğŸ”„ é‡å¤æ•°æ®", "ğŸ”§ æ•°æ®ç±»å‹", "âš–ï¸ ç±»åˆ«å¹³è¡¡"
    ])

    with tab1:
        st.markdown("### ç¼ºå¤±å€¼å¤„ç†")

        # ç¼ºå¤±å€¼ç»Ÿè®¡
        missing = df.isnull().sum()
        missing = missing[missing > 0]

        if len(missing) > 0:
            st.warning(f"æ£€æµ‹åˆ° {len(missing)} åˆ—å­˜åœ¨ç¼ºå¤±å€¼")

            col1, col2 = st.columns(2)
            with col1:
                st.dataframe(pd.DataFrame({
                    'åˆ—å': missing.index,
                    'ç¼ºå¤±æ•°é‡': missing.values,
                    'ç¼ºå¤±æ¯”ä¾‹': (missing.values / len(df) * 100).round(2)
                }), use_container_width=True)

            with col2:
                strategy = st.selectbox(
                    "é€‰æ‹©å¡«å……ç­–ç•¥",
                    ["median", "mean", "mode", "knn", "drop_rows", "constant"]
                )

                fill_value = None
                if strategy == "constant":
                    fill_value = st.number_input("å¡«å……å¸¸æ•°å€¼", value=0.0)

                if st.button("ğŸ”§ æ‰§è¡Œç¼ºå¤±å€¼å¤„ç†", type="primary"):
                    cleaned_df = cleaner.handle_missing_values(strategy=strategy, fill_value=fill_value)
                    st.session_state.processed_data = cleaned_df
                    st.success("âœ… ç¼ºå¤±å€¼å¤„ç†å®Œæˆ")
                    st.rerun()
        else:
            st.success("âœ… æ•°æ®æ— ç¼ºå¤±å€¼")

    with tab2:
        st.markdown("### å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†")

        col1, col2 = st.columns(2)
        with col1:
            method = st.selectbox("æ£€æµ‹æ–¹æ³•", ["iqr", "zscore"])
            threshold = st.slider("é˜ˆå€¼", 1.0, 5.0, 1.5 if method == "iqr" else 3.0)

        with col2:
            handle_method = st.selectbox("å¤„ç†æ–¹æ³•", ["clip", "replace_median", "remove"])

        if st.button("ğŸ” æ£€æµ‹å¼‚å¸¸å€¼"):
            outliers = cleaner.detect_outliers(method=method, threshold=threshold)
            if outliers:
                st.warning(f"æ£€æµ‹åˆ° {len(outliers)} åˆ—å­˜åœ¨å¼‚å¸¸å€¼")
                st.json(outliers)
            else:
                st.success("âœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸å€¼")

        if st.button("ğŸ”§ å¤„ç†å¼‚å¸¸å€¼", type="primary"):
            cleaned_df = cleaner.handle_outliers(method=handle_method, threshold=threshold)
            st.session_state.processed_data = cleaned_df
            st.success("âœ… å¼‚å¸¸å€¼å¤„ç†å®Œæˆ")

    with tab3:
        st.markdown("### ğŸ”„ æ•°æ®å»é‡ä¸åˆ†å¸ƒä¼˜åŒ–")

        col_clean_1, col_clean_2 = st.columns(2)

        with col_clean_1:
            st.markdown("#### 1. è¡Œå»é‡")
            st.caption("åˆ é™¤å®Œå…¨é‡å¤çš„æ ·æœ¬è¡Œ")
            dup_count = df.duplicated().sum()
            st.metric("å®Œå…¨é‡å¤è¡Œæ•°", dup_count)

            if dup_count > 0:
                if st.button("ğŸ—‘ï¸ åˆ é™¤é‡å¤è¡Œ", type="primary"):
                    cleaned_df = cleaner.remove_duplicates()
                    st.session_state.processed_data = cleaned_df
                    st.success(f"âœ… å·²åˆ é™¤ {dup_count} è¡Œé‡å¤æ•°æ®")
                    st.rerun()
            else:
                st.info("âœ… æ— é‡å¤è¡Œ")

        st.markdown("---")

        with col_clean_2:
            st.markdown("#### 2. ç‰¹å¾åˆ†å¸ƒä¼˜åŒ– (é’ˆå¯¹æ•°å€¼)")
            st.caption("é™ä½æŸä¸€ç‰¹å¾ä¸­ä¼—æ•°ï¼ˆå‡ºç°æœ€å¤šçš„å€¼ï¼‰çš„æ¯”ä¾‹ï¼Œå¹³è¡¡æ•°æ®åˆ†å¸ƒ")

            # æ£€æµ‹é˜ˆå€¼è®¾ç½®
            rep_threshold = st.slider("é«˜é‡å¤ç‡æ£€æµ‹é˜ˆå€¼", 0.5, 0.99, 0.8, 0.05,
                                      help="æ£€æµ‹ä¼—æ•°å æ¯”è¶…è¿‡æ­¤æ¯”ä¾‹çš„ç‰¹å¾")

            high_rep_cols = cleaner.detect_high_repetition_columns(rep_threshold)

            if high_rep_cols:
                st.warning(f"âš ï¸ æ£€æµ‹åˆ° {len(high_rep_cols)} ä¸ªç‰¹å¾å­˜åœ¨é«˜é‡å¤å€¼")

                # æ˜¾ç¤ºè¯¦æƒ…
                rep_data = []
                for col, info in high_rep_cols.items():
                    rep_data.append({
                        "ç‰¹å¾": col,
                        "ä¼—æ•°": str(info['most_frequent_value']),
                        "å½“å‰å æ¯”": f"{info['frequency'] * 100:.1f}%"
                    })
                st.dataframe(pd.DataFrame(rep_data), use_container_width=True, hide_index=True)

                # æ“ä½œåŒº
                st.markdown("##### ğŸ”§ æ‰§è¡Œä¼˜åŒ–")
                target_col = st.selectbox("é€‰æ‹©è¦ä¼˜åŒ–çš„ç‰¹å¾", list(high_rep_cols.keys()))

                # æ™ºèƒ½è®¡ç®—æ»‘å—èŒƒå›´ï¼šä¸èƒ½æ¯”å½“å‰å æ¯”è¿˜é«˜ï¼Œä¹Ÿä¸èƒ½å¤ªä½ï¼ˆå¦‚0%ï¼‰
                current_freq = high_rep_cols[target_col]['frequency']
                target_rate = st.slider(
                    f"ç›®æ ‡å æ¯” (é’ˆå¯¹ {target_col})",
                    0.1, float(current_freq), 0.5, 0.05,
                    help="é€šè¿‡éšæœºåˆ é™¤åŒ…å«ä¼—æ•°çš„æ ·æœ¬ï¼Œä½¿å…¶å æ¯”é™ä½åˆ°æ­¤å€¼"
                )

                if st.button(f"ğŸ“‰ é™ä½ '{target_col}' çš„é‡å¤ç‡", type="primary"):
                    original_len = len(df)
                    cleaned_df = cleaner.reduce_feature_repetition(target_col, target_rate)
                    new_len = len(cleaned_df)
                    st.session_state.processed_data = cleaned_df

                    st.success(f"âœ… ä¼˜åŒ–å®Œæˆï¼åˆ é™¤äº† {original_len - new_len} ä¸ªæ ·æœ¬")
                    st.info(f"ğŸ“Š å½“å‰è¡Œæ•°: {new_len}ï¼Œ'{target_col}' çš„ä¼—æ•°å æ¯”å·²è°ƒæ•´è‡³ {target_rate * 100:.1f}%")
                    st.rerun()
            else:
                st.success("âœ… æœªæ£€æµ‹åˆ°é«˜é‡å¤ç‡ç‰¹å¾")

    with tab4:
        st.markdown("### æ•°æ®ç±»å‹è¯Šæ–­")

        pseudo_numeric = cleaner.detect_pseudo_numeric_columns()

        if pseudo_numeric:
            st.warning(f"æ£€æµ‹åˆ° {len(pseudo_numeric)} ä¸ªä¼ªæ•°å€¼åˆ—")
            st.json(pseudo_numeric)

            if st.button("ğŸ”§ ä¿®å¤ä¼ªæ•°å€¼åˆ—", type="primary"):
                cleaned_df = cleaner.fix_pseudo_numeric_columns()
                st.session_state.processed_data = cleaned_df
                st.success("âœ… æ•°æ®ç±»å‹ä¿®å¤å®Œæˆ")
        else:
            st.success("âœ… æ•°æ®ç±»å‹æ­£å¸¸")

    with tab5:
        st.markdown("### âš–ï¸ ç±»åˆ«å¹³è¡¡ (é’ˆå¯¹åŒ–å­¦ç»“æ„)")
        st.info(
            "ğŸ’¡ è§£å†³ç‰¹å®šå•ä½“/åˆ†å­é‡å¤æ¬¡æ•°è¿‡å¤šçš„é—®é¢˜ã€‚é€šè¿‡é™åˆ¶æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ ·æœ¬æ•°ï¼Œå¼ºåˆ¶æ•°æ®åˆ†å¸ƒæ›´å‡åŒ€ï¼Œé¿å…æ¨¡å‹åå‘å¸¸è§åˆ†å­ã€‚")

        # 1. é€‰æ‹©åˆ†ç±»åˆ—
        # é»˜è®¤å°è¯•æ‰¾ 'smiles' ç›¸å…³åˆ—
        text_cols = df.select_dtypes(include=['object']).columns.tolist()
        if text_cols:
            cat_col = st.selectbox("é€‰æ‹©è¦å¹³è¡¡çš„ç±»åˆ«åˆ— (é€šå¸¸æ˜¯SMILES)", text_cols)

            # 2. åˆ†æå½“å‰åˆ†å¸ƒ
            counts = df[cat_col].value_counts()
            n_unique = len(counts)

            col1, col2, col3 = st.columns(3)
            col1.metric("å”¯ä¸€ç±»åˆ«æ•°", n_unique)
            col2.metric("æœ€å¤§æ ·æœ¬æ•°", counts.max())
            col3.metric("ä¸­ä½æ•°æ ·æœ¬æ•°", int(counts.median()))

            st.markdown("#### Top 10 å‡ºç°æœ€é¢‘ç¹çš„åˆ†å­")
            st.bar_chart(counts.head(10))

            # 3. è®¾ç½®å¹³è¡¡å‚æ•°
            st.markdown("#### ğŸ”§ å¹³è¡¡è®¾ç½®")

            limit_val = st.slider(
                "æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ ·æœ¬æ•° (Max Samples per Category)",
                min_value=1,
                max_value=int(counts.max()),
                value=int(counts.median()) if n_unique > 0 else 10,
                help="å¦‚æœæŸåˆ†å­çš„å‡ºç°æ¬¡æ•°è¶…è¿‡æ­¤å€¼ï¼Œå¤šä½™çš„æ ·æœ¬å°†è¢«éšæœºä¸¢å¼ƒã€‚"
            )

            if st.button(f"âš–ï¸ æ‰§è¡Œå¹³è¡¡ (é™åˆ¶ä¸º {limit_val} ä¸ª)", type="primary"):
                old_len = len(df)
                cleaned_df = cleaner.balance_category_counts(cat_col, max_samples=limit_val)
                new_len = len(cleaned_df)

                st.session_state.processed_data = cleaned_df

                st.success(f"âœ… å¹³è¡¡å®Œæˆï¼")
                st.info(f"ğŸ“Š æ€»æ ·æœ¬æ•°ä» {old_len} å‡å°‘åˆ° {new_len} (åˆ é™¤äº† {old_len - new_len} ä¸ªè¿‡åº¦é‡å¤æ ·æœ¬)")
                st.rerun()
        else:
            st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬åˆ—ï¼Œæ— æ³•æ‰§è¡Œç±»åˆ«å¹³è¡¡")


# ============================================================
# é¡µé¢ï¼šæ•°æ®å¢å¼º
# ============================================================
def page_data_enhancement():
    """æ•°æ®å¢å¼ºé¡µé¢"""
    st.title("âœ¨ æ•°æ®å¢å¼º")

    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    enhancer = DataEnhancer(df)

    tab1, tab2 = st.tabs(["ğŸ”® KNNæ™ºèƒ½å¡«å……", "ğŸ§¬ VAEç”Ÿæˆå¼å¢å¼º"])

    with tab1:
        st.markdown("### KNNæ™ºèƒ½å¡«å……")
        st.info("ä½¿ç”¨Kè¿‘é‚»ç®—æ³•é¢„æµ‹å¹¶å¡«å……ç¼ºå¤±å€¼ï¼Œæ¯”ç®€å•çš„å‡å€¼/ä¸­ä½æ•°å¡«å……æ›´å‡†ç¡®")

        n_neighbors = st.slider("Kå€¼ï¼ˆè¿‘é‚»æ•°é‡ï¼‰", 1, 20, 5)

        if st.button("ğŸ”§ æ‰§è¡ŒKNNå¡«å……", type="primary"):
            with st.spinner("æ­£åœ¨æ‰§è¡ŒKNNå¡«å……..."):
                filled_df = enhancer.knn_impute(n_neighbors=n_neighbors)
                st.session_state.processed_data = filled_df
                st.success("âœ… KNNå¡«å……å®Œæˆ")

                # å¯¹æ¯”
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("åŸå§‹ç¼ºå¤±å€¼", df.isnull().sum().sum())
                with col2:
                    st.metric("å¤„ç†åç¼ºå¤±å€¼", filled_df.isnull().sum().sum())

    with tab2:
        st.markdown("### VAEç”Ÿæˆå¼æ•°æ®å¢å¼º")
        st.info("ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨(VAE)å­¦ä¹ æ•°æ®åˆ†å¸ƒï¼Œç”Ÿæˆé«˜ä¿çœŸè™šæ‹Ÿæ•°æ®ç‚¹")

        col1, col2 = st.columns(2)
        with col1:
            n_samples = st.number_input("ç”Ÿæˆæ ·æœ¬æ•°é‡", 10, 1000, 100)
            latent_dim = st.slider("æ½œåœ¨ç©ºé—´ç»´åº¦", 4, 64, 16)
            h_dim = st.slider("éšè—å±‚ç»´åº¦", 32, 256, 128)

        with col2:
            epochs = st.slider("è®­ç»ƒè½®æ•°", 10, 500, 100)
            batch_size = st.selectbox("æ‰¹å¤§å°", [16, 32, 64, 128], index=1)
            learning_rate = st.number_input("å­¦ä¹ ç‡", 0.0001, 0.1, 0.001, format="%.4f")

        if st.button("ğŸš€ ç”Ÿæˆå¢å¼ºæ•°æ®", type="primary"):
            try:
                with st.spinner("æ­£åœ¨è®­ç»ƒVAEæ¨¡å‹..."):
                    progress_bar = st.progress(0)

                    generated_df, fig = enhancer.generate_with_vae(
                        n_samples=n_samples,
                        latent_dim=latent_dim,
                        h_dim=h_dim,
                        epochs=epochs,
                        batch_size=batch_size,
                        lr=learning_rate
                    )

                    progress_bar.progress(100)

                st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_df)} ä¸ªæ ·æœ¬")

                # PCAå¯è§†åŒ–
                st.markdown("### ğŸ“Š PCAå¯è§†åŒ–å¯¹æ¯”")
                st.plotly_chart(fig, use_container_width=True)

                # åˆå¹¶é€‰é¡¹
                if st.checkbox("å°†ç”Ÿæˆæ•°æ®åˆå¹¶åˆ°åŸå§‹æ•°æ®"):
                    merged_df = pd.concat([df, generated_df], ignore_index=True)
                    st.session_state.processed_data = merged_df
                    st.success(f"âœ… åˆå¹¶åæ•°æ®: {merged_df.shape}")

            except Exception as e:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")


# ============================================================
# é¡µé¢ï¼šåˆ†å­ç‰¹å¾æå–ï¼ˆå®Œæ•´5ç§æ–¹æ³•ï¼‰
# ============================================================
def page_molecular_features():
    """åˆ†å­ç‰¹å¾æå–é¡µé¢ - å®Œæ•´è¿˜åŸ5ç§æ–¹æ³• + åˆ†å­æŒ‡çº¹ (é€‚é…åŒç»„åˆ†)"""
    st.title("ğŸ§¬ åˆ†å­ç‰¹å¾æå–")

    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return

    # ä¼˜å…ˆä½¿ç”¨å¤„ç†åçš„æ•°æ®
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data

    # æ£€æµ‹SMILESåˆ—
    text_cols = df.select_dtypes(include=['object']).columns.tolist()
    smiles_candidates = [col for col in text_cols if 'smiles' in col.lower() or 'smi' in col.lower()]

    if not text_cols:
        st.warning("âš ï¸ æ•°æ®ä¸­æœªæ£€æµ‹åˆ°æ–‡æœ¬åˆ—ï¼Œæ— æ³•æå–åˆ†å­ç‰¹å¾")
        return

    st.markdown("### ğŸ”¬ SMILESåˆ—é€‰æ‹©")

    col1, col2 = st.columns(2)
    with col1:
        default_idx = 0
        if smiles_candidates:
            default_idx = text_cols.index(smiles_candidates[0])

        # è¿™é‡Œæ˜ç¡®è¿™æ˜¯ç¬¬ä¸€ç»„åˆ†ï¼ˆé€šå¸¸æ˜¯æ ‘è„‚ï¼‰
        smiles_col = st.selectbox(
            "é€‰æ‹©åŒ…å«SMILESçš„åˆ— (æ ‘è„‚/ä¸»ä½“)",
            text_cols,
            index=default_idx
        )

    with col2:
        st.markdown("**ç¤ºä¾‹SMILES:**")
        samples = df[smiles_col].dropna().head(3).tolist()
        for s in samples:
            st.code(s[:50] + "..." if len(str(s)) > 50 else s)

    st.markdown("---")

    # ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ï¼š5ç§æå–æ–¹æ³•é€‰æ‹©
    st.markdown("### ğŸ› ï¸ æå–æ–¹æ³•é€‰æ‹©")

    extraction_method = st.radio(
        "é€‰æ‹©åˆ†å­ç‰¹å¾æå–æ–¹æ³•",
        [
            "ğŸ‘† åˆ†å­æŒ‡çº¹ (MACCS/Morgan) [æ–°]",
            "ğŸ”¹ RDKit æ ‡å‡†ç‰ˆ (æ¨èæ–°æ‰‹)",
            "ğŸš€ RDKit å¹¶è¡Œç‰ˆ (å¤§æ•°æ®é›†)",
            "ğŸ’¾ RDKit å†…å­˜ä¼˜åŒ–ç‰ˆ (ä½å†…å­˜)",
            "ğŸ”¬ Mordred æè¿°ç¬¦ (1600+ç‰¹å¾)",
            "ğŸ•¸ï¸ å›¾ç¥ç»ç½‘ç»œç‰¹å¾ (æ‹“æ‰‘ç»“æ„)",
            "âš›ï¸ MLåŠ›åœºç‰¹å¾ (ANIèƒ½é‡/åŠ›)",
            "âš—ï¸ ç¯æ°§æ ‘è„‚ååº”ç‰¹å¾ (åŸºäºé¢†åŸŸçŸ¥è¯†)"
        ],
        help="ä¸åŒæ–¹æ³•é€‚ç”¨äºä¸åŒåœºæ™¯"
    )

    # UI å˜é‡åˆå§‹åŒ–
    fp_type = "MACCS"
    fp_bits = 2048
    fp_radius = 2
    hardener_col = None  # åˆå§‹åŒ–å›ºåŒ–å‰‚åˆ—å˜é‡
    phr_col = None

    # ============== [UI ä¿®æ”¹] æŒ‡çº¹å‚æ•°è®¾ç½® ==============
    if "åˆ†å­æŒ‡çº¹" in extraction_method:
        st.info("ğŸ’¡ æç¤ºï¼šå¯¹äºç¯æ°§æ ‘è„‚ä½“ç³»ï¼Œå»ºè®®åŒæ—¶é€‰æ‹©æ ‘è„‚å’Œå›ºåŒ–å‰‚åˆ—ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ‹¼æ¥ä¸¤è€…çš„æŒ‡çº¹ä»¥æè¿°å®Œæ•´ç½‘ç»œç»“æ„ã€‚")

        col_fp1, col_fp2, col_fp3 = st.columns(3)
        with col_fp1:
            fp_type = st.selectbox("æŒ‡çº¹ç±»å‹", ["MACCS", "Morgan"])

        if fp_type == "Morgan":
            with col_fp2:
                fp_radius = st.selectbox("åŠå¾„ (Radius)", [2, 3, 4], index=0)
            with col_fp3:
                fp_bits = st.selectbox("ä½é•¿ (Bits)", [1024, 2048, 4096], index=1)

        # [æ–°å¢] åŒç»„åˆ†é€‰æ‹© UI
        st.markdown("#### åŒç»„åˆ†è®¾ç½® (æ¨è)")
        col_h1, col_h2 = st.columns(2)
        with col_h1:
            # æ’é™¤å·²é€‰çš„æ ‘è„‚åˆ—ï¼Œé¿å…é‡å¤é€‰æ‹©
            candidate_cols = ["æ—  (ä»…æå–å•åˆ—)"] + [c for c in text_cols if c != smiles_col]
            hardener_col_opt = st.selectbox("é€‰æ‹©ã€å›ºåŒ–å‰‚ã€‘SMILESåˆ—", candidate_cols)

            if hardener_col_opt != "æ—  (ä»…æå–å•åˆ—)":
                hardener_col = hardener_col_opt

    # ============== [UI] ç¯æ°§æ ‘è„‚ç‰¹å¾å‚æ•° ==============
    if "ç¯æ°§æ ‘è„‚ååº”ç‰¹å¾" in extraction_method:
        st.info("ğŸ’¡ è¯¥æ–¹æ³•éœ€è¦åŒæ—¶æä¾›ã€æ ‘è„‚ã€‘å’Œã€å›ºåŒ–å‰‚ã€‘çš„SMILESç»“æ„ã€‚")
        col_h, col_p = st.columns(2)
        with col_h:
            candidate_cols = [c for c in text_cols if c != smiles_col]
            hardener_col = st.selectbox("é€‰æ‹©ã€å›ºåŒ–å‰‚ã€‘SMILESåˆ—", candidate_cols)
        with col_p:
            num_cols = df.select_dtypes(include=np.number).columns.tolist()
            phr_col = st.selectbox("é€‰æ‹©ã€é…æ¯”/PHRã€‘åˆ— (å¯é€‰)", ["æ—  (å‡è®¾ç†æƒ³é…æ¯”)"] + num_cols)

    # å¹¶è¡Œç‰ˆå‚æ•°
    if "å¹¶è¡Œç‰ˆ" in extraction_method and OPTIMIZED_EXTRACTOR_AVAILABLE:
        col1, col2 = st.columns(2)
        with col1:
            n_jobs = st.slider("å¹¶è¡Œè¿›ç¨‹æ•°", 1, mp.cpu_count(), mp.cpu_count() // 2)
        with col2:
            batch_size = st.number_input("æ‰¹å¤„ç†å¤§å°", 100, 5000, 1000)

    st.markdown("---")

    # æ‰§è¡Œæå–
    if st.button("ğŸš€ å¼€å§‹æå–åˆ†å­ç‰¹å¾", type="primary"):
        smiles_list = df[smiles_col].tolist()

        # å‡†å¤‡å›ºåŒ–å‰‚åˆ—è¡¨
        hardener_list = None
        if hardener_col:
            hardener_list = df[hardener_col].tolist()

        try:
            progress_bar = st.progress(0)
            status_text = st.empty()

            # --- [é€»è¾‘ä¿®æ”¹] åˆ†å‘æå–ä»»åŠ¡ ---
            if "åˆ†å­æŒ‡çº¹" in extraction_method:
                from core.molecular_features import FingerprintExtractor

                # æç¤ºç”¨æˆ·å½“å‰æ¨¡å¼
                mode_str = "åŒç»„åˆ†æ‹¼æ¥" if hardener_list else "å•ç»„åˆ†"
                status_text.text(f"æ­£åœ¨æå– {fp_type} æŒ‡çº¹ ({mode_str}æ¨¡å¼)...")

                extractor = FingerprintExtractor()
                # ä¼ å…¥ smiles_list_2 (å›ºåŒ–å‰‚)
                features_df, valid_indices = extractor.smiles_to_fingerprints(
                    smiles_list,
                    smiles_list_2=hardener_list,
                    fp_type=fp_type, n_bits=fp_bits, radius=fp_radius
                )

            elif "æ ‡å‡†ç‰ˆ" in extraction_method:
                status_text.text("æ­£åœ¨ä½¿ç”¨RDKitæ ‡å‡†ç‰ˆæå–...")
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)

            elif "å¹¶è¡Œç‰ˆ" in extraction_method:
                if OPTIMIZED_EXTRACTOR_AVAILABLE:
                    status_text.text(f"æ­£åœ¨ä½¿ç”¨RDKitå¹¶è¡Œç‰ˆæå– ({n_jobs}è¿›ç¨‹)...")
                    extractor = OptimizedRDKitFeatureExtractor(n_jobs=n_jobs, batch_size=batch_size)
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                else:
                    st.warning("å¹¶è¡Œç‰ˆä¸å¯ç”¨ï¼Œå›é€€åˆ°æ ‡å‡†ç‰ˆ")
                    extractor = AdvancedMolecularFeatureExtractor()
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)

            elif "å†…å­˜ä¼˜åŒ–ç‰ˆ" in extraction_method:
                status_text.text("æ­£åœ¨ä½¿ç”¨RDKitå†…å­˜ä¼˜åŒ–ç‰ˆ...")
                extractor = MemoryEfficientRDKitExtractor()
                features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)

            elif "Mordred" in extraction_method:
                status_text.text("æ­£åœ¨ä½¿ç”¨Mordredæå–...")
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_mordred(smiles_list)

            elif "å›¾ç¥ç»ç½‘ç»œ" in extraction_method:
                status_text.text("æ­£åœ¨æå–å›¾ç»“æ„ç‰¹å¾...")
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_graph_features(smiles_list)

            elif "MLåŠ›åœº" in extraction_method:
                from core.molecular_features import MLForceFieldExtractor
                status_text.text("æ­£åœ¨è®¡ç®—ANIåŠ›åœºç‰¹å¾...")
                extractor = MLForceFieldExtractor()
                if not extractor.AVAILABLE:
                    st.error("TorchANI æœªå®‰è£…")
                    return
                features_df, valid_indices = extractor.smiles_to_ani_features(smiles_list)

            elif "ç¯æ°§æ ‘è„‚" in extraction_method:
                from core.molecular_features import EpoxyDomainFeatureExtractor
                status_text.text("æ­£åœ¨è®¡ç®—ç¯æ°§æ ‘è„‚é¢†åŸŸç‰¹å¾...")
                if hardener_col is None:
                    st.error("è¯·é€‰æ‹©å›ºåŒ–å‰‚åˆ—ï¼")
                    return

                phr_list = None
                if phr_col and phr_col != "æ—  (å‡è®¾ç†æƒ³é…æ¯”)":
                    phr_list = df[phr_col].tolist()

                extractor = EpoxyDomainFeatureExtractor()
                features_df, valid_indices = extractor.extract_features(smiles_list, hardener_list, phr_list)

            progress_bar.progress(100)

            # --- åˆå¹¶ç»“æœé€»è¾‘ (ä¿æŒä¸å˜) ---
            if len(features_df) > 0:
                st.session_state.molecular_features = features_df
                prefix = f"{smiles_col}_"
                features_df = features_df.add_prefix(prefix)

                df_valid = df.iloc[valid_indices].reset_index(drop=True)
                features_df = features_df.reset_index(drop=True)

                # é˜²æ­¢åˆ—åå†²çªï¼šå¦‚æœæ–°ç‰¹å¾åå·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤æ—§çš„
                cols_to_drop = [col for col in features_df.columns if col in df_valid.columns]
                if cols_to_drop:
                    df_valid = df_valid.drop(columns=cols_to_drop)

                merged_df = pd.concat([df_valid, features_df], axis=1)
                merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
                st.session_state.processed_data = merged_df

                st.success(f"âœ… æˆåŠŸæå– {len(features_df)} ä¸ªæ ·æœ¬çš„ {features_df.shape[1]} ä¸ªåˆ†å­ç‰¹å¾")

                # ç»“æœç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                col1.metric("æœ‰æ•ˆæ ·æœ¬", len(valid_indices))
                col2.metric("ç‰¹å¾æ•°é‡", features_df.shape[1])
                col3.metric("åŒç»„åˆ†æ¨¡å¼", "æ˜¯" if hardener_list else "å¦")

                st.markdown("### ğŸ“‹ ç‰¹å¾é¢„è§ˆ")
                st.dataframe(features_df.head(), use_container_width=True)
            else:
                st.error("âŒ æœªèƒ½æå–ä»»ä½•ç‰¹å¾ï¼Œè¯·æ£€æŸ¥SMILESæ ¼å¼")

        except Exception as e:
            st.error(f"âŒ æå–å¤±è´¥: {str(e)}")
            st.code(traceback.format_exc())


# ============================================================
# é¡µé¢ï¼šç‰¹å¾é€‰æ‹©ï¼ˆå®Œæ•´ç‰ˆï¼‰
# ============================================================
def page_feature_selection():
    """ç‰¹å¾é€‰æ‹©é¡µé¢ - è°ƒç”¨å®Œæ•´çš„show_robust_feature_selection"""
    st.title("ğŸ¯ ç‰¹å¾é€‰æ‹©")

    # è°ƒç”¨å®Œæ•´çš„ç‰¹å¾é€‰æ‹©UI
    show_robust_feature_selection()


# ============================================================
# é¡µé¢ï¼šæ¨¡å‹è®­ç»ƒï¼ˆå®Œæ•´æ‰‹åŠ¨è°ƒå‚ï¼‰
# ============================================================
def page_model_training():
    """æ¨¡å‹è®­ç»ƒé¡µé¢ - å®Œæ•´æ‰‹åŠ¨è°ƒå‚ç•Œé¢"""
    st.title("ğŸ¤– æ¨¡å‹è®­ç»ƒ")

    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return

    if not st.session_state.feature_cols or not st.session_state.target_col:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ç‰¹å¾é€‰æ‹©é¡µé¢é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡")
        return

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    feature_cols = st.session_state.feature_cols
    target_col = st.session_state.target_col

    # å‡†å¤‡æ•°æ®
    X = df[feature_cols]
    y = df[target_col]

    # æ˜¾ç¤ºå½“å‰é…ç½®
    col1, col2, col3 = st.columns(3)
    col1.metric("ç‰¹å¾æ•°é‡", len(feature_cols))
    col2.metric("æ ·æœ¬æ•°é‡", len(df))
    col3.metric("ç›®æ ‡å˜é‡", target_col)

    st.markdown("---")

    # æ¨¡å‹é€‰æ‹©
    trainer = EnhancedModelTrainer()
    available_models = trainer.get_available_models()

    # æ·»åŠ äººå·¥ç¥ç»ç½‘ç»œé€‰é¡¹
    if ANN_AVAILABLE and "äººå·¥ç¥ç»ç½‘ç»œ" not in available_models:
        available_models.append("äººå·¥ç¥ç»ç½‘ç»œ")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("### ğŸ“¦ æ¨¡å‹é€‰æ‹©")
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            available_models,
            help="é€‰æ‹©è¦è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹"
        )

        st.markdown("### âš™ï¸ è®­ç»ƒè®¾ç½®")
        test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.4, DEFAULT_TEST_SIZE)
        random_state = st.number_input("éšæœºç§å­", 0, 1000, DEFAULT_RANDOM_STATE)

    with col2:
        st.markdown("### ğŸ›ï¸ æ‰‹åŠ¨è°ƒå‚")

        # ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ï¼šåŠ¨æ€ç”Ÿæˆæ‰‹åŠ¨è°ƒå‚ç•Œé¢
        manual_params = {}

        if selected_model in MANUAL_TUNING_PARAMS:
            param_configs = MANUAL_TUNING_PARAMS[selected_model]

            if param_configs:
                st.info(f"ä¸º **{selected_model}** é…ç½®è¶…å‚æ•°")

                # åˆ›å»ºå‚æ•°è¾“å…¥æ§ä»¶
                param_cols = st.columns(2)

                for i, config in enumerate(param_configs):
                    with param_cols[i % 2]:
                        param_name = config['name']
                        param_label = config['label']
                        widget_type = config['widget']
                        default_val = config['default']
                        args = config.get('args', {})

                        # æ ¹æ®widgetç±»å‹åˆ›å»ºæ§ä»¶
                        if widget_type == 'slider':
                            manual_params[param_name] = st.slider(
                                param_label,
                                value=default_val,
                                key=f"param_{selected_model}_{param_name}",
                                **args
                            )
                        elif widget_type == 'number_input':
                            manual_params[param_name] = st.number_input(
                                param_label,
                                value=default_val,
                                key=f"param_{selected_model}_{param_name}",
                                **args
                            )
                        elif widget_type == 'selectbox':
                            options = args.get('options', [])
                            default_idx = options.index(default_val) if default_val in options else 0
                            manual_params[param_name] = st.selectbox(
                                param_label,
                                options=options,
                                index=default_idx,
                                key=f"param_{selected_model}_{param_name}"
                            )
                        elif widget_type == 'text_input':
                            manual_params[param_name] = st.text_input(
                                param_label,
                                value=default_val,
                                key=f"param_{selected_model}_{param_name}"
                            )
            else:
                st.info(f"**{selected_model}** æ— éœ€é…ç½®å‚æ•°")

        # æ˜¾ç¤ºå½“å‰å‚æ•°
        if manual_params:
            st.markdown("**å½“å‰å‚æ•°é…ç½®:**")
            st.json(manual_params)

    st.markdown("---")

    # è®­ç»ƒæŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
        try:
            with st.spinner(f"æ­£åœ¨è®­ç»ƒ {selected_model}..."):
                # åˆå¹¶é»˜è®¤å‚æ•°å’Œæ‰‹åŠ¨å‚æ•°
                final_params = MODEL_PARAMETERS.get(selected_model, {}).copy()
                final_params.update(manual_params)

                # å¤„ç†ç‰¹æ®Šå‚æ•°
                if selected_model == "å¤šå±‚æ„ŸçŸ¥å™¨" and 'hidden_layer_sizes' in final_params:
                    if isinstance(final_params['hidden_layer_sizes'], str):
                        try:
                            final_params['hidden_layer_sizes'] = tuple(
                                int(x.strip()) for x in final_params['hidden_layer_sizes'].split(',')
                            )
                        except:
                            final_params['hidden_layer_sizes'] = (100, 50)
                if 'random_state' in final_params:
                    final_params.pop('random_state')
                # è®­ç»ƒæ¨¡å‹
                result = trainer.train_model(
                    X, y,
                    model_name=selected_model,
                    test_size=test_size,
                    random_state=random_state,
                    **final_params
                )

                # ä¿å­˜ç»“æœ
                st.session_state.model = result['model']
                st.session_state.model_name = selected_model
                st.session_state.train_result = result
                st.session_state.scaler = result.get('scaler')
                st.session_state.pipeline = result.get('pipeline')
                st.session_state.X_train = result['X_train']
                st.session_state.X_test = result['X_test']
                st.session_state.y_train = result['y_train']
                st.session_state.y_test = result['y_test']

                st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

                # æ˜¾ç¤ºç»“æœ
                st.markdown("### ğŸ“Š è®­ç»ƒç»“æœ")

                col1, col2, col3, col4 = st.columns(4)
                col1.metric("RÂ² åˆ†æ•°", f"{result['r2']:.4f}")
                col2.metric("RMSE", f"{result['rmse']:.4f}")
                col3.metric("MAE", f"{result['mae']:.4f}")
                col4.metric("è®­ç»ƒæ—¶é—´", f"{result['train_time']:.2f}ç§’")

                # å¯è§†åŒ–
                visualizer = Visualizer()

                # ä¼˜å…ˆä½¿ç”¨æ–°é£æ ¼ç»˜å›¾
                if 'y_pred_train' in result:
                    st.markdown("### ğŸ“ˆ å®éªŒå€¼ vs é¢„æµ‹å€¼")
                    fig = visualizer.plot_parity_train_test(
                        y_train=result['y_train'],
                        y_pred_train=result['y_pred_train'],
                        y_test=result['y_test'],
                        y_pred_test=result['y_pred'],
                        target_name=target_col
                    )
                    st.pyplot(fig)
                else:
                    # å›é€€æ—§ç‰ˆï¼ˆé˜²æ­¢æœªæ›´æ–° trainer å¯¼è‡´æŠ¥é”™ï¼‰
                    fig, export_df = visualizer.plot_predictions_vs_true(
                        result['y_test'],
                        result['y_pred'],
                        selected_model
                    )
                    st.pyplot(fig)

                plt.close()

        except Exception as e:
            st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
            st.code(traceback.format_exc())


# ============================================================
# é¡µé¢ï¼šæ¨¡å‹è§£é‡Šï¼ˆå®Œæ•´ç‰ˆï¼‰
# ============================================================
def page_model_interpretation():
    """æ¨¡å‹è§£é‡Šé¡µé¢"""
    st.title("ğŸ“Š æ¨¡å‹è§£é‡Š")

    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return

    model = st.session_state.model
    model_name = st.session_state.model_name
    result = st.session_state.train_result

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ” SHAPåˆ†æ", "ğŸ“ˆ é¢„æµ‹æ€§èƒ½", "ğŸ“‰ å­¦ä¹ æ›²çº¿", "ğŸ¯ ç‰¹å¾é‡è¦æ€§", "ğŸ’¾ æ•°æ®å¯¼å‡º"
    ])

    with tab1:
        st.markdown("### SHAPç‰¹å¾é‡è¦æ€§åˆ†æ")

        try:
            X_test = st.session_state.X_test

            # é‡‡æ ·ç”¨äºSHAPè®¡ç®—
            sample_size = min(100, len(X_test))
            X_sample = X_test.sample(n=sample_size, random_state=42) if len(X_test) > sample_size else X_test

            interpreter = ModelInterpreter(model, X_sample, model_name)

            col1, col2 = st.columns(2)
            with col1:
                plot_type = st.selectbox("å›¾è¡¨ç±»å‹", ["bar", "beeswarm"])
            with col2:
                max_display = st.slider("æ˜¾ç¤ºç‰¹å¾æ•°", 5, 30, 15)

            if st.button("ğŸ” è®¡ç®—SHAPå€¼"):
                with st.spinner("æ­£åœ¨è®¡ç®—SHAPå€¼..."):
                    fig = interpreter.plot_summary(X_sample, plot_type=plot_type, max_display=max_display)
                    if fig:
                        st.pyplot(fig)
                        plt.close()
        except Exception as e:
            st.error(f"SHAPåˆ†æå¤±è´¥: {str(e)}")

    with tab2:
        st.markdown("### é¢„æµ‹æ€§èƒ½å¯è§†åŒ–")

        visualizer = Visualizer()

        # é¢„æµ‹å€¼ vs çœŸå®å€¼
        fig1, export_df = visualizer.plot_predictions_vs_true(
            result['y_test'],
            result['y_pred'],
            model_name
        )
        st.pyplot(fig1)
        plt.close()

        # æ®‹å·®åˆ†æ
        fig2 = visualizer.plot_residuals(
            result['y_test'],
            result['y_pred'],
            model_name
        )
        st.pyplot(fig2)
        plt.close()

    with tab3:
        st.markdown("### å­¦ä¹ æ›²çº¿")

        try:
            from sklearn.model_selection import learning_curve

            X = st.session_state.X_train
            y = st.session_state.y_train

            if st.button("ğŸ“‰ ç”Ÿæˆå­¦ä¹ æ›²çº¿"):
                with st.spinner("æ­£åœ¨è®¡ç®—å­¦ä¹ æ›²çº¿..."):
                    train_sizes, train_scores, test_scores = learning_curve(
                        model, X, y,
                        cv=5,
                        n_jobs=-1,
                        train_sizes=np.linspace(0.1, 1.0, 10),
                        scoring='r2'
                    )

                    fig, ax = plt.subplots(figsize=(10, 6))

                    train_mean = train_scores.mean(axis=1)
                    train_std = train_scores.std(axis=1)
                    test_mean = test_scores.mean(axis=1)
                    test_std = test_scores.std(axis=1)

                    ax.plot(train_sizes, train_mean, 'o-', label='è®­ç»ƒé›†')
                    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)

                    ax.plot(train_sizes, test_mean, 'o-', label='éªŒè¯é›†')
                    ax.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)

                    ax.set_xlabel('è®­ç»ƒæ ·æœ¬æ•°')
                    ax.set_ylabel('RÂ² åˆ†æ•°')
                    ax.set_title('å­¦ä¹ æ›²çº¿')
                    ax.legend()
                    ax.grid(True, alpha=0.3)

                    st.pyplot(fig)
                    plt.close()
        except Exception as e:
            st.error(f"å­¦ä¹ æ›²çº¿ç”Ÿæˆå¤±è´¥: {str(e)}")

    with tab4:
        st.markdown("### ç‰¹å¾é‡è¦æ€§")

        # å°è¯•è·å–ç‰¹å¾é‡è¦æ€§
        try:
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
                feature_names = st.session_state.feature_cols

                importance_df = pd.DataFrame({
                    'ç‰¹å¾': feature_names,
                    'é‡è¦æ€§': importances
                }).sort_values('é‡è¦æ€§', ascending=False)

                fig, ax = plt.subplots(figsize=(10, max(6, len(feature_names) * 0.3)))

                top_n = min(20, len(importance_df))
                top_features = importance_df.head(top_n)

                ax.barh(range(top_n), top_features['é‡è¦æ€§'].values[::-1])
                ax.set_yticks(range(top_n))
                ax.set_yticklabels(top_features['ç‰¹å¾'].values[::-1])
                ax.set_xlabel('é‡è¦æ€§')
                ax.set_title(f'{model_name} - ç‰¹å¾é‡è¦æ€§ (Top {top_n})')

                st.pyplot(fig)
                plt.close()

                st.dataframe(importance_df, use_container_width=True)
            else:
                st.info("è¯¥æ¨¡å‹ä¸æ”¯æŒç›´æ¥è·å–ç‰¹å¾é‡è¦æ€§ï¼Œè¯·ä½¿ç”¨SHAPåˆ†æ")
        except Exception as e:
            st.error(f"ç‰¹å¾é‡è¦æ€§è·å–å¤±è´¥: {str(e)}")

    with tab5:
        st.markdown("### å¯¼å‡ºé¢„æµ‹ç»“æœ")

        export_df = pd.DataFrame({
            'çœŸå®å€¼': result['y_test'],
            'é¢„æµ‹å€¼': result['y_pred'],
            'æ®‹å·®': result['y_test'] - result['y_pred']
        })

        csv = export_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœCSV",
            csv,
            f"predictions_{model_name}.csv",
            "text/csv"
        )


# ============================================================
# é¡µé¢ï¼šé¢„æµ‹åº”ç”¨
# ============================================================
def page_prediction():
    """é¢„æµ‹åº”ç”¨é¡µé¢"""
    st.title("ğŸ”® é¢„æµ‹åº”ç”¨")

    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return

    model = st.session_state.model
    model_name = st.session_state.model_name
    feature_cols = st.session_state.feature_cols
    scaler = st.session_state.scaler

    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ‰‹åŠ¨è¾“å…¥", "ğŸ“ æ‰¹é‡é¢„æµ‹", "ğŸ¯ é€‚ç”¨åŸŸåˆ†æ"])

    with tab1:
        st.markdown("### æ‰‹åŠ¨è¾“å…¥ç‰¹å¾å€¼")

        input_values = {}
        cols = st.columns(3)

        for i, feature in enumerate(feature_cols):
            with cols[i % 3]:
                input_values[feature] = st.number_input(
                    feature,
                    value=0.0,
                    format="%.4f",
                    key=f"input_{feature}"
                )

        if st.button("ğŸ”® é¢„æµ‹", type="primary"):
            try:
                input_df = pd.DataFrame([input_values])

                # ä½¿ç”¨pipelineæˆ–ç›´æ¥é¢„æµ‹
                if st.session_state.pipeline is not None:
                    prediction = st.session_state.pipeline.predict(input_df)
                else:
                    prediction = model.predict(input_df)

                st.success(f"### é¢„æµ‹ç»“æœ: **{prediction[0]:.4f}**")

            except Exception as e:
                st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")

    with tab2:
        st.markdown("### æ‰¹é‡é¢„æµ‹")

        uploaded_file = st.file_uploader("ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®", type=['csv', 'xlsx'])

        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    new_df = pd.read_csv(uploaded_file)
                else:
                    new_df = pd.read_excel(uploaded_file)

                st.dataframe(new_df.head(), use_container_width=True)

                # æ£€æŸ¥ç‰¹å¾åˆ—
                missing_cols = set(feature_cols) - set(new_df.columns)
                if missing_cols:
                    st.error(f"ç¼ºå°‘ç‰¹å¾åˆ—: {missing_cols}")
                else:
                    if st.button("ğŸš€ æ‰§è¡Œæ‰¹é‡é¢„æµ‹"):
                        X_new = new_df[feature_cols]

                        if st.session_state.pipeline is not None:
                            predictions = st.session_state.pipeline.predict(X_new)
                        else:
                            predictions = model.predict(X_new)

                        new_df['é¢„æµ‹å€¼'] = predictions
                        st.dataframe(new_df, use_container_width=True)

                        # ä¸‹è½½
                        csv = new_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
                            csv,
                            "batch_predictions.csv",
                            "text/csv"
                        )
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")

    with tab3:
        st.markdown("### é€‚ç”¨åŸŸåˆ†æ")
        st.info("åˆ†ææ–°æ ·æœ¬æ˜¯å¦åœ¨æ¨¡å‹è®­ç»ƒæ•°æ®çš„é€‚ç”¨èŒƒå›´å†…")

        if st.session_state.X_train is not None and scaler is not None:
            try:
                X_train = st.session_state.X_train

                # åˆ›å»ºåˆ†æå™¨
                analyzer = ApplicabilityDomainAnalyzer(X_train)

                st.markdown("#### è¾“å…¥å¾…åˆ†ææ ·æœ¬")

                input_values = {}
                cols = st.columns(3)
                for i, feature in enumerate(feature_cols):
                    with cols[i % 3]:
                        input_values[feature] = st.number_input(
                            feature,
                            value=0.0,
                            format="%.4f",
                            key=f"ad_input_{feature}"
                        )

                if st.button("ğŸ¯ åˆ†æé€‚ç”¨åŸŸ"):
                    input_df = pd.DataFrame([input_values])
                    is_in_domain, fig = analyzer.analyze(input_df, scaler)

                    if is_in_domain:
                        st.success("âœ… æ ·æœ¬åœ¨æ¨¡å‹é€‚ç”¨åŸŸå†…ï¼Œé¢„æµ‹ç»“æœå¯é ")
                    else:
                        st.warning("âš ï¸ æ ·æœ¬è¶…å‡ºæ¨¡å‹é€‚ç”¨åŸŸï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å¯é ")

                    st.pyplot(fig)
                    plt.close()

            except Exception as e:
                st.error(f"é€‚ç”¨åŸŸåˆ†æå¤±è´¥: {str(e)}")
        else:
            st.warning("éœ€è¦è®­ç»ƒæ•°æ®å’Œscaleræ‰èƒ½è¿›è¡Œé€‚ç”¨åŸŸåˆ†æ")


# ============================================================
# é¡µé¢ï¼šè¶…å‚ä¼˜åŒ–
# ============================================================
def page_hyperparameter_optimization():
    """è¶…å‚æ•°ä¼˜åŒ–é¡µé¢"""
    st.title("âš™ï¸ è¶…å‚æ•°ä¼˜åŒ–")

    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return

    if not st.session_state.feature_cols or not st.session_state.target_col:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ç‰¹å¾é€‰æ‹©é¡µé¢é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡")
        return

    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    feature_cols = st.session_state.feature_cols
    target_col = st.session_state.target_col

    X = df[feature_cols]
    y = df[target_col]

    st.markdown("### Optunaæ™ºèƒ½è¶…å‚æ•°ä¼˜åŒ–")

    col1, col2 = st.columns(2)

    with col1:
        trainer = EnhancedModelTrainer()
        available_models = trainer.get_available_models()

        # æ”¯æŒä¼˜åŒ–çš„æ¨¡å‹
        optimizable_models = [
            "éšæœºæ£®æ—", "XGBoost", "LightGBM", "CatBoost",
            "SVR", "Ridgeå›å½’", "Lassoå›å½’", "ElasticNet",
            "AdaBoost", "æ¢¯åº¦æå‡æ ‘"
        ]
        optimizable_models = [m for m in optimizable_models if m in available_models]

        model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", optimizable_models)

    with col2:
        n_trials = st.slider("ä¼˜åŒ–è½®æ•°", 10, 200, DEFAULT_OPTUNA_TRIALS)
        cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5)

    if st.button("ğŸš€ å¼€å§‹ä¼˜åŒ–", type="primary"):
        try:
            optimizer = HyperparameterOptimizer()

            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner(f"æ­£åœ¨ä¼˜åŒ– {model_name}..."):
                best_params, best_score, study = optimizer.optimize(
                    model_name, X, y,
                    n_trials=n_trials,
                    cv=cv_folds
                )

            progress_bar.progress(100)

            st.success(f"âœ… ä¼˜åŒ–å®Œæˆï¼æœ€ä½³RÂ²åˆ†æ•°: {best_score:.4f}")

            st.markdown("### æœ€ä½³å‚æ•°")
            st.json(best_params)

            # ä¼˜åŒ–å†å²å¯è§†åŒ–
            if study is not None:
                st.markdown("### ä¼˜åŒ–å†å²")

                try:
                    import plotly.graph_objects as go

                    trials = study.trials
                    values = [t.value for t in trials if t.value is not None]

                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        y=values,
                        mode='lines+markers',
                        name='RÂ² Score'
                    ))
                    fig.update_layout(
                        title='ä¼˜åŒ–è¿‡ç¨‹',
                        xaxis_title='Trial',
                        yaxis_title='RÂ² Score'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                except:
                    pass

            # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒ
            if st.button("ğŸ¯ ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæ¨¡å‹"):
                result = trainer.train_model(
                    X, y,
                    model_name=model_name,
                    **best_params
                )

                st.session_state.model = result['model']
                st.session_state.model_name = model_name
                st.session_state.train_result = result
                st.session_state.best_params = best_params

                st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼RÂ²: {result['r2']:.4f}")

        except Exception as e:
            st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}")
            st.code(traceback.format_exc())


# ============================================================
# ä¸»å‡½æ•°
# ============================================================
def main():
    """ä¸»å‡½æ•°"""
    page = render_sidebar()

    if page == "ğŸ  é¦–é¡µ":
        page_home()
    elif page == "ğŸ“¤ æ•°æ®ä¸Šä¼ ":
        page_data_upload()
    elif page == "ğŸ” æ•°æ®æ¢ç´¢":
        page_data_explore()
    elif page == "ğŸ§¹ æ•°æ®æ¸…æ´—":
        page_data_cleaning()
    elif page == "âœ¨ æ•°æ®å¢å¼º":
        page_data_enhancement()
    elif page == "ğŸ§¬ åˆ†å­ç‰¹å¾":
        page_molecular_features()
    elif page == "ğŸ¯ ç‰¹å¾é€‰æ‹©":
        page_feature_selection()
    elif page == "ğŸ¤– æ¨¡å‹è®­ç»ƒ":
        page_model_training()
    elif page == "ğŸ“Š æ¨¡å‹è§£é‡Š":
        page_model_interpretation()
    elif page == "ğŸ”® é¢„æµ‹åº”ç”¨":
        page_prediction()
    elif page == "âš™ï¸ è¶…å‚ä¼˜åŒ–":
        page_hyperparameter_optimization()


if __name__ == "__main__":
    main()