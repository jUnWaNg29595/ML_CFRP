# -*- coding: utf-8 -*-
"""
ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å° v1.2.0

"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import torch
import traceback
import json
import io
from datetime import datetime
import multiprocessing as mp
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core.data_processor import AdvancedDataCleaner, SparseDataHandler, DataEnhancer
from core.data_explorer import EnhancedDataExplorer
from core.model_trainer import EnhancedModelTrainer
from core.model_interpreter import ModelInterpreter, EnhancedModelInterpreter
from core.molecular_features import AdvancedMolecularFeatureExtractor, RDKitFeatureExtractor
from core.feature_selector import SmartFeatureSelector, SmartSparseDataSelector, show_robust_feature_selection
from core.optimizer import HyperparameterOptimizer, InverseDesigner, generate_tuning_suggestions
from core.visualizer import Visualizer
from core.applicability_domain import ApplicabilityDomainAnalyzer
from core.ui_config import (
    MANUAL_TUNING_PARAMS,
    MODEL_PARAMETERS,
    DEFAULT_OPTUNA_TRIALS,
    DEFAULT_TEST_SIZE,
    DEFAULT_RANDOM_STATE
)

from config import APP_NAME, VERSION, DATA_DIR
from generate_sample_data import generate_hybrid_dataset, generate_pure_numeric_dataset

# å¯é€‰æ¨¡å—å¯¼å…¥
try:
    from core.molecular_features import OptimizedRDKitFeatureExtractor, MemoryEfficientRDKitExtractor
    OPTIMIZED_EXTRACTOR_AVAILABLE = True
except ImportError:
    OPTIMIZED_EXTRACTOR_AVAILABLE = False

try:
    from core.graph_utils import GNNFeaturizer, smiles_to_pyg_graph
    GNN_AVAILABLE = True
except ImportError:
    GNN_AVAILABLE = False

try:
    from core.ann_model import ANNRegressor
    ANN_AVAILABLE = True
except ImportError:
    ANN_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# --- å…¨å±€å¸¸é‡ ---
USER_DATA_DB = "datasets/user_data.csv"

# --- è‡ªå®šä¹‰ CSS æ ·å¼ ---
CUSTOM_CSS = """
<style>
    :root {
        --primary-color: #4F46E5;
        --success-color: #10B981;
        --warning-color: #F59E0B;
        --error-color: #EF4444;
        --bg-card: #F8FAFC;
        --border-color: #E2E8F0;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 12px;
        padding: 20px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        margin: 8px 0;
    }
    
    .metric-card-success {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
    }
    
    .metric-card-warning {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    }
    
    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        margin: 8px 0;
    }
    
    .metric-label {
        font-size: 0.9rem;
        opacity: 0.9;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    .result-panel {
        background: var(--bg-card);
        border: 1px solid var(--border-color);
        border-radius: 8px;
        padding: 16px;
        margin: 8px 0;
    }
    
    .feature-badge {
        display: inline-block;
        background: #E0E7FF;
        color: #4338CA;
        padding: 4px 12px;
        border-radius: 16px;
        font-size: 0.85rem;
        margin: 2px;
    }
    
    .status-success {
        color: var(--success-color);
        font-weight: 600;
    }
    
    .status-warning {
        color: var(--warning-color);
        font-weight: 600;
    }
    
    .status-error {
        color: var(--error-color);
        font-weight: 600;
    }
</style>
"""

st.markdown(CUSTOM_CSS, unsafe_allow_html=True)


# ============================================================
# Session State åˆå§‹åŒ–
# ============================================================
def init_session_state():
    """åˆå§‹åŒ–æ‰€æœ‰session stateå˜é‡"""
    defaults = {
        'data': None,
        'processed_data': None,
        'molecular_features': None,
        'target_col': None,
        'feature_cols': [],
        'model': None,
        'model_name': None,
        'train_result': None,
        'scaler': None,
        'pipeline': None,
        'X_train': None,
        'X_test': None,
        'y_train': None,
        'y_test': None,
        'optimization_history': [],
        'best_params': None,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


init_session_state()


# ============================================================
# ä¾§è¾¹æ æ¸²æŸ“
# ============================================================
def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ å¯¼èˆª"""
    with st.sidebar:
        st.title(f"ğŸ”¬ {APP_NAME}")
        st.caption(f"ç‰ˆæœ¬ {VERSION}")
        st.markdown("---")
        
        page = st.radio(
            "ğŸ“Œ åŠŸèƒ½å¯¼èˆª",
            [
                "ğŸ  é¦–é¡µ",
                "ğŸ“¤ æ•°æ®ä¸Šä¼ ",
                "ğŸ” æ•°æ®æ¢ç´¢",
                "ğŸ§¹ æ•°æ®æ¸…æ´—",
                "âœ¨ æ•°æ®å¢å¼º",
                "ğŸ§¬ åˆ†å­ç‰¹å¾",
                "ğŸ¯ ç‰¹å¾é€‰æ‹©",
                "ğŸ¤– æ¨¡å‹è®­ç»ƒ",
                "ğŸ“Š æ¨¡å‹è§£é‡Š",
                "ğŸ”® é¢„æµ‹åº”ç”¨",
                "âš™ï¸ è¶…å‚ä¼˜åŒ–",
            ],
            label_visibility="collapsed"
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“Š æ•°æ®çŠ¶æ€")
        
        if st.session_state.data is not None:
            df = st.session_state.data
            st.success(f"âœ… å·²åŠ è½½: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
            
            if st.session_state.molecular_features is not None:
                mf = st.session_state.molecular_features
                st.info(f"ğŸ§¬ åˆ†å­ç‰¹å¾: {mf.shape[1]}ä¸ª")
        else:
            st.warning("âš ï¸ æœªåŠ è½½æ•°æ®")
        
        if st.session_state.model is not None:
            st.success(f"âœ… å·²è®­ç»ƒ: {st.session_state.model_name}")
        
        st.markdown("---")
        st.markdown("### ğŸ”§ ç³»ç»Ÿä¿¡æ¯")
        st.caption(f"CPUæ ¸å¿ƒ: {mp.cpu_count()}")
        if PSUTIL_AVAILABLE:
            mem = psutil.virtual_memory()
            st.caption(f"å†…å­˜ä½¿ç”¨: {mem.percent}%")
        
        return page


# ============================================================
# é¡µé¢ï¼šé¦–é¡µ
# ============================================================
def page_home():
    """é¦–é¡µ"""
    st.title("ğŸ”¬ ç¢³çº¤ç»´å¤åˆææ–™æ™ºèƒ½é¢„æµ‹å¹³å°")
    st.markdown(f"**ç‰ˆæœ¬ {VERSION}** ")
    
    st.markdown("---")
    
    # åŠŸèƒ½å¡ç‰‡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <div class="metric-label">æ•°æ®å¤„ç†</div>
            <div class="metric-value">ğŸ“Š</div>
            <p>æ™ºèƒ½æ¸…æ´— Â· VAEå¢å¼º Â· KNNå¡«å……</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card metric-card-success">
            <div class="metric-label">åˆ†å­ç‰¹å¾</div>
            <div class="metric-value">ğŸ§¬</div>
            <p>RDKit Â· Mordred Â· å›¾ç‰¹å¾</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card metric-card-warning">
            <div class="metric-label">æ¨¡å‹è®­ç»ƒ</div>
            <div class="metric-value">ğŸ¤–</div>
            <p>15+æ¨¡å‹ Â· æ‰‹åŠ¨è°ƒå‚ Â· Optunaä¼˜åŒ–</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # æ ¸å¿ƒåŠŸèƒ½ä»‹ç»
    st.markdown("## ğŸš€ æ ¸å¿ƒåŠŸèƒ½")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸ“Š æ•°æ®å¤„ç†
        - **æ™ºèƒ½æ•°æ®æ¸…æ´—**: ç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼æ£€æµ‹ã€æ•°æ®ç±»å‹ä¿®å¤
        - **VAEæ•°æ®å¢å¼º**: åŸºäºå˜åˆ†è‡ªç¼–ç å™¨çš„è¡¨æ ¼æ•°æ®ç”Ÿæˆ
        - **KNNæ™ºèƒ½å¡«å……**: åŸºäºKè¿‘é‚»çš„ç¼ºå¤±å€¼é¢„æµ‹
        
        ### ğŸ§¬ åˆ†å­ç‰¹å¾æå–
        - **RDKitæ ‡å‡†ç‰ˆ**: 200+åˆ†å­æè¿°ç¬¦
        - **RDKitå¹¶è¡Œç‰ˆ**: å¤šè¿›ç¨‹åŠ é€Ÿæå–
        - **RDKitå†…å­˜ä¼˜åŒ–ç‰ˆ**: ä½å†…å­˜å ç”¨
        - **Mordredæè¿°ç¬¦**: 1600+åˆ†å­ç‰¹å¾
        - **å›¾ç¥ç»ç½‘ç»œç‰¹å¾**: åˆ†å­æ‹“æ‰‘ç»“æ„ç‰¹å¾
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ¤– æ¨¡å‹è®­ç»ƒ
        - **ä¼ ç»Ÿæ¨¡å‹**: çº¿æ€§å›å½’ã€SVRã€å†³ç­–æ ‘ç­‰
        - **é›†æˆæ¨¡å‹**: éšæœºæ£®æ—ã€XGBoostã€LightGBMã€CatBoost
        - **æ·±åº¦å­¦ä¹ **: è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ(ANN)
        - **AutoML**: TabPFNã€AutoGluon
        - **æ‰‹åŠ¨è°ƒå‚**: å¯è§†åŒ–å‚æ•°é…ç½®ç•Œé¢
        
        ### ğŸ“Š æ¨¡å‹è§£é‡Š
        - **SHAPåˆ†æ**: ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
        - **å­¦ä¹ æ›²çº¿**: æ¨¡å‹æ”¶æ•›åˆ†æ
        - **é€‚ç”¨åŸŸåˆ†æ**: PCAå‡¸åŒ…è¾¹ç•Œæ£€æµ‹
        """)
    
    st.markdown("---")
    
    # å¿«é€Ÿå¼€å§‹
    st.markdown("## âš¡ å¿«é€Ÿå¼€å§‹")
    st.info("""
    1. **ä¸Šä¼ æ•°æ®** â†’ æ”¯æŒCSVã€Excelæ ¼å¼
    2. **æ•°æ®æ¢ç´¢** â†’ æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯å’Œåˆ†å¸ƒ
    3. **åˆ†å­ç‰¹å¾** â†’ ä»SMILESæå–åˆ†å­æè¿°ç¬¦
    4. **ç‰¹å¾é€‰æ‹©** â†’ é€‰æ‹©ç›®æ ‡å˜é‡å’Œè¾“å…¥ç‰¹å¾
    5. **æ¨¡å‹è®­ç»ƒ** â†’ é€‰æ‹©æ¨¡å‹å¹¶è°ƒæ•´å‚æ•°
    6. **æ¨¡å‹è§£é‡Š** â†’ SHAPåˆ†æå’Œæ€§èƒ½è¯„ä¼°
    7. **é¢„æµ‹åº”ç”¨** â†’ å¯¹æ–°æ ·æœ¬è¿›è¡Œé¢„æµ‹
    """)


# ============================================================
# é¡µé¢ï¼šæ•°æ®ä¸Šä¼ 
# ============================================================
def page_data_upload():
    """æ•°æ®ä¸Šä¼ é¡µé¢"""
    st.title("ğŸ“¤ æ•°æ®ä¸Šä¼ ")
    
    tab1, tab2 = st.tabs(["ğŸ“ ä¸Šä¼ æ–‡ä»¶", "ğŸ“ ç”Ÿæˆç¤ºä¾‹æ•°æ®"])
    
    with tab1:
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            help="æ”¯æŒCSVå’ŒExcelæ ¼å¼"
        )
        
        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                st.session_state.data = df
                st.session_state.processed_data = df.copy()
                
                st.success(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
                
                # æ•°æ®é¢„è§ˆ
                st.markdown("### ğŸ“‹ æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head(10), use_container_width=True)
                
                # åˆ—ä¿¡æ¯
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("#### æ•°å€¼åˆ—")
                    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
                    for col in numeric_cols[:10]:
                        st.markdown(f"<span class='feature-badge'>{col}</span>", unsafe_allow_html=True)
                    if len(numeric_cols) > 10:
                        st.caption(f"... ç­‰å…± {len(numeric_cols)} ä¸ªæ•°å€¼åˆ—")
                
                with col2:
                    st.markdown("#### æ–‡æœ¬åˆ—")
                    text_cols = df.select_dtypes(include=['object']).columns.tolist()
                    for col in text_cols[:10]:
                        st.markdown(f"<span class='feature-badge'>{col}</span>", unsafe_allow_html=True)
                    if len(text_cols) > 10:
                        st.caption(f"... ç­‰å…± {len(text_cols)} ä¸ªæ–‡æœ¬åˆ—")
                        
            except Exception as e:
                st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
    
    with tab2:
        st.markdown("### ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ§ª æ··åˆæ•°æ®é›†")
            st.caption("åŒ…å«å·¥è‰ºå‚æ•°å’ŒSMILESåˆ†å­ç»“æ„")
            n_samples_hybrid = st.number_input("æ ·æœ¬æ•°é‡", 100, 2000, 500, key="n_hybrid")
            if st.button("ç”Ÿæˆæ··åˆæ•°æ®é›†", type="primary"):
                df = generate_hybrid_dataset(n_samples=n_samples_hybrid)
                st.session_state.data = df
                st.session_state.processed_data = df.copy()
                st.success(f"âœ… å·²ç”Ÿæˆæ··åˆæ•°æ®é›†: {df.shape}")
                st.dataframe(df.head(), use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ“Š çº¯æ•°å€¼æ•°æ®é›†")
            st.caption("ä»…åŒ…å«æ•°å€¼å‹å·¥è‰ºå‚æ•°")
            n_samples_numeric = st.number_input("æ ·æœ¬æ•°é‡", 100, 2000, 500, key="n_numeric")
            if st.button("ç”Ÿæˆçº¯æ•°å€¼æ•°æ®é›†", type="primary"):
                df = generate_pure_numeric_dataset(n_samples=n_samples_numeric)
                st.session_state.data = df
                st.session_state.processed_data = df.copy()
                st.success(f"âœ… å·²ç”Ÿæˆçº¯æ•°å€¼æ•°æ®é›†: {df.shape}")
                st.dataframe(df.head(), use_container_width=True)


# ============================================================
# é¡µé¢ï¼šæ•°æ®æ¢ç´¢
# ============================================================
def page_data_explore():
    """æ•°æ®æ¢ç´¢é¡µé¢"""
    st.title("ğŸ” æ•°æ®æ¢ç´¢")
    
    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    df = st.session_state.data
    explorer = EnhancedDataExplorer(df)
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š æè¿°ç»Ÿè®¡", "ğŸ”— ç›¸å…³æ€§åˆ†æ", "ğŸ“ˆ åˆ†å¸ƒå›¾", "â“ ç¼ºå¤±å€¼", "ğŸ’¾ å¯¼å‡º"
    ])
    
    with tab1:
        stats = explorer.generate_summary_stats()
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("æ€»è¡Œæ•°", stats['basic_info']['total_rows'])
        col2.metric("æ€»åˆ—æ•°", stats['basic_info']['total_columns'])
        col3.metric("æ•°å€¼åˆ—", stats['basic_info']['numeric_columns'])
        col4.metric("ç¼ºå¤±å€¼", stats['basic_info']['missing_values'])
        
        st.markdown("### æ•°å€¼ç‰¹å¾ç»Ÿè®¡")
        if explorer.numeric_cols:
            st.dataframe(df[explorer.numeric_cols].describe(), use_container_width=True)
    
    with tab2:
        st.markdown("### ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ")
        fig = explorer.plot_correlation_matrix()
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—")
        
        # é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
        pairs = explorer.get_high_correlation_pairs(threshold=0.8)
        if pairs:
            st.markdown("### âš ï¸ é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > 0.8)")
            for p in pairs[:10]:
                st.write(f"- **{p['feature1']}** â†” **{p['feature2']}**: {p['correlation']:.3f}")
    
    with tab3:
        st.markdown("### æ•°å€¼ç‰¹å¾åˆ†å¸ƒ")
        fig = explorer.plot_distributions()
        if fig:
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("### ç®±çº¿å›¾")
        fig_box = explorer.plot_boxplots()
        if fig_box:
            st.plotly_chart(fig_box, use_container_width=True)
    
    with tab4:
        st.markdown("### ç¼ºå¤±å€¼åˆ†æ")
        fig_missing = explorer.plot_missing_values()
        if fig_missing:
            st.plotly_chart(fig_missing, use_container_width=True)
        else:
            st.success("âœ… æ•°æ®æ— ç¼ºå¤±å€¼")
    
    with tab5:
        st.markdown("### å¯¼å‡ºæ•°æ®")
        col1, col2 = st.columns(2)
        
        with col1:
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "ğŸ“¥ ä¸‹è½½CSV",
                csv,
                "data_export.csv",
                "text/csv"
            )
        
        with col2:
            buffer = io.BytesIO()
            df.to_excel(buffer, index=False)
            st.download_button(
                "ğŸ“¥ ä¸‹è½½Excel",
                buffer.getvalue(),
                "data_export.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )


# ============================================================
# é¡µé¢ï¼šæ•°æ®æ¸…æ´—
# ============================================================
def page_data_cleaning():
    """æ•°æ®æ¸…æ´—é¡µé¢"""
    st.title("ğŸ§¹ æ•°æ®æ¸…æ´—")
    
    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    cleaner = AdvancedDataCleaner(df)
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "â“ ç¼ºå¤±å€¼å¤„ç†", "ğŸ“Š å¼‚å¸¸å€¼æ£€æµ‹", "ğŸ”„ é‡å¤æ•°æ®", "ğŸ”§ æ•°æ®ç±»å‹"
    ])
    
    with tab1:
        st.markdown("### ç¼ºå¤±å€¼å¤„ç†")
        
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        missing = df.isnull().sum()
        missing = missing[missing > 0]
        
        if len(missing) > 0:
            st.warning(f"æ£€æµ‹åˆ° {len(missing)} åˆ—å­˜åœ¨ç¼ºå¤±å€¼")
            
            col1, col2 = st.columns(2)
            with col1:
                st.dataframe(pd.DataFrame({
                    'åˆ—å': missing.index,
                    'ç¼ºå¤±æ•°é‡': missing.values,
                    'ç¼ºå¤±æ¯”ä¾‹': (missing.values / len(df) * 100).round(2)
                }), use_container_width=True)
            
            with col2:
                strategy = st.selectbox(
                    "é€‰æ‹©å¡«å……ç­–ç•¥",
                    ["median", "mean", "mode", "knn", "drop_rows", "constant"]
                )
                
                fill_value = None
                if strategy == "constant":
                    fill_value = st.number_input("å¡«å……å¸¸æ•°å€¼", value=0.0)
                
                if st.button("ğŸ”§ æ‰§è¡Œç¼ºå¤±å€¼å¤„ç†", type="primary"):
                    cleaned_df = cleaner.handle_missing_values(strategy=strategy, fill_value=fill_value)
                    st.session_state.processed_data = cleaned_df
                    st.success("âœ… ç¼ºå¤±å€¼å¤„ç†å®Œæˆ")
                    st.rerun()
        else:
            st.success("âœ… æ•°æ®æ— ç¼ºå¤±å€¼")
    
    with tab2:
        st.markdown("### å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†")
        
        col1, col2 = st.columns(2)
        with col1:
            method = st.selectbox("æ£€æµ‹æ–¹æ³•", ["iqr", "zscore"])
            threshold = st.slider("é˜ˆå€¼", 1.0, 5.0, 1.5 if method == "iqr" else 3.0)
        
        with col2:
            handle_method = st.selectbox("å¤„ç†æ–¹æ³•", ["clip", "replace_median", "remove"])
        
        if st.button("ğŸ” æ£€æµ‹å¼‚å¸¸å€¼"):
            outliers = cleaner.detect_outliers(method=method, threshold=threshold)
            if outliers:
                st.warning(f"æ£€æµ‹åˆ° {len(outliers)} åˆ—å­˜åœ¨å¼‚å¸¸å€¼")
                st.json(outliers)
            else:
                st.success("âœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸å€¼")
        
        if st.button("ğŸ”§ å¤„ç†å¼‚å¸¸å€¼", type="primary"):
            cleaned_df = cleaner.handle_outliers(method=handle_method, threshold=threshold)
            st.session_state.processed_data = cleaned_df
            st.success("âœ… å¼‚å¸¸å€¼å¤„ç†å®Œæˆ")
    
    with tab3:
        st.markdown("### é‡å¤æ•°æ®å¤„ç†")
        
        dup_count = df.duplicated().sum()
        st.metric("é‡å¤è¡Œæ•°", dup_count)
        
        if dup_count > 0:
            if st.button("ğŸ—‘ï¸ åˆ é™¤é‡å¤è¡Œ", type="primary"):
                cleaned_df = cleaner.remove_duplicates()
                st.session_state.processed_data = cleaned_df
                st.success(f"âœ… å·²åˆ é™¤ {dup_count} è¡Œé‡å¤æ•°æ®")
                st.rerun()
        else:
            st.success("âœ… æ— é‡å¤æ•°æ®")
    
    with tab4:
        st.markdown("### æ•°æ®ç±»å‹è¯Šæ–­")
        
        pseudo_numeric = cleaner.detect_pseudo_numeric_columns()
        
        if pseudo_numeric:
            st.warning(f"æ£€æµ‹åˆ° {len(pseudo_numeric)} ä¸ªä¼ªæ•°å€¼åˆ—")
            st.json(pseudo_numeric)
            
            if st.button("ğŸ”§ ä¿®å¤ä¼ªæ•°å€¼åˆ—", type="primary"):
                cleaned_df = cleaner.fix_pseudo_numeric_columns()
                st.session_state.processed_data = cleaned_df
                st.success("âœ… æ•°æ®ç±»å‹ä¿®å¤å®Œæˆ")
        else:
            st.success("âœ… æ•°æ®ç±»å‹æ­£å¸¸")


# ============================================================
# é¡µé¢ï¼šæ•°æ®å¢å¼º
# ============================================================
def page_data_enhancement():
    """æ•°æ®å¢å¼ºé¡µé¢"""
    st.title("âœ¨ æ•°æ®å¢å¼º")
    
    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    enhancer = DataEnhancer(df)
    
    tab1, tab2 = st.tabs(["ğŸ”® KNNæ™ºèƒ½å¡«å……", "ğŸ§¬ VAEç”Ÿæˆå¼å¢å¼º"])
    
    with tab1:
        st.markdown("### KNNæ™ºèƒ½å¡«å……")
        st.info("ä½¿ç”¨Kè¿‘é‚»ç®—æ³•é¢„æµ‹å¹¶å¡«å……ç¼ºå¤±å€¼ï¼Œæ¯”ç®€å•çš„å‡å€¼/ä¸­ä½æ•°å¡«å……æ›´å‡†ç¡®")
        
        n_neighbors = st.slider("Kå€¼ï¼ˆè¿‘é‚»æ•°é‡ï¼‰", 1, 20, 5)
        
        if st.button("ğŸ”§ æ‰§è¡ŒKNNå¡«å……", type="primary"):
            with st.spinner("æ­£åœ¨æ‰§è¡ŒKNNå¡«å……..."):
                filled_df = enhancer.knn_impute(n_neighbors=n_neighbors)
                st.session_state.processed_data = filled_df
                st.success("âœ… KNNå¡«å……å®Œæˆ")
                
                # å¯¹æ¯”
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("åŸå§‹ç¼ºå¤±å€¼", df.isnull().sum().sum())
                with col2:
                    st.metric("å¤„ç†åç¼ºå¤±å€¼", filled_df.isnull().sum().sum())
    
    with tab2:
        st.markdown("### VAEç”Ÿæˆå¼æ•°æ®å¢å¼º")
        st.info("ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨(VAE)å­¦ä¹ æ•°æ®åˆ†å¸ƒï¼Œç”Ÿæˆé«˜ä¿çœŸè™šæ‹Ÿæ•°æ®ç‚¹")
        
        col1, col2 = st.columns(2)
        with col1:
            n_samples = st.number_input("ç”Ÿæˆæ ·æœ¬æ•°é‡", 10, 1000, 100)
            latent_dim = st.slider("æ½œåœ¨ç©ºé—´ç»´åº¦", 4, 64, 16)
            h_dim = st.slider("éšè—å±‚ç»´åº¦", 32, 256, 128)
        
        with col2:
            epochs = st.slider("è®­ç»ƒè½®æ•°", 10, 500, 100)
            batch_size = st.selectbox("æ‰¹å¤§å°", [16, 32, 64, 128], index=1)
            learning_rate = st.number_input("å­¦ä¹ ç‡", 0.0001, 0.1, 0.001, format="%.4f")
        
        if st.button("ğŸš€ ç”Ÿæˆå¢å¼ºæ•°æ®", type="primary"):
            try:
                with st.spinner("æ­£åœ¨è®­ç»ƒVAEæ¨¡å‹..."):
                    progress_bar = st.progress(0)
                    
                    generated_df, fig = enhancer.generate_with_vae(
                        n_samples=n_samples,
                        latent_dim=latent_dim,
                        h_dim=h_dim,
                        epochs=epochs,
                        batch_size=batch_size,
                        lr=learning_rate
                    )
                    
                    progress_bar.progress(100)
                
                st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_df)} ä¸ªæ ·æœ¬")
                
                # PCAå¯è§†åŒ–
                st.markdown("### ğŸ“Š PCAå¯è§†åŒ–å¯¹æ¯”")
                st.plotly_chart(fig, use_container_width=True)
                
                # åˆå¹¶é€‰é¡¹
                if st.checkbox("å°†ç”Ÿæˆæ•°æ®åˆå¹¶åˆ°åŸå§‹æ•°æ®"):
                    merged_df = pd.concat([df, generated_df], ignore_index=True)
                    st.session_state.processed_data = merged_df
                    st.success(f"âœ… åˆå¹¶åæ•°æ®: {merged_df.shape}")
                    
            except Exception as e:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")


# ============================================================
# é¡µé¢ï¼šåˆ†å­ç‰¹å¾æå–ï¼ˆå®Œæ•´5ç§æ–¹æ³•ï¼‰
# ============================================================
def page_molecular_features():
    """åˆ†å­ç‰¹å¾æå–é¡µé¢ - å®Œæ•´è¿˜åŸ5ç§æ–¹æ³•"""
    st.title("ğŸ§¬ åˆ†å­ç‰¹å¾æå–")
    
    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    
    # æ£€æµ‹SMILESåˆ—
    text_cols = df.select_dtypes(include=['object']).columns.tolist()
    smiles_candidates = [col for col in text_cols if 'smiles' in col.lower() or 'smi' in col.lower()]
    
    if not text_cols:
        st.warning("âš ï¸ æ•°æ®ä¸­æœªæ£€æµ‹åˆ°æ–‡æœ¬åˆ—ï¼Œæ— æ³•æå–åˆ†å­ç‰¹å¾")
        return
    
    st.markdown("### ğŸ”¬ SMILESåˆ—é€‰æ‹©")
    
    col1, col2 = st.columns(2)
    with col1:
        default_idx = 0
        if smiles_candidates:
            default_idx = text_cols.index(smiles_candidates[0])
        
        smiles_col = st.selectbox(
            "é€‰æ‹©åŒ…å«SMILESçš„åˆ—",
            text_cols,
            index=default_idx
        )
    
    with col2:
        # æ˜¾ç¤ºSMILESç¤ºä¾‹
        st.markdown("**ç¤ºä¾‹SMILES:**")
        samples = df[smiles_col].dropna().head(3).tolist()
        for s in samples:
            st.code(s[:50] + "..." if len(str(s)) > 50 else s)
    
    st.markdown("---")
    
    # ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ï¼š5ç§æå–æ–¹æ³•é€‰æ‹©
    st.markdown("### ğŸ› ï¸ æå–æ–¹æ³•é€‰æ‹©")
    
    extraction_method = st.radio(
        "é€‰æ‹©åˆ†å­ç‰¹å¾æå–æ–¹æ³•",
        [
            "ğŸ”¹ RDKit æ ‡å‡†ç‰ˆ (æ¨èæ–°æ‰‹)",
            "ğŸš€ RDKit å¹¶è¡Œç‰ˆ (å¤§æ•°æ®é›†)",
            "ğŸ’¾ RDKit å†…å­˜ä¼˜åŒ–ç‰ˆ (ä½å†…å­˜)",
            "ğŸ”¬ Mordred æè¿°ç¬¦ (1600+ç‰¹å¾)",
            "ğŸ•¸ï¸ å›¾ç¥ç»ç½‘ç»œç‰¹å¾ (æ‹“æ‰‘ç»“æ„)"
        ],
        help="ä¸åŒæ–¹æ³•é€‚ç”¨äºä¸åŒåœºæ™¯"
    )
    
    # æ–¹æ³•è¯´æ˜
    method_info = {
        "ğŸ”¹ RDKit æ ‡å‡†ç‰ˆ (æ¨èæ–°æ‰‹)": {
            "desc": "ä½¿ç”¨RDKitè®¡ç®—200+åˆ†å­æè¿°ç¬¦ï¼Œé€‚åˆä¸­å°å‹æ•°æ®é›†",
            "features": "~200ä¸ª",
            "speed": "ä¸­ç­‰",
            "memory": "ä¸­ç­‰"
        },
        "ğŸš€ RDKit å¹¶è¡Œç‰ˆ (å¤§æ•°æ®é›†)": {
            "desc": "å¤šè¿›ç¨‹å¹¶è¡Œè®¡ç®—ï¼Œæ˜¾è‘—åŠ é€Ÿå¤§æ•°æ®é›†å¤„ç†",
            "features": "~200ä¸ª",
            "speed": "å¿«",
            "memory": "è¾ƒé«˜"
        },
        "ğŸ’¾ RDKit å†…å­˜ä¼˜åŒ–ç‰ˆ (ä½å†…å­˜)": {
            "desc": "åˆ†æ‰¹å¤„ç†ï¼Œé€‚åˆå†…å­˜å—é™ç¯å¢ƒ",
            "features": "~200ä¸ª",
            "speed": "æ…¢",
            "memory": "ä½"
        },
        "ğŸ”¬ Mordred æè¿°ç¬¦ (1600+ç‰¹å¾)": {
            "desc": "ä½¿ç”¨Mordredåº“è®¡ç®—1600+åˆ†å­æè¿°ç¬¦ï¼Œç‰¹å¾æœ€å…¨é¢",
            "features": "~1600ä¸ª",
            "speed": "æ…¢",
            "memory": "é«˜"
        },
        "ğŸ•¸ï¸ å›¾ç¥ç»ç½‘ç»œç‰¹å¾ (æ‹“æ‰‘ç»“æ„)": {
            "desc": "æå–åˆ†å­å›¾çš„æ‹“æ‰‘ç»Ÿè®¡ç‰¹å¾ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹æ•°ã€è¾¹æ•°ã€å¹³å‡åº¦ç­‰",
            "features": "~10ä¸ª",
            "speed": "ä¸­ç­‰",
            "memory": "ä¸­ç­‰"
        }
    }
    
    info = method_info[extraction_method]
    col1, col2, col3 = st.columns(3)
    col1.metric("é¢„è®¡ç‰¹å¾æ•°", info["features"])
    col2.metric("å¤„ç†é€Ÿåº¦", info["speed"])
    col3.metric("å†…å­˜å ç”¨", info["memory"])
    st.info(info["desc"])
    
    # å¹¶è¡Œç‰ˆå‚æ•°
    if "å¹¶è¡Œç‰ˆ" in extraction_method and OPTIMIZED_EXTRACTOR_AVAILABLE:
        col1, col2 = st.columns(2)
        with col1:
            n_jobs = st.slider("å¹¶è¡Œè¿›ç¨‹æ•°", 1, mp.cpu_count(), mp.cpu_count() // 2)
        with col2:
            batch_size = st.number_input("æ‰¹å¤„ç†å¤§å°", 100, 5000, 1000)
    
    st.markdown("---")
    
    # æ‰§è¡Œæå–
    if st.button("ğŸš€ å¼€å§‹æå–åˆ†å­ç‰¹å¾", type="primary"):
        smiles_list = df[smiles_col].tolist()
        
        try:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            if "æ ‡å‡†ç‰ˆ" in extraction_method:
                status_text.text("æ­£åœ¨ä½¿ç”¨RDKitæ ‡å‡†ç‰ˆæå–...")
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                
            elif "å¹¶è¡Œç‰ˆ" in extraction_method:
                if OPTIMIZED_EXTRACTOR_AVAILABLE:
                    status_text.text(f"æ­£åœ¨ä½¿ç”¨RDKitå¹¶è¡Œç‰ˆæå– ({n_jobs}è¿›ç¨‹)...")
                    extractor = OptimizedRDKitFeatureExtractor(n_jobs=n_jobs, batch_size=batch_size)
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                else:
                    st.warning("å¹¶è¡Œç‰ˆä¸å¯ç”¨ï¼Œå›é€€åˆ°æ ‡å‡†ç‰ˆ")
                    extractor = AdvancedMolecularFeatureExtractor()
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                    
            elif "å†…å­˜ä¼˜åŒ–ç‰ˆ" in extraction_method:
                if OPTIMIZED_EXTRACTOR_AVAILABLE:
                    status_text.text("æ­£åœ¨ä½¿ç”¨RDKitå†…å­˜ä¼˜åŒ–ç‰ˆæå–...")
                    extractor = MemoryEfficientRDKitExtractor()
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                else:
                    st.warning("å†…å­˜ä¼˜åŒ–ç‰ˆä¸å¯ç”¨ï¼Œå›é€€åˆ°æ ‡å‡†ç‰ˆ")
                    extractor = AdvancedMolecularFeatureExtractor()
                    features_df, valid_indices = extractor.smiles_to_rdkit_features(smiles_list)
                    
            elif "Mordred" in extraction_method:
                status_text.text("æ­£åœ¨ä½¿ç”¨Mordredæå–æè¿°ç¬¦...")
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_mordred(smiles_list)
                
            elif "å›¾ç¥ç»ç½‘ç»œ" in extraction_method:
                status_text.text("æ­£åœ¨æå–å›¾ç»“æ„ç‰¹å¾...")
                extractor = AdvancedMolecularFeatureExtractor()
                features_df, valid_indices = extractor.smiles_to_graph_features(smiles_list)
            
            progress_bar.progress(100)
            
            if len(features_df) > 0:
                st.session_state.molecular_features = features_df
                
                # åˆå¹¶åˆ°åŸå§‹æ•°æ®
                df_valid = df.iloc[valid_indices].reset_index(drop=True)
                merged_df = pd.concat([df_valid, features_df.reset_index(drop=True)], axis=1)
                st.session_state.processed_data = merged_df
                
                st.success(f"âœ… æˆåŠŸæå– {len(features_df)} ä¸ªæ ·æœ¬çš„ {features_df.shape[1]} ä¸ªåˆ†å­ç‰¹å¾")
                
                # ç»“æœç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                col1.metric("æœ‰æ•ˆæ ·æœ¬", len(valid_indices))
                col2.metric("å¤±è´¥æ ·æœ¬", len(smiles_list) - len(valid_indices))
                col3.metric("ç‰¹å¾æ•°é‡", features_df.shape[1])
                
                # ç‰¹å¾é¢„è§ˆ
                st.markdown("### ğŸ“‹ ç‰¹å¾é¢„è§ˆ")
                st.dataframe(features_df.head(), use_container_width=True)
            else:
                st.error("âŒ æœªèƒ½æå–ä»»ä½•ç‰¹å¾ï¼Œè¯·æ£€æŸ¥SMILESæ ¼å¼")
                
        except Exception as e:
            st.error(f"âŒ æå–å¤±è´¥: {str(e)}")
            st.code(traceback.format_exc())


# ============================================================
# é¡µé¢ï¼šç‰¹å¾é€‰æ‹©ï¼ˆå®Œæ•´ç‰ˆï¼‰
# ============================================================
def page_feature_selection():
    """ç‰¹å¾é€‰æ‹©é¡µé¢ - è°ƒç”¨å®Œæ•´çš„show_robust_feature_selection"""
    st.title("ğŸ¯ ç‰¹å¾é€‰æ‹©")
    
    # è°ƒç”¨å®Œæ•´çš„ç‰¹å¾é€‰æ‹©UI
    show_robust_feature_selection()


# ============================================================
# é¡µé¢ï¼šæ¨¡å‹è®­ç»ƒï¼ˆå®Œæ•´æ‰‹åŠ¨è°ƒå‚ï¼‰
# ============================================================
def page_model_training():
    """æ¨¡å‹è®­ç»ƒé¡µé¢ - å®Œæ•´æ‰‹åŠ¨è°ƒå‚ç•Œé¢"""
    st.title("ğŸ¤– æ¨¡å‹è®­ç»ƒ")
    
    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    if not st.session_state.feature_cols or not st.session_state.target_col:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ç‰¹å¾é€‰æ‹©é¡µé¢é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡")
        return
    
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    feature_cols = st.session_state.feature_cols
    target_col = st.session_state.target_col
    
    # å‡†å¤‡æ•°æ®
    X = df[feature_cols]
    y = df[target_col]
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    col1, col2, col3 = st.columns(3)
    col1.metric("ç‰¹å¾æ•°é‡", len(feature_cols))
    col2.metric("æ ·æœ¬æ•°é‡", len(df))
    col3.metric("ç›®æ ‡å˜é‡", target_col)
    
    st.markdown("---")
    
    # æ¨¡å‹é€‰æ‹©
    trainer = EnhancedModelTrainer()
    available_models = trainer.get_available_models()
    
    # æ·»åŠ äººå·¥ç¥ç»ç½‘ç»œé€‰é¡¹
    if ANN_AVAILABLE and "äººå·¥ç¥ç»ç½‘ç»œ" not in available_models:
        available_models.append("äººå·¥ç¥ç»ç½‘ç»œ")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("### ğŸ“¦ æ¨¡å‹é€‰æ‹©")
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            available_models,
            help="é€‰æ‹©è¦è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹"
        )
        
        st.markdown("### âš™ï¸ è®­ç»ƒè®¾ç½®")
        test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.4, DEFAULT_TEST_SIZE)
        random_state = st.number_input("éšæœºç§å­", 0, 1000, DEFAULT_RANDOM_STATE)
    
    with col2:
        st.markdown("### ğŸ›ï¸ æ‰‹åŠ¨è°ƒå‚")
        
        # ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ï¼šåŠ¨æ€ç”Ÿæˆæ‰‹åŠ¨è°ƒå‚ç•Œé¢
        manual_params = {}
        
        if selected_model in MANUAL_TUNING_PARAMS:
            param_configs = MANUAL_TUNING_PARAMS[selected_model]
            
            if param_configs:
                st.info(f"ä¸º **{selected_model}** é…ç½®è¶…å‚æ•°")
                
                # åˆ›å»ºå‚æ•°è¾“å…¥æ§ä»¶
                param_cols = st.columns(2)
                
                for i, config in enumerate(param_configs):
                    with param_cols[i % 2]:
                        param_name = config['name']
                        param_label = config['label']
                        widget_type = config['widget']
                        default_val = config['default']
                        args = config.get('args', {})
                        
                        # æ ¹æ®widgetç±»å‹åˆ›å»ºæ§ä»¶
                        if widget_type == 'slider':
                            manual_params[param_name] = st.slider(
                                param_label,
                                value=default_val,
                                key=f"param_{selected_model}_{param_name}",
                                **args
                            )
                        elif widget_type == 'number_input':
                            manual_params[param_name] = st.number_input(
                                param_label,
                                value=default_val,
                                key=f"param_{selected_model}_{param_name}",
                                **args
                            )
                        elif widget_type == 'selectbox':
                            options = args.get('options', [])
                            default_idx = options.index(default_val) if default_val in options else 0
                            manual_params[param_name] = st.selectbox(
                                param_label,
                                options=options,
                                index=default_idx,
                                key=f"param_{selected_model}_{param_name}"
                            )
                        elif widget_type == 'text_input':
                            manual_params[param_name] = st.text_input(
                                param_label,
                                value=default_val,
                                key=f"param_{selected_model}_{param_name}"
                            )
            else:
                st.info(f"**{selected_model}** æ— éœ€é…ç½®å‚æ•°")
        
        # æ˜¾ç¤ºå½“å‰å‚æ•°
        if manual_params:
            st.markdown("**å½“å‰å‚æ•°é…ç½®:**")
            st.json(manual_params)
    
    st.markdown("---")
    
    # è®­ç»ƒæŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
        try:
            with st.spinner(f"æ­£åœ¨è®­ç»ƒ {selected_model}..."):
                # åˆå¹¶é»˜è®¤å‚æ•°å’Œæ‰‹åŠ¨å‚æ•°
                final_params = MODEL_PARAMETERS.get(selected_model, {}).copy()
                final_params.update(manual_params)
                
                # å¤„ç†ç‰¹æ®Šå‚æ•°
                if selected_model == "å¤šå±‚æ„ŸçŸ¥å™¨" and 'hidden_layer_sizes' in final_params:
                    if isinstance(final_params['hidden_layer_sizes'], str):
                        try:
                            final_params['hidden_layer_sizes'] = tuple(
                                int(x.strip()) for x in final_params['hidden_layer_sizes'].split(',')
                            )
                        except:
                            final_params['hidden_layer_sizes'] = (100, 50)
                
                # è®­ç»ƒæ¨¡å‹
                result = trainer.train_model(
                    X, y,
                    model_name=selected_model,
                    test_size=test_size,
                    random_state=random_state,
                    **final_params
                )
                
                # ä¿å­˜ç»“æœ
                st.session_state.model = result['model']
                st.session_state.model_name = selected_model
                st.session_state.train_result = result
                st.session_state.scaler = result.get('scaler')
                st.session_state.pipeline = result.get('pipeline')
                st.session_state.X_train = result['X_train']
                st.session_state.X_test = result['X_test']
                st.session_state.y_train = result['y_train']
                st.session_state.y_test = result['y_test']
                
                st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                
                # æ˜¾ç¤ºç»“æœ
                st.markdown("### ğŸ“Š è®­ç»ƒç»“æœ")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("RÂ² åˆ†æ•°", f"{result['r2']:.4f}")
                col2.metric("RMSE", f"{result['rmse']:.4f}")
                col3.metric("MAE", f"{result['mae']:.4f}")
                col4.metric("è®­ç»ƒæ—¶é—´", f"{result['train_time']:.2f}ç§’")
                
                # å¯è§†åŒ–
                visualizer = Visualizer()
                fig, export_df = visualizer.plot_predictions_vs_true(
                    result['y_test'],
                    result['y_pred'],
                    selected_model
                )
                st.pyplot(fig)
                plt.close()
                
        except Exception as e:
            st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
            st.code(traceback.format_exc())


# ============================================================
# é¡µé¢ï¼šæ¨¡å‹è§£é‡Šï¼ˆå®Œæ•´ç‰ˆï¼‰
# ============================================================
def page_model_interpretation():
    """æ¨¡å‹è§£é‡Šé¡µé¢"""
    st.title("ğŸ“Š æ¨¡å‹è§£é‡Š")
    
    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    model = st.session_state.model
    model_name = st.session_state.model_name
    result = st.session_state.train_result
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ” SHAPåˆ†æ", "ğŸ“ˆ é¢„æµ‹æ€§èƒ½", "ğŸ“‰ å­¦ä¹ æ›²çº¿", "ğŸ¯ ç‰¹å¾é‡è¦æ€§", "ğŸ’¾ æ•°æ®å¯¼å‡º"
    ])
    
    with tab1:
        st.markdown("### SHAPç‰¹å¾é‡è¦æ€§åˆ†æ")
        
        try:
            X_test = st.session_state.X_test
            
            # é‡‡æ ·ç”¨äºSHAPè®¡ç®—
            sample_size = min(100, len(X_test))
            X_sample = X_test.sample(n=sample_size, random_state=42) if len(X_test) > sample_size else X_test
            
            interpreter = ModelInterpreter(model, X_sample, model_name)
            
            col1, col2 = st.columns(2)
            with col1:
                plot_type = st.selectbox("å›¾è¡¨ç±»å‹", ["bar", "beeswarm"])
            with col2:
                max_display = st.slider("æ˜¾ç¤ºç‰¹å¾æ•°", 5, 30, 15)
            
            if st.button("ğŸ” è®¡ç®—SHAPå€¼"):
                with st.spinner("æ­£åœ¨è®¡ç®—SHAPå€¼..."):
                    fig = interpreter.plot_summary(X_sample, plot_type=plot_type, max_display=max_display)
                    if fig:
                        st.pyplot(fig)
                        plt.close()
        except Exception as e:
            st.error(f"SHAPåˆ†æå¤±è´¥: {str(e)}")
    
    with tab2:
        st.markdown("### é¢„æµ‹æ€§èƒ½å¯è§†åŒ–")
        
        visualizer = Visualizer()
        
        # é¢„æµ‹å€¼ vs çœŸå®å€¼
        fig1, export_df = visualizer.plot_predictions_vs_true(
            result['y_test'],
            result['y_pred'],
            model_name
        )
        st.pyplot(fig1)
        plt.close()
        
        # æ®‹å·®åˆ†æ
        fig2 = visualizer.plot_residuals(
            result['y_test'],
            result['y_pred'],
            model_name
        )
        st.pyplot(fig2)
        plt.close()
    
    with tab3:
        st.markdown("### å­¦ä¹ æ›²çº¿")
        
        try:
            from sklearn.model_selection import learning_curve
            
            X = st.session_state.X_train
            y = st.session_state.y_train
            
            if st.button("ğŸ“‰ ç”Ÿæˆå­¦ä¹ æ›²çº¿"):
                with st.spinner("æ­£åœ¨è®¡ç®—å­¦ä¹ æ›²çº¿..."):
                    train_sizes, train_scores, test_scores = learning_curve(
                        model, X, y,
                        cv=5,
                        n_jobs=-1,
                        train_sizes=np.linspace(0.1, 1.0, 10),
                        scoring='r2'
                    )
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    
                    train_mean = train_scores.mean(axis=1)
                    train_std = train_scores.std(axis=1)
                    test_mean = test_scores.mean(axis=1)
                    test_std = test_scores.std(axis=1)
                    
                    ax.plot(train_sizes, train_mean, 'o-', label='è®­ç»ƒé›†')
                    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)
                    
                    ax.plot(train_sizes, test_mean, 'o-', label='éªŒè¯é›†')
                    ax.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)
                    
                    ax.set_xlabel('è®­ç»ƒæ ·æœ¬æ•°')
                    ax.set_ylabel('RÂ² åˆ†æ•°')
                    ax.set_title('å­¦ä¹ æ›²çº¿')
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    
                    st.pyplot(fig)
                    plt.close()
        except Exception as e:
            st.error(f"å­¦ä¹ æ›²çº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    with tab4:
        st.markdown("### ç‰¹å¾é‡è¦æ€§")
        
        # å°è¯•è·å–ç‰¹å¾é‡è¦æ€§
        try:
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
                feature_names = st.session_state.feature_cols
                
                importance_df = pd.DataFrame({
                    'ç‰¹å¾': feature_names,
                    'é‡è¦æ€§': importances
                }).sort_values('é‡è¦æ€§', ascending=False)
                
                fig, ax = plt.subplots(figsize=(10, max(6, len(feature_names) * 0.3)))
                
                top_n = min(20, len(importance_df))
                top_features = importance_df.head(top_n)
                
                ax.barh(range(top_n), top_features['é‡è¦æ€§'].values[::-1])
                ax.set_yticks(range(top_n))
                ax.set_yticklabels(top_features['ç‰¹å¾'].values[::-1])
                ax.set_xlabel('é‡è¦æ€§')
                ax.set_title(f'{model_name} - ç‰¹å¾é‡è¦æ€§ (Top {top_n})')
                
                st.pyplot(fig)
                plt.close()
                
                st.dataframe(importance_df, use_container_width=True)
            else:
                st.info("è¯¥æ¨¡å‹ä¸æ”¯æŒç›´æ¥è·å–ç‰¹å¾é‡è¦æ€§ï¼Œè¯·ä½¿ç”¨SHAPåˆ†æ")
        except Exception as e:
            st.error(f"ç‰¹å¾é‡è¦æ€§è·å–å¤±è´¥: {str(e)}")
    
    with tab5:
        st.markdown("### å¯¼å‡ºé¢„æµ‹ç»“æœ")
        
        export_df = pd.DataFrame({
            'çœŸå®å€¼': result['y_test'],
            'é¢„æµ‹å€¼': result['y_pred'],
            'æ®‹å·®': result['y_test'] - result['y_pred']
        })
        
        csv = export_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœCSV",
            csv,
            f"predictions_{model_name}.csv",
            "text/csv"
        )


# ============================================================
# é¡µé¢ï¼šé¢„æµ‹åº”ç”¨
# ============================================================
def page_prediction():
    """é¢„æµ‹åº”ç”¨é¡µé¢"""
    st.title("ğŸ”® é¢„æµ‹åº”ç”¨")
    
    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    model = st.session_state.model
    model_name = st.session_state.model_name
    feature_cols = st.session_state.feature_cols
    scaler = st.session_state.scaler
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ‰‹åŠ¨è¾“å…¥", "ğŸ“ æ‰¹é‡é¢„æµ‹", "ğŸ¯ é€‚ç”¨åŸŸåˆ†æ"])
    
    with tab1:
        st.markdown("### æ‰‹åŠ¨è¾“å…¥ç‰¹å¾å€¼")
        
        input_values = {}
        cols = st.columns(3)
        
        for i, feature in enumerate(feature_cols):
            with cols[i % 3]:
                input_values[feature] = st.number_input(
                    feature,
                    value=0.0,
                    format="%.4f",
                    key=f"input_{feature}"
                )
        
        if st.button("ğŸ”® é¢„æµ‹", type="primary"):
            try:
                input_df = pd.DataFrame([input_values])
                
                # ä½¿ç”¨pipelineæˆ–ç›´æ¥é¢„æµ‹
                if st.session_state.pipeline is not None:
                    prediction = st.session_state.pipeline.predict(input_df)
                else:
                    prediction = model.predict(input_df)
                
                st.success(f"### é¢„æµ‹ç»“æœ: **{prediction[0]:.4f}**")
                
            except Exception as e:
                st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")
    
    with tab2:
        st.markdown("### æ‰¹é‡é¢„æµ‹")
        
        uploaded_file = st.file_uploader("ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®", type=['csv', 'xlsx'])
        
        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    new_df = pd.read_csv(uploaded_file)
                else:
                    new_df = pd.read_excel(uploaded_file)
                
                st.dataframe(new_df.head(), use_container_width=True)
                
                # æ£€æŸ¥ç‰¹å¾åˆ—
                missing_cols = set(feature_cols) - set(new_df.columns)
                if missing_cols:
                    st.error(f"ç¼ºå°‘ç‰¹å¾åˆ—: {missing_cols}")
                else:
                    if st.button("ğŸš€ æ‰§è¡Œæ‰¹é‡é¢„æµ‹"):
                        X_new = new_df[feature_cols]
                        
                        if st.session_state.pipeline is not None:
                            predictions = st.session_state.pipeline.predict(X_new)
                        else:
                            predictions = model.predict(X_new)
                        
                        new_df['é¢„æµ‹å€¼'] = predictions
                        st.dataframe(new_df, use_container_width=True)
                        
                        # ä¸‹è½½
                        csv = new_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
                            csv,
                            "batch_predictions.csv",
                            "text/csv"
                        )
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
    
    with tab3:
        st.markdown("### é€‚ç”¨åŸŸåˆ†æ")
        st.info("åˆ†ææ–°æ ·æœ¬æ˜¯å¦åœ¨æ¨¡å‹è®­ç»ƒæ•°æ®çš„é€‚ç”¨èŒƒå›´å†…")
        
        if st.session_state.X_train is not None and scaler is not None:
            try:
                X_train = st.session_state.X_train
                
                # åˆ›å»ºåˆ†æå™¨
                analyzer = ApplicabilityDomainAnalyzer(X_train)
                
                st.markdown("#### è¾“å…¥å¾…åˆ†ææ ·æœ¬")
                
                input_values = {}
                cols = st.columns(3)
                for i, feature in enumerate(feature_cols):
                    with cols[i % 3]:
                        input_values[feature] = st.number_input(
                            feature,
                            value=0.0,
                            format="%.4f",
                            key=f"ad_input_{feature}"
                        )
                
                if st.button("ğŸ¯ åˆ†æé€‚ç”¨åŸŸ"):
                    input_df = pd.DataFrame([input_values])
                    is_in_domain, fig = analyzer.analyze(input_df, scaler)
                    
                    if is_in_domain:
                        st.success("âœ… æ ·æœ¬åœ¨æ¨¡å‹é€‚ç”¨åŸŸå†…ï¼Œé¢„æµ‹ç»“æœå¯é ")
                    else:
                        st.warning("âš ï¸ æ ·æœ¬è¶…å‡ºæ¨¡å‹é€‚ç”¨åŸŸï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å¯é ")
                    
                    st.pyplot(fig)
                    plt.close()
                    
            except Exception as e:
                st.error(f"é€‚ç”¨åŸŸåˆ†æå¤±è´¥: {str(e)}")
        else:
            st.warning("éœ€è¦è®­ç»ƒæ•°æ®å’Œscaleræ‰èƒ½è¿›è¡Œé€‚ç”¨åŸŸåˆ†æ")


# ============================================================
# é¡µé¢ï¼šè¶…å‚ä¼˜åŒ–
# ============================================================
def page_hyperparameter_optimization():
    """è¶…å‚æ•°ä¼˜åŒ–é¡µé¢"""
    st.title("âš™ï¸ è¶…å‚æ•°ä¼˜åŒ–")
    
    if st.session_state.data is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    if not st.session_state.feature_cols or not st.session_state.target_col:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ç‰¹å¾é€‰æ‹©é¡µé¢é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡")
        return
    
    df = st.session_state.processed_data if st.session_state.processed_data is not None else st.session_state.data
    feature_cols = st.session_state.feature_cols
    target_col = st.session_state.target_col
    
    X = df[feature_cols]
    y = df[target_col]
    
    st.markdown("### Optunaæ™ºèƒ½è¶…å‚æ•°ä¼˜åŒ–")
    
    col1, col2 = st.columns(2)
    
    with col1:
        trainer = EnhancedModelTrainer()
        available_models = trainer.get_available_models()
        
        # æ”¯æŒä¼˜åŒ–çš„æ¨¡å‹
        optimizable_models = [
            "éšæœºæ£®æ—", "XGBoost", "LightGBM", "CatBoost",
            "SVR", "Ridgeå›å½’", "Lassoå›å½’", "ElasticNet",
            "AdaBoost", "æ¢¯åº¦æå‡æ ‘"
        ]
        optimizable_models = [m for m in optimizable_models if m in available_models]
        
        model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", optimizable_models)
    
    with col2:
        n_trials = st.slider("ä¼˜åŒ–è½®æ•°", 10, 200, DEFAULT_OPTUNA_TRIALS)
        cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5)
    
    if st.button("ğŸš€ å¼€å§‹ä¼˜åŒ–", type="primary"):
        try:
            optimizer = HyperparameterOptimizer()
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            with st.spinner(f"æ­£åœ¨ä¼˜åŒ– {model_name}..."):
                best_params, best_score, study = optimizer.optimize(
                    model_name, X, y,
                    n_trials=n_trials,
                    cv=cv_folds
                )
            
            progress_bar.progress(100)
            
            st.success(f"âœ… ä¼˜åŒ–å®Œæˆï¼æœ€ä½³RÂ²åˆ†æ•°: {best_score:.4f}")
            
            st.markdown("### æœ€ä½³å‚æ•°")
            st.json(best_params)
            
            # ä¼˜åŒ–å†å²å¯è§†åŒ–
            if study is not None:
                st.markdown("### ä¼˜åŒ–å†å²")
                
                try:
                    import plotly.graph_objects as go
                    
                    trials = study.trials
                    values = [t.value for t in trials if t.value is not None]
                    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        y=values,
                        mode='lines+markers',
                        name='RÂ² Score'
                    ))
                    fig.update_layout(
                        title='ä¼˜åŒ–è¿‡ç¨‹',
                        xaxis_title='Trial',
                        yaxis_title='RÂ² Score'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                except:
                    pass
            
            # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒ
            if st.button("ğŸ¯ ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæ¨¡å‹"):
                result = trainer.train_model(
                    X, y,
                    model_name=model_name,
                    **best_params
                )
                
                st.session_state.model = result['model']
                st.session_state.model_name = model_name
                st.session_state.train_result = result
                st.session_state.best_params = best_params
                
                st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼RÂ²: {result['r2']:.4f}")
                
        except Exception as e:
            st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}")
            st.code(traceback.format_exc())


# ============================================================
# ä¸»å‡½æ•°
# ============================================================
def main():
    """ä¸»å‡½æ•°"""
    page = render_sidebar()
    
    if page == "ğŸ  é¦–é¡µ":
        page_home()
    elif page == "ğŸ“¤ æ•°æ®ä¸Šä¼ ":
        page_data_upload()
    elif page == "ğŸ” æ•°æ®æ¢ç´¢":
        page_data_explore()
    elif page == "ğŸ§¹ æ•°æ®æ¸…æ´—":
        page_data_cleaning()
    elif page == "âœ¨ æ•°æ®å¢å¼º":
        page_data_enhancement()
    elif page == "ğŸ§¬ åˆ†å­ç‰¹å¾":
        page_molecular_features()
    elif page == "ğŸ¯ ç‰¹å¾é€‰æ‹©":
        page_feature_selection()
    elif page == "ğŸ¤– æ¨¡å‹è®­ç»ƒ":
        page_model_training()
    elif page == "ğŸ“Š æ¨¡å‹è§£é‡Š":
        page_model_interpretation()
    elif page == "ğŸ”® é¢„æµ‹åº”ç”¨":
        page_prediction()
    elif page == "âš™ï¸ è¶…å‚ä¼˜åŒ–":
        page_hyperparameter_optimization()


if __name__ == "__main__":
    main()
