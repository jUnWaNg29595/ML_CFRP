# -*- coding: utf-8 -*-
"""åˆ†å­ç‰¹å¾å·¥ç¨‹æ¨¡å— - å®Œæ•´5ç§æå–æ–¹æ³• + åˆ†å­æŒ‡çº¹ (é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆ)"""

import pandas as pd
import numpy as np
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp
from rdkit.Chem import MACCSkeys
from tqdm import tqdm
import warnings
import torch
import os  # æ–°å¢
import re  # æ–°å¢: ç”¨äºåˆ†å‰²å¤šç»„åˆ† SMILES
from functools import partial  # æ–°å¢

warnings.filterwarnings('ignore')

try:
    from rdkit import Chem
    from rdkit.Chem import Descriptors
    from rdkit.Chem import AllChem
    from rdkit.Chem import Descriptors3D, rdMolDescriptors
    from rdkit.Chem import MACCSkeys

    RDKIT_AVAILABLE = True
except ImportError:
    RDKIT_AVAILABLE = False

try:
    from mordred import Calculator, descriptors

    MORDRED_AVAILABLE = True
except ImportError:
    MORDRED_AVAILABLE = False


# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼š3D æ„è±¡ç”Ÿæˆ (ç”¨äºå¤šè¿›ç¨‹)
# =============================================================================
def _generate_3d_data_worker(smiles):
    """
    å•ä¸ªæ ·æœ¬çš„ 3D æ„è±¡ç”Ÿæˆå·¥ä½œå‡½æ•°ï¼ˆä¾›å¤šè¿›ç¨‹è°ƒç”¨ï¼‰

    - æ”¯æŒå¤šç»„åˆ†/å¤šç‰‡æ®µ SMILESï¼šä¼šè‡ªåŠ¨æŒ‰ ';'ã€'ï¼›'ã€'|'ã€å¸¦ç©ºæ ¼çš„ ' + 'ã€ä»¥åŠ '.' è¿›è¡Œåˆ†å‰²
    - å¯¹æ¯ä¸ªç‰‡æ®µåˆ†åˆ«ç”Ÿæˆ 3Dï¼ˆETKDGv3ï¼‰å¹¶åšè½»é‡ä¼˜åŒ–ï¼ˆMMFF / UFFï¼‰
    - ä»…ä¿ç•™ ANI2x æ”¯æŒçš„å…ƒç´ ï¼šH,C,N,O,F,S,Cl

    è¿”å›:
        list[tuple[list[int], np.ndarray]]  # [(atomic_numbers, coordinates), ...]
        æˆ– Noneï¼ˆä»»ä¸€ç‰‡æ®µå¤±è´¥åˆ™è¿”å› Noneï¼Œä¿è¯æ•°æ®è´¨é‡ï¼‰
    """
    if not RDKIT_AVAILABLE:
        return None

    try:
        if smiles is None or (isinstance(smiles, float) and np.isnan(smiles)):
            return None
        s = str(smiles).strip()
        if not s:
            return None

        # 1) æ™ºèƒ½åˆ†å‰²å¤šç»„åˆ†
        # å…ˆæŒ‰ ; / ï¼› / | åˆ†å‰²
        parts = re.split(r"\s*[;ï¼›|]\s*", s)

        # å†æŒ‰â€œå¸¦ç©ºæ ¼çš„ +â€åˆ†å‰²ï¼ˆé¿å…è¯¯ä¼¤ [N+] è¿™ç±»å¸¦ç”µè·å†™æ³•ï¼‰
        final = []
        for p in parts:
            final.extend(re.split(r"\s+\+\s+", p))

        # å†æŒ‰ '.' åˆ†å‰²ï¼ˆSMILES è§„èŒƒçš„å¤šç‰‡æ®µåˆ†éš”ï¼‰
        frags = []
        for p in final:
            frags.extend([x.strip() for x in str(p).split('.') if x and str(x).strip()])

        frags = [f for f in frags if f]
        if not frags:
            return None

        frag_data = []

        supported_species = {1, 6, 7, 8, 9, 16, 17}  # H,C,N,O,F,S,Cl (ANI2x)

        for frag in frags:
            mol = Chem.MolFromSmiles(frag)
            if mol is None:
                return None

            mol = Chem.AddHs(mol)  # åŠ›åœº/ANI è®¡ç®—å»ºè®®åŠ æ°¢

            # 2) ç”Ÿæˆ 3D æ„è±¡ï¼ˆETKDGv3ï¼‰
            params = AllChem.ETKDGv3()
            params.useRandomCoords = True
            params.numThreads = 1  # ç¦ç”¨ RDKit å†…éƒ¨çº¿ç¨‹ï¼Œé¿å…ä¸å¤šè¿›ç¨‹å†²çª

            res = AllChem.EmbedMolecule(mol, params)
            if res != 0:
                # å…œåº•ï¼šå†è¯•ä¸€æ¬¡
                res = AllChem.EmbedMolecule(mol, useRandomCoords=True)
                if res != 0:
                    return None

            # 3) å¿«é€Ÿå‡ ä½•ä¼˜åŒ–ï¼šä¼˜å…ˆ MMFFï¼Œå¦åˆ™ UFF
            try:
                AllChem.MMFFOptimizeMolecule(mol, maxIters=40)
            except Exception:
                try:
                    AllChem.UFFOptimizeMolecule(mol, maxIters=200)
                except Exception:
                    pass

            # 4) æå–æ•°æ®
            atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]
            if not set(atoms).issubset(supported_species):
                return None

            coords = mol.GetConformer().GetPositions().astype(np.float32)

            frag_data.append((atoms, coords))

        return frag_data if frag_data else None

    except Exception:
        return None



# =============================================================================
# 3D æè¿°ç¬¦ï¼šRDKit3D + Coulomb Matrix (å¯é€‰æ›´å‰æ²¿çš„æ„è±¡è¡¨å¾)
# =============================================================================
def _rdkit3d_feature_worker(smiles, coulomb_top_k: int = 10):
    """
    è®¡ç®—å•ä¸ªæ ·æœ¬çš„ 3D æ„è±¡æè¿°ç¬¦ï¼ˆä¿®å¤ç‰ˆï¼‰
    """
    if not RDKIT_AVAILABLE:
        return None

    try:
        if smiles is None or (isinstance(smiles, float) and np.isnan(smiles)):
            return None
        s = str(smiles).strip()
        if not s:
            return None

        # --- é¢„å¤„ç†ï¼šå¤„ç†èšåˆç‰©ä¸­çš„ * å· ---
        # 3D æ„è±¡ç”Ÿæˆä¸æ”¯æŒ *ï¼Œå°†å…¶æ›¿æ¢ä¸º C (ç”²åŸº) ä»¥æ¨¡æ‹Ÿå ä½
        if '*' in s:
            s = s.replace('*', 'C')

        # åˆ†å‰²å¤šç»„åˆ†
        parts = re.split(r"\s*[;ï¼›|]\s*", s)
        final = []
        for p in parts:
            final.extend(re.split(r"\s+\+\s+", p))
        frags = []
        for p in final:
            frags.extend([x.strip() for x in str(p).split('.') if x and str(x).strip()])
        frags = [f for f in frags if f]
        if not frags:
            return None

        total_atoms = 0
        n_frags = 0
        d3_weighted = {}
        eig_all = []

        for frag in frags:
            mol = Chem.MolFromSmiles(frag)
            if mol is None:
                continue  # è§£æå¤±è´¥è·³è¿‡è¯¥ç‰‡æ®µï¼Œä¸è¦ç›´æ¥è¿”å› None

            # è¿‡æ»¤æ‰å•åŸå­æˆ–å¤ªå°çš„ç¢ç‰‡ï¼ˆé€šå¸¸æ˜¯ç¦»å­æˆ–æ‚è´¨ï¼‰ï¼Œå®ƒä»¬å¾ˆéš¾ç”Ÿæˆæœ‰æ„ä¹‰çš„ 3D
            if mol.GetNumAtoms() < 2:
                continue

            mol = Chem.AddHs(mol)

            # --- ç”Ÿæˆ 3D æ„è±¡ (æ”¾å®½å‚æ•°) ---
            params = AllChem.ETKDGv3()
            params.useRandomCoords = True
            params.numThreads = 1
            params.maxAttempts = 50  # [ä¿®æ”¹] å¢åŠ å°è¯•æ¬¡æ•°

            # å°è¯•åµŒå…¥
            res = AllChem.EmbedMolecule(mol, params)

            # å¦‚æœå¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„éšæœºåæ ‡
            if res != 0:
                res = AllChem.EmbedMolecule(mol, useRandomCoords=True, maxAttempts=100)
                if res != 0:
                    # [ä¿®æ”¹] å¦‚æœè¯¥ç‰‡æ®µç”Ÿæˆå¤±è´¥ï¼Œä»…è·³è¿‡è¯¥ç‰‡æ®µï¼Œä¸æ”¾å¼ƒæ•´ä¸ªæ ·æœ¬
                    # print(f"âš ï¸ 3Dç”Ÿæˆå¤±è´¥ (è·³è¿‡ç‰‡æ®µ): {frag}")
                    continue

                    # ä¼˜åŒ–
            try:
                AllChem.MMFFOptimizeMolecule(mol, maxIters=100)
            except Exception:
                pass

            n_atoms = int(mol.GetNumAtoms())
            if n_atoms <= 0:
                continue

            n_frags += 1
            total_atoms += n_atoms

            # RDKit 3D descriptors
            try:
                d3 = Descriptors3D.CalcMolDescriptors3D(mol)  # dict
                for k, v in d3.items():
                    val = float(v)
                    if np.isfinite(val):
                        d3_weighted[k] = d3_weighted.get(k, 0.0) + val * n_atoms
            except Exception:
                pass

            # Coulomb matrix
            try:
                cm = rdMolDescriptors.CalcCoulombMat(mol)
                cm_arr = np.array([list(row) for row in cm], dtype=float)
                eig = np.linalg.eigvalsh(cm_arr)
                eig_all.append(eig)
            except Exception:
                pass

        # [ä¿®æ”¹] å¦‚æœæ‰€æœ‰ç‰‡æ®µéƒ½å¤±è´¥äº†ï¼Œæ‰è¿”å› None
        if total_atoms <= 0:
            # æ‰“å¼€ä¸‹é¢çš„æ³¨é‡Šå¯ä»¥è°ƒè¯•å…·ä½“æ˜¯å“ªä¸ª SMILES å¤±è´¥äº†
            # print(f"âŒ æ‰€æœ‰ç‰‡æ®µ3Dç”Ÿæˆå‡å¤±è´¥: {s}")
            return None

        out = {
            "rdkit3d_n_atoms": int(total_atoms),
            "rdkit3d_n_fragments": int(n_frags),
        }

        # åŠ æƒå¹³å‡
        for k, v in d3_weighted.items():
            out[f"rdkit3d_{k}"] = float(v) / float(total_atoms)

        # Coulomb Matrix å¤„ç†
        if eig_all:
            eig_concat = np.concatenate(eig_all).astype(float)
            if eig_concat.size > 0:
                eig_sorted = np.sort(eig_concat)[::-1]  # desc
                for i in range(int(coulomb_top_k)):
                    out[f"coulomb_eig_{i + 1}"] = float(eig_sorted[i]) if i < len(eig_sorted) else 0.0
                out["coulomb_eig_mean"] = float(np.mean(eig_concat))
                out["coulomb_eig_std"] = float(np.std(eig_concat))
                out["coulomb_eig_max"] = float(np.max(eig_concat))
                out["coulomb_eig_min"] = float(np.min(eig_concat))
            else:
                _fill_nan(out, coulomb_top_k)
        else:
            _fill_nan(out, coulomb_top_k)

        return out

    except Exception as e:
        # print(f"âŒ 3D Worker å¼‚å¸¸: {e}") # è°ƒè¯•ç”¨
        return None


def _fill_nan(out, k):
    for i in range(int(k)):
        out[f"coulomb_eig_{i + 1}"] = np.nan
    out["coulomb_eig_mean"] = np.nan
    out["coulomb_eig_std"] = np.nan
    out["coulomb_eig_max"] = np.nan
    out["coulomb_eig_min"] = np.nan


class RDKit3DDescriptorExtractor:
    """RDKit 3D æ„è±¡æè¿°ç¬¦æå–å™¨ï¼ˆå¯é€‰æ›´å‰æ²¿çš„å‡ ä½•è¡¨å¾ï¼‰"""

    def __init__(self, coulomb_top_k: int = 10):
        self.coulomb_top_k = int(coulomb_top_k)
        self.feature_names = []  # è¿è¡Œåæ‰çŸ¥é“å®Œæ•´åˆ—å

    def smiles_to_3d_descriptors(self, smiles_list, n_jobs: int | None = None):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… RDKit æ‰èƒ½ä½¿ç”¨ 3D æè¿°ç¬¦ã€‚")

        if n_jobs is None:
            n_jobs = 1 if os.name == 'nt' else max(1, (mp.cpu_count() or 1) - 1)

        feats = []
        valid_indices = []

        print(f"\nğŸ§Š 3D æ„è±¡æè¿°ç¬¦æå– (n_jobs={n_jobs}, coulomb_top_k={self.coulomb_top_k})")

        worker = partial(_rdkit3d_feature_worker, coulomb_top_k=self.coulomb_top_k)

        if n_jobs == 1:
            for idx, s in enumerate(tqdm(smiles_list, desc="3D Descriptors")):
                out = worker(s)
                if out is not None:
                    feats.append(out)
                    valid_indices.append(idx)
        else:
            try:
                with ProcessPoolExecutor(max_workers=n_jobs) as executor:
                    for idx, out in enumerate(tqdm(executor.map(worker, smiles_list),
                                                   total=len(smiles_list),
                                                   desc=f"3D Descriptors ({n_jobs} workers)")):
                        if out is not None:
                            feats.append(out)
                            valid_indices.append(idx)
            except Exception as e:
                print(f"âš ï¸ 3D å¹¶è¡Œæå–å¤±è´¥ï¼Œå›é€€å•è¿›ç¨‹ï¼š{e}")
                for idx, s in enumerate(tqdm(smiles_list, desc="3D Descriptors (fallback)")):
                    out = worker(s)
                    if out is not None:
                        feats.append(out)
                        valid_indices.append(idx)

        if not feats:
            return pd.DataFrame(), []

        df = pd.DataFrame(feats)
        df = df.apply(pd.to_numeric, errors='coerce')
        self.feature_names = df.columns.tolist()

        return df, valid_indices



# =============================================================================
# é¢„è®­ç»ƒ SMILES Transformer Embeddingï¼ˆå¯é€‰ï¼šéœ€è¦ transformersï¼‰
# =============================================================================
class SmilesTransformerEmbeddingExtractor:
    """
    é¢„è®­ç»ƒ SMILES Transformer è¡¨å¾ï¼ˆä¾‹å¦‚ ChemBERTa ç­‰ï¼‰

    - é€‚åˆåšâ€œå‰æ²¿ç‰¹å¾å·¥ç¨‹â€ï¼šä¸ä¾èµ–æ‰‹å·¥æè¿°ç¬¦ï¼Œèƒ½å­¦ä¹ åˆ°æ›´æŠ½è±¡çš„åˆ†å­è¯­ä¹‰è¡¨ç¤º
    - æ³¨æ„ï¼šé¦–æ¬¡è¿è¡Œä¼šä» HuggingFace ä¸‹è½½æ¨¡å‹æƒé‡ï¼ˆéœ€è¦è”ç½‘ï¼‰
    """

    _CACHE = {}  # (model_name, device_str) -> (tokenizer, model, hidden_size)

    def __init__(
        self,
        model_name: str = "seyonec/ChemBERTa-zinc-base-v1",
        pooling: str = "cls",
        max_length: int = 128,
        device=None
    ):
        self.model_name = model_name
        self.pooling = (pooling or "cls").lower()
        self.max_length = int(max_length)

        try:
            import torch
            from transformers import AutoTokenizer, AutoModel
            self.torch = torch
            self.AutoTokenizer = AutoTokenizer
            self.AutoModel = AutoModel
            self.AVAILABLE = True
        except Exception:
            self.AVAILABLE = False
            self.feature_names = []
            return

        if device is None:
            self.device = self.torch.device('cuda' if self.torch.cuda.is_available() else 'cpu')
        else:
            self.device = device

        cache_key = (self.model_name, str(self.device))
        if cache_key in self._CACHE:
            self.tokenizer, self.model, self.hidden_size = self._CACHE[cache_key]
        else:
            self.tokenizer = self.AutoTokenizer.from_pretrained(self.model_name)
            # æŸäº› tokenizer å¯èƒ½æ²¡æœ‰ pad_tokenï¼Œåšä¸ªå…œåº•
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token or self.tokenizer.cls_token

            self.model = self.AutoModel.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()

            # hidden size
            self.hidden_size = int(getattr(self.model.config, "hidden_size", 0) or 0)

            self._CACHE[cache_key] = (self.tokenizer, self.model, self.hidden_size)

        # feature names è¿è¡Œåæ ¹æ® hidden_size ç”Ÿæˆ
        self.feature_names = [f"lm_emb_{i}" for i in range(self.hidden_size)] if self.hidden_size else []

    def _pool(self, last_hidden_state, attention_mask):
        # last_hidden_state: (B, L, H)
        if self.pooling == "mean":
            # mean pooling with mask
            mask = attention_mask.unsqueeze(-1).float()  # (B, L, 1)
            summed = (last_hidden_state * mask).sum(dim=1)
            denom = mask.sum(dim=1).clamp(min=1.0)
            return summed / denom
        # default: cls pooling (take first token)
        return last_hidden_state[:, 0, :]

    def smiles_to_embeddings(self, smiles_list, batch_size: int = 32):
        if not self.AVAILABLE:
            raise ImportError("éœ€è¦ transformersï¼špip install transformers")

        # è¿‡æ»¤ç©ºå€¼
        valid_indices = []
        texts = []
        for i, s in enumerate(smiles_list):
            if s is None or (isinstance(s, float) and np.isnan(s)):
                continue
            ss = str(s).strip()
            if not ss:
                continue
            valid_indices.append(i)
            texts.append(ss)

        if not texts:
            return pd.DataFrame(), []

        embs = []

        for start in tqdm(range(0, len(texts), batch_size), desc="Transformer Embedding"):
            batch = texts[start:start + batch_size]
            inputs = self.tokenizer(
                batch,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=self.max_length
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            with self.torch.no_grad():
                outputs = self.model(**inputs)
                last_hidden = outputs.last_hidden_state
                pooled = self._pool(last_hidden, inputs.get("attention_mask"))
                embs.append(pooled.detach().cpu().numpy().astype(np.float32))

        emb_mat = np.vstack(embs)
        # ç”Ÿæˆåˆ—å
        if not self.feature_names or len(self.feature_names) != emb_mat.shape[1]:
            self.feature_names = [f"lm_emb_{i}" for i in range(emb_mat.shape[1])]

        df = pd.DataFrame(emb_mat, columns=self.feature_names)
        return df, valid_indices

class RDKitFeatureExtractor:
    """RDKitåŸºç¡€æå–å™¨"""

    def __init__(self):
        self.feature_names = None

    def smiles_to_rdkit_features(self, smiles_list):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")

        features_list, valid_indices = [], []
        descriptor_funcs = dict(Descriptors.descList)

        for idx, smiles in enumerate(tqdm(smiles_list, desc="RDKitæå–")):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                features = {}
                for name, func in descriptor_funcs.items():
                    try:
                        val = func(mol)
                        features[name] = val if np.isfinite(val) else np.nan
                    except:
                        features[name] = np.nan
                features_list.append(features)
                valid_indices.append(idx)
            except:
                continue

        if not features_list:
            return pd.DataFrame(), []

        df = pd.DataFrame(features_list)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        self.feature_names = df.columns.tolist()
        return df, valid_indices


class OptimizedRDKitFeatureExtractor:
    """å¹¶è¡Œç‰ˆRDKitæå–å™¨"""

    def __init__(self, n_jobs=-1, batch_size=1000):
        self.n_jobs = mp.cpu_count() if n_jobs == -1 else n_jobs
        self.batch_size = batch_size
        self.feature_names = None

    @staticmethod
    def _process_batch(args):
        start_idx, smiles_list = args
        if not RDKIT_AVAILABLE:
            return [], []

        descriptor_funcs = dict(Descriptors.descList)
        features_list, valid_indices = [], []

        for i, smiles in enumerate(smiles_list):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is None:
                    continue
                features = {}
                for name, func in descriptor_funcs.items():
                    try:
                        val = func(mol)
                        features[name] = val if np.isfinite(val) else np.nan
                    except:
                        features[name] = np.nan
                features_list.append(features)
                valid_indices.append(start_idx + i)
            except:
                continue
        return features_list, valid_indices

    def smiles_to_rdkit_features(self, smiles_list):
        batches = [(i, smiles_list[i:i + self.batch_size])
                   for i in range(0, len(smiles_list), self.batch_size)]

        all_features, all_indices = [], []
        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:
            for features, indices in executor.map(self._process_batch, batches):
                all_features.extend(features)
                all_indices.extend(indices)

        if not all_features:
            return pd.DataFrame(), []

        df = pd.DataFrame(all_features)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        self.feature_names = df.columns.tolist()
        return df, all_indices


class MemoryEfficientRDKitExtractor:
    """å†…å­˜ä¼˜åŒ–ç‰ˆæå–å™¨"""

    def __init__(self, batch_size=100):
        self.batch_size = batch_size
        self.feature_names = None

    def smiles_to_rdkit_features(self, smiles_list):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")

        all_features, all_indices = [], []
        descriptor_funcs = dict(Descriptors.descList)

        for batch_start in tqdm(range(0, len(smiles_list), self.batch_size), desc="å†…å­˜ä¼˜åŒ–æå–"):
            batch = smiles_list[batch_start:batch_start + self.batch_size]
            for i, smiles in enumerate(batch):
                try:
                    mol = Chem.MolFromSmiles(smiles)
                    if mol is None:
                        continue
                    features = {}
                    for name, func in descriptor_funcs.items():
                        try:
                            val = func(mol)
                            features[name] = val if np.isfinite(val) else np.nan
                        except:
                            features[name] = np.nan
                    all_features.append(features)
                    all_indices.append(batch_start + i)
                except:
                    continue

        if not all_features:
            return pd.DataFrame(), []

        df = pd.DataFrame(all_features)
        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0]
        df = df.fillna(df.median())

        self.feature_names = df.columns.tolist()
        return df, all_indices


class AdvancedMolecularFeatureExtractor:
    """é«˜çº§åˆ†å­ç‰¹å¾æå–å™¨"""

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…rdkit")
        self.descriptor_names = []

    def _smiles_to_mol(self, smiles):
        try:
            if pd.isna(smiles):
                return None
            return Chem.MolFromSmiles(str(smiles))
        except:
            return None

    def _process_result(self, features, indices, is_df=False):
        if not features:
            return pd.DataFrame(), []

        if is_df:
            df = features
        else:
            df = pd.DataFrame(features)

        df = df.select_dtypes(include=[np.number])
        df = df.dropna(axis=1, how='all')
        df = df.loc[:, df.var() > 0] if len(df) > 0 else df
        df = df.fillna(df.median())
        if df.columns.duplicated().any():
            df = df.loc[:, ~df.columns.duplicated(keep='first')]

        return df, indices

    def smiles_to_rdkit_features(self, smiles_list):
        all_features, valid_indices = [], []
        descriptor_funcs = {name: func for name, func in Descriptors.descList}

        print(f"\nğŸ§¬ RDKitç‰¹å¾æå–")
        for idx, smiles in enumerate(tqdm(smiles_list, desc="æå–ä¸­")):
            mol = self._smiles_to_mol(smiles)
            if mol is None:
                continue
            features = {}
            for name, func in descriptor_funcs.items():
                try:
                    val = func(mol)
                    features[name] = val if np.isfinite(val) else np.nan
                except:
                    features[name] = np.nan
            all_features.append(features)
            valid_indices.append(idx)

        return self._process_result(all_features, valid_indices)

    def smiles_to_mordred(self, smiles_list, batch_size=1000):
        """
        Mordredç‰¹å¾æå– - ä¼˜åŒ–ç‰ˆ
        å¢åŠ äº†åˆ†æ‰¹å¤„ç†å’ŒWindowsç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ä¿æŠ¤
        """
        if not MORDRED_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£…mordred")

        print(f"\nğŸ”¬ Mordredç‰¹å¾æå–")

        # 1. é¢„å¤„ç†åˆ†å­
        mols = []
        valid_indices = []
        for idx, smiles in enumerate(tqdm(smiles_list, desc="é¢„å¤„ç†åˆ†å­ç»“æ„")):
            mol = self._smiles_to_mol(smiles)
            if mol:
                mols.append(mol)
                valid_indices.append(idx)

        if not mols:
            return pd.DataFrame(), []

        # 2. åˆå§‹åŒ–è®¡ç®—å™¨
        calc = Calculator(descriptors, ignore_3D=True)

        # 3. æ™ºèƒ½é€‰æ‹©è¿›ç¨‹æ•°
        # Windows ä¸‹å¤šè¿›ç¨‹æå…¶ä¸ç¨³å®šï¼Œå¼ºåˆ¶ä½¿ç”¨å•è¿›ç¨‹
        is_windows = os.name == 'nt'
        if is_windows:
            print("âš ï¸ æ£€æµ‹åˆ° Windows ç³»ç»Ÿï¼Œå¼ºåˆ¶ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼ä»¥ç¡®ä¿ç¨³å®šï¼ˆå¯èƒ½ä¼šæ…¢ä¸€äº›ï¼‰ã€‚")
            n_proc = 1
        else:
            n_proc = mp.cpu_count()

        # 4. åˆ†æ‰¹è®¡ç®— (Batch Processing)
        # å³ä½¿æ˜¯å•è¿›ç¨‹ï¼Œåˆ†æ‰¹ä¹Ÿèƒ½è®©è¿›åº¦æ¡åŠ¨èµ·æ¥ï¼Œå¹¶é˜²æ­¢å†…å­˜æº¢å‡º
        all_dfs = []
        total_mols = len(mols)

        # ä¸»è¿›åº¦æ¡
        pbar = tqdm(total=total_mols, desc="è®¡ç®—Mordredæè¿°ç¬¦")

        for i in range(0, total_mols, batch_size):
            batch_mols = mols[i: i + batch_size]

            try:
                # å°è¯•è®¡ç®—å½“å‰æ‰¹æ¬¡
                # quiet=True æ˜¯ä¸ºäº†é˜²æ­¢ mordred å†…éƒ¨å†æ‰“å°ä¸€ä¸ªè¿›åº¦æ¡å¹²æ‰°æˆ‘ä»¬
                # ä¿®æ”¹å¼€å§‹ï¼šä¿®å¤ n_proc å‚æ•°å¯¼è‡´çš„ TypeError
                if n_proc > 1:
                    try:
                        # å°è¯•å¹¶è¡Œ
                        df_batch = calc.pandas(batch_mols, n_proc=n_proc, quiet=True)
                    except TypeError:
                        # å¦‚æœä¸æ”¯æŒ n_proc å‚æ•°ï¼Œå›é€€åˆ°é»˜è®¤è°ƒç”¨
                        if i == 0:
                            print(f"\nâš ï¸ Mordredç‰ˆæœ¬ä¸æ”¯æŒå¹¶è¡Œå‚æ•°ï¼Œåˆ‡æ¢è‡³é»˜è®¤æ¨¡å¼...")
                        n_proc = 1
                        df_batch = calc.pandas(batch_mols, quiet=True)
                    except Exception as e:
                        # å…¶ä»–å¹¶è¡Œé”™è¯¯ï¼Œå›é€€åˆ°å•è¿›ç¨‹
                        if i == 0:
                            print(f"\nâš ï¸ å¹¶è¡Œè®¡ç®—å‡ºé”™ ({str(e)})ï¼Œè‡ªåŠ¨åˆ‡æ¢å›å•è¿›ç¨‹æ¨¡å¼...")
                        n_proc = 1
                        # å•è¿›ç¨‹æ¨¡å¼ä¸‹ä¸ä¼  n_proc å‚æ•°
                        df_batch = calc.pandas(batch_mols, quiet=True)
                else:
                    # å•è¿›ç¨‹æ¨¡å¼ï¼šç›´æ¥ä¸ä¼  n_proc å‚æ•°ï¼Œå…¼å®¹æ‰€æœ‰ç‰ˆæœ¬
                    df_batch = calc.pandas(batch_mols, quiet=True)
                # ä¿®æ”¹ç»“æŸ
                if type(df_batch).__name__ == 'MordredDataFrame':
                    df_batch = pd.DataFrame(df_batch)

                all_dfs.append(df_batch)

            except Exception as e:
                print(f"\nâŒ æ‰¹æ¬¡ {i // batch_size + 1} è®¡ç®—å¤±è´¥: {str(e)}")
                # å¦‚æœæŸæ‰¹æ¬¡å½»åº•å¤±è´¥ï¼Œæ’å…¥å…¨NaNè¡Œä»¥ä¿æŒç´¢å¼•å¯¹é½
                empty_df = pd.DataFrame(index=range(len(batch_mols)), columns=[str(d) for d in calc.descriptors])
                all_dfs.append(empty_df)

            finally:
                pbar.update(len(batch_mols))

        pbar.close()

        if not all_dfs:
            return pd.DataFrame(), []

        # 5. åˆå¹¶ä¸åå¤„ç†
        try:
            final_df = pd.concat(all_dfs, ignore_index=True)
            # å¼ºåˆ¶è½¬ä¸ºæ•°å€¼ï¼Œéæ•°å€¼è½¬ä¸º NaN
            final_df = final_df.apply(pd.to_numeric, errors='coerce')
            return self._process_result(final_df, valid_indices, is_df=True)
        except Exception as e:
            print(f"âŒ ç»“æœåˆå¹¶å¤±è´¥: {str(e)}")
            return pd.DataFrame(), []

    def smiles_to_graph_features(self, smiles_list):
        all_features, valid_indices = [], []

        print(f"\nğŸ•¸ï¸ å›¾ç‰¹å¾æå–")
        for idx, smiles in enumerate(tqdm(smiles_list, desc="æ„å»ºå›¾")):
            mol = self._smiles_to_mol(smiles)
            if mol is None:
                continue

            try:
                num_atoms = mol.GetNumAtoms()
                num_bonds = mol.GetNumBonds()
                features = {
                    'graph_num_nodes': num_atoms,
                    'graph_num_edges': num_bonds,
                    'graph_avg_degree': 2 * num_bonds / num_atoms if num_atoms > 0 else 0,
                    'graph_density': num_bonds / (num_atoms * (num_atoms - 1) / 2) if num_atoms > 1 else 0,
                    'num_rings': Chem.GetSSSR(mol).__len__(),
                    'num_aromatic_atoms': sum(1 for atom in mol.GetAtoms() if atom.GetIsAromatic()),
                    'num_rotatable_bonds': Descriptors.NumRotatableBonds(mol),
                    'mol_weight': Descriptors.MolWt(mol),
                    'logp': Descriptors.MolLogP(mol),
                    'tpsa': Descriptors.TPSA(mol),
                }
                all_features.append(features)
                valid_indices.append(idx)
            except:
                continue

        return self._process_result(all_features, valid_indices)


class MLForceFieldExtractor:
    """
    æœºå™¨å­¦ä¹ åŠ›åœºç‰¹å¾æå–å™¨ï¼ˆTorchANI / ANI2xï¼‰

    âœ… ä¿®å¤ç‚¹ï¼ˆå¯¹åº”â€œåŠ›åœºç‰¹å¾æ€»æ˜¯ 0â€çš„å¸¸è§åŸå› ï¼‰ï¼š
    1) æ—§ç‰ˆåœ¨ batch padding åå°è¯•ç”¨â€œæ‹†åŒ…â€è·å– atomic_energiesï¼Œæ˜“ä¸ TorchANI è¾“å‡ºç»“æ„ä¸åŒ¹é…ï¼Œ
       å¯¼è‡´èƒ½é‡è¢«é”™è¯¯è®¡ç®—ä¸ºæ¥è¿‘ 0ï¼ˆç”šè‡³å˜æˆå…¨ 0ï¼‰ã€‚
    2) æ—§ç‰ˆå°† padding åŸå­å½“ä½œçœŸå®åŸå­ï¼ˆæˆ–é”™è¯¯ maskï¼‰ï¼Œä¼šæ±¡æŸ“èƒ½é‡/åŠ›ã€‚
    3) å¤šç»„åˆ†/å¤šç‰‡æ®µ SMILESï¼ˆA.B æˆ– A;Bï¼‰è‹¥ç›´æ¥ä½œä¸ºä¸€ä¸ªä½“ç³»è®¡ç®—ï¼Œç‰‡æ®µé—´éç‰©ç†è¿‘è·ç¦»ä¼šå¯¼è‡´å¼‚å¸¸ã€‚

    æœ¬å®ç°ç­–ç•¥ï¼š
    - å…ˆå¤šè¿›ç¨‹ç”Ÿæˆ 3D æ„è±¡ï¼ˆæ¯ä¸ªç‰‡æ®µç‹¬ç«‹ï¼‰
    - æŒ‰ â€œåŸå­æ•°ç›¸åŒâ€ åˆ†ç»„åš batch æ¨ç†ï¼ˆæ— éœ€ paddingï¼‰
    - å¯¹æ¯ä¸ªæ ·æœ¬æŠŠå„ç‰‡æ®µçš„ç»“æœèšåˆä¸ºä¸€ä¸ªç‰¹å¾å‘é‡
    """

    SUPPORTED_SPECIES = {1, 6, 7, 8, 9, 16, 17}  # H,C,N,O,F,S,Cl (ANI2x)

    _HARTREE_TO_KJ_MOL = 2625.499638
    _HARTREE_TO_KCAL_MOL = 627.509474

    def __init__(self, device=None, energy_unit: str = "hartree"):
        """
        Args:
            device: torch.device æˆ– Noneï¼ˆè‡ªåŠ¨é€‰æ‹© cuda/cpuï¼‰
            energy_unit: 'hartree' | 'kJ/mol' | 'kcal/mol'
        """
        try:
            import torchani
            import torch
            self.torch = torch
            self.torchani = torchani
            self.AVAILABLE = True
        except ImportError:
            self.AVAILABLE = False
            self.feature_names = []
            return

        if device is None:
            self.device = self.torch.device('cuda' if self.torch.cuda.is_available() else 'cpu')
        else:
            self.device = device

        self.energy_unit = (energy_unit or "hartree").lower()

        # âœ… CPU æ€§èƒ½ä¼˜åŒ–ï¼šè®© Torch åœ¨ CPU ä¸Šå……åˆ†ä½¿ç”¨çº¿ç¨‹
        # æ³¨æ„ï¼šåœ¨å¤šè¿›ç¨‹ 3D ç”Ÿæˆæ—¶ï¼ŒANI æ¨ç†é€šå¸¸åœ¨ä¸»è¿›ç¨‹æ‰§è¡Œï¼Œå› æ­¤è¿™é‡Œå¤šçº¿ç¨‹èƒ½æ˜æ˜¾åŠ é€Ÿ
        try:
            if self.device.type == "cpu":
                import os as _os
                n_cpu = _os.cpu_count() or 1
                # è®¡ç®—çº¿ç¨‹ï¼šå°½é‡ç”¨æ»¡ CPUï¼›Interop çº¿ç¨‹ä¿æŒè¾ƒå°ä»¥å‡å°‘è°ƒåº¦å¼€é”€
                self.torch.set_num_threads(n_cpu)
                try:
                    self.torch.set_num_interop_threads(min(4, n_cpu))
                except Exception:
                    pass
        except Exception:
            pass

        try:
            self.model = self.torchani.models.ANI2x().to(self.device)
            self.model.eval()
        except Exception as e:
            print(f"ANI Model load error: {e}")
            self.AVAILABLE = False
            self.feature_names = []
            return

        # ä¿ç•™æ—§åˆ—åï¼Œé¿å…ä¸‹æ¸¸é€»è¾‘/å†å²æ¨¡å‹ä¸å…¼å®¹
        self.feature_names = [
            'ani_energy',
            'ani_energy_per_atom',
            'ani_max_force',
            'ani_mean_force',
            'ani_force_std',
            # æ–°å¢è¯Šæ–­/ç»“æ„ä¿¡æ¯
            'ani_n_atoms',
            'ani_n_fragments',
            'ani_success'
        ]

    def _convert_energy(self, e_hartree: float) -> float:
        if e_hartree is None or (isinstance(e_hartree, float) and (np.isnan(e_hartree) or np.isinf(e_hartree))):
            return np.nan
        if self.energy_unit in ["hartree", "ha"]:
            return float(e_hartree)
        if self.energy_unit in ["kj/mol", "kjmol", "kj"]:
            return float(e_hartree) * self._HARTREE_TO_KJ_MOL
        if self.energy_unit in ["kcal/mol", "kcalmol", "kcal"]:
            return float(e_hartree) * self._HARTREE_TO_KCAL_MOL
        # æœªçŸ¥å•ä½ï¼šä¸è½¬æ¢
        return float(e_hartree)

    def _infer_batch(self, species_np: np.ndarray, coords_np: np.ndarray):
        """
        å¯¹åŒåŸå­æ•°çš„ä¸€ç»„åˆ†å­åš batch æ¨ç†ï¼ˆæ—  paddingï¼‰
        species_np: (B, N) int64 åŸå­åºæ•°
        coords_np: (B, N, 3) float32 3D åæ ‡
        è¿”å›:
            energies: (B,) float
            forces: (B, N, 3) float
        """
        species = self.torch.tensor(species_np, dtype=self.torch.long, device=self.device)
        coords = self.torch.tensor(coords_np, dtype=self.torch.float32, device=self.device)
        coords.requires_grad_(True)

        energy = self.model((species, coords)).energies  # (B,)
        forces = -self.torch.autograd.grad(
            energy.sum(), coords, create_graph=False, retain_graph=False
        )[0]  # (B, N, 3)

        return (
            energy.detach().cpu().numpy().astype(np.float64),
            forces.detach().cpu().numpy().astype(np.float64)
        )

    def smiles_to_ani_features(self, smiles_list, batch_size: int = 64, n_jobs: int | None = None):
        if not self.AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£… torchani: pip install torchani")

        # -------- 1) å¤šè¿›ç¨‹ç”Ÿæˆ 3D æ„è±¡ï¼ˆæ¯ä¸ªæ ·æœ¬å¯èƒ½å«å¤šä¸ªç‰‡æ®µï¼‰--------
        print(f"\nâš›ï¸ æ­£åœ¨ç”Ÿæˆ 3D æ„è±¡ï¼ˆå¤šç»„åˆ†å°†æŒ‰ç‰‡æ®µåˆ†åˆ«ç”Ÿæˆï¼‰...")

        # Windows ä¸‹å¤šè¿›ç¨‹å¯èƒ½ä¸ç¨³å®šï¼Œé»˜è®¤é™ä¸ºå•è¿›ç¨‹
        if n_jobs is None:
            n_jobs = 1 if os.name == 'nt' else max(1, (mp.cpu_count() or 1) - 1)

        valid_indices = []
        sample_frags = []  # list[list[(atoms, coords)]]

        try:
            if n_jobs == 1:
                # å•è¿›ç¨‹ï¼ˆæ›´ç¨³ï¼‰
                for i, s in enumerate(tqdm(smiles_list, desc="3D Generation")):
                    res = _generate_3d_data_worker(s)
                    if res is not None:
                        valid_indices.append(i)
                        sample_frags.append(res)
            else:
                with ProcessPoolExecutor(max_workers=n_jobs) as executor:
                    for i, res in enumerate(tqdm(executor.map(_generate_3d_data_worker, smiles_list),
                                                 total=len(smiles_list),
                                                 desc=f"3D Generation ({n_jobs} workers)")):
                        if res is not None:
                            valid_indices.append(i)
                            sample_frags.append(res)
        except Exception as e:
            print(f"âš ï¸ 3D å¹¶è¡Œç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°å•è¿›ç¨‹ï¼š{e}")
            valid_indices = []
            sample_frags = []
            for i, s in enumerate(tqdm(smiles_list, desc="3D Generation (fallback)")):
                res = _generate_3d_data_worker(s)
                if res is not None:
                    valid_indices.append(i)
                    sample_frags.append(res)

        if not sample_frags:
            return pd.DataFrame(), []

        # -------- 2) å±•å¹³ç‰‡æ®µï¼ŒæŒ‰åŸå­æ•°åˆ†ç»„ batch æ¨ç†ï¼ˆæ—  paddingï¼‰--------
        from collections import defaultdict

        frag_records = []  # æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªç‰‡æ®µ
        for orig_i, frags in zip(valid_indices, sample_frags):
            for atoms, coords in frags:
                frag_records.append({
                    'orig_index': orig_i,
                    'n_atoms': int(len(atoms)),
                    'atoms': atoms,
                    'coords': coords,
                    'energy': np.nan,
                    'forces': None,
                    'failed': False
                })

        groups = defaultdict(list)
        for r in frag_records:
            groups[r['n_atoms']].append(r)

        print(f"âš›ï¸ å¼€å§‹ ANI æ¨ç†ï¼ˆæŒ‰åŸå­æ•°åˆ†ç»„æ‰¹å¤„ç†ï¼ŒBatch Size={batch_size}, Device={self.device}ï¼‰...")

        for n_atoms, recs in groups.items():
            for start in tqdm(range(0, len(recs), batch_size), desc=f"Inference (N={n_atoms})"):
                batch = recs[start:start + batch_size]
                try:
                    species_np = np.asarray([b['atoms'] for b in batch], dtype=np.int64)
                    coords_np = np.stack([b['coords'] for b in batch]).astype(np.float32)

                    energies, forces = self._infer_batch(species_np, coords_np)
                    for k, b in enumerate(batch):
                        b['energy'] = float(energies[k])
                        b['forces'] = forces[k]
                except Exception as e:
                    # å…œåº•ï¼šé€ä¸ªæ¨ç†ï¼Œå°½é‡ä¸è®©æ•´ä¸ªæ‰¹æ¬¡å¤±è´¥
                    for b in batch:
                        try:
                            species_np = np.asarray([b['atoms']], dtype=np.int64)
                            coords_np = np.asarray([b['coords']], dtype=np.float32)
                            energies, forces = self._infer_batch(species_np, coords_np)
                            b['energy'] = float(energies[0])
                            b['forces'] = forces[0]
                        except Exception:
                            b['failed'] = True
                            b['energy'] = np.nan
                            b['forces'] = None

        # -------- 3) æŒ‰æ ·æœ¬èšåˆç‰‡æ®µç»“æœï¼Œç”Ÿæˆç‰¹å¾ --------
        sample_acc = {}
        for idx in valid_indices:
            sample_acc[idx] = {
                'energies': [],
                'force_norms': [],
                'n_atoms': 0,
                'n_frags': 0,
                'failed': False
            }

        for r in frag_records:
            acc = sample_acc.get(r['orig_index'])
            if acc is None:
                continue

            if r.get('failed') or r.get('forces') is None or (not np.isfinite(r.get('energy', np.nan))):
                acc['failed'] = True
                continue

            acc['energies'].append(float(r['energy']))
            norms = np.linalg.norm(np.asarray(r['forces'], dtype=np.float64), axis=1)
            acc['force_norms'].append(norms)
            acc['n_atoms'] += int(r['n_atoms'])
            acc['n_frags'] += 1

        features_list = []
        final_indices = []

        for idx in valid_indices:
            acc = sample_acc[idx]
            if acc['failed'] or acc['n_atoms'] <= 0 or len(acc['energies']) == 0:
                continue

            e_total = float(np.sum(acc['energies']))
            e_total_conv = self._convert_energy(e_total)
            e_per_atom = e_total_conv / acc['n_atoms'] if acc['n_atoms'] > 0 else np.nan

            if acc['force_norms']:
                fn = np.concatenate(acc['force_norms'])
                f_max = float(np.max(fn)) if fn.size else np.nan
                f_mean = float(np.mean(fn)) if fn.size else np.nan
                f_std = float(np.std(fn)) if fn.size else np.nan
            else:
                f_max = f_mean = f_std = np.nan

            feats = {
                'ani_energy': e_total_conv,
                'ani_energy_per_atom': e_per_atom,
                'ani_max_force': f_max,
                'ani_mean_force': f_mean,
                'ani_force_std': f_std,
                'ani_n_atoms': int(acc['n_atoms']),
                'ani_n_fragments': int(acc['n_frags']),
                'ani_success': 1
            }
            features_list.append(feats)
            final_indices.append(idx)

        if not features_list:
            return pd.DataFrame(), []

        df = pd.DataFrame(features_list)
        return df, final_indices

class EpoxyDomainFeatureExtractor:
    """ç¯æ°§æ ‘è„‚é¢†åŸŸçŸ¥è¯†ç‰¹å¾æå–å™¨ (å¢å¼ºç‰ˆï¼šåŠ å…¥ç”µå­æ•ˆåº”æ¨¡æ‹Ÿ)"""

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… rdkit")

    def _get_epoxide_count(self, mol):
        patt = Chem.MolFromSmarts("[C]1[O][C]1")
        matches = mol.GetSubstructMatches(patt)
        return len(matches)

    def _get_active_hydrogen_count(self, mol):
        count = 0
        for atom in mol.GetAtoms():
            # è®¡ç®—ä¸æ°®åŸå­ç›¸è¿çš„æ°¢åŸå­æ•° (èƒºç±»å›ºåŒ–å‰‚)
            if atom.GetAtomicNum() == 7:
                count += atom.GetTotalNumHs()
        return count

    def _calc_electronic_props(self, mol):
        """è®¡ç®—ç”µå­æ€§è´¨ (ä½œä¸ºDFTçš„ä½æˆæœ¬æ›¿ä»£)"""
        try:
            # è®¡ç®— Gasteiger éƒ¨åˆ†ç”µè·
            AllChem.ComputeGasteigerCharges(mol)
            charges = []
            for atom in mol.GetAtoms():
                # è·å–è®¡ç®—å‡ºçš„ç”µè·
                c = atom.GetProp('_GasteigerCharge')
                # æœ‰äº›åŸå­å¯èƒ½æ— æ³•è®¡ç®—ï¼Œè¿”å›infæˆ–nan
                if c and not c.lower().startswith('nan') and not c.lower().startswith('inf'):
                    charges.append(float(c))

            if not charges:
                return 0.0, 0.0, 0.0

            max_pos_charge = max(charges)  # äº²ç”µæ€§æŒ‡æ ‡
            max_neg_charge = min(charges)  # äº²æ ¸æ€§æŒ‡æ ‡

            # æ‹“æ‰‘ææ€§è¡¨é¢ç§¯ (TPSA) - è¡¨å¾åˆ†å­ææ€§
            tpsa = Descriptors.TPSA(mol)

            return max_pos_charge, max_neg_charge, tpsa
        except Exception:
            return 0.0, 0.0, 0.0

    def extract_features(self, resin_smiles_list, hardener_smiles_list, stoichiometry_list=None, stoich_mode: str = 'Resin/Hardener (æ€»è´¨é‡æ¯”, R/H)'):
        features_list = []
        valid_indices = []

        if len(resin_smiles_list) != len(hardener_smiles_list):
            return pd.DataFrame(), []

        # éå†æ¯å¯¹æ ·æœ¬
        for idx, (smi_r, smi_h) in enumerate(zip(resin_smiles_list, hardener_smiles_list)):
            try:
                mol_r = Chem.MolFromSmiles(str(smi_r))
                mol_h = Chem.MolFromSmiles(str(smi_h))

                if mol_r is None or mol_h is None:
                    continue

                # 1. åŸºç¡€åŒ–å­¦è®¡é‡ç‰¹å¾ (åŸæœ‰åŠŸèƒ½)
                mw_r = Descriptors.MolWt(mol_r)
                mw_h = Descriptors.MolWt(mol_h)
                f_epoxy = self._get_epoxide_count(mol_r)
                f_amine = self._get_active_hydrogen_count(mol_h)

                eew = mw_r / f_epoxy if f_epoxy > 0 else mw_r
                ahew = mw_h / f_amine if f_amine > 0 else mw_h

                # è®¡ç®—ç†è®ºé…æ¯” (phr)
                theo_phr = (ahew / eew) * 100 if eew > 0 else 0


                # ç”¨æˆ·æä¾›çš„é…æ¯”ï¼ˆå¯é€‰ï¼‰
                # è¯´æ˜ï¼š
                # - stoich_mode = "Resin/Hardener (æ€»è´¨é‡æ¯”, R/H)"ï¼šåˆ—å€¼ä¸º æ ‘è„‚æ€»é‡/å›ºåŒ–å‰‚æ€»é‡ (R/H)
                #   åˆ™å¯æ¢ç®—ä¸ºå®é™… PHR = 100 / (R/H)
                # - stoich_mode = "PHR (Hardener per 100 Resin)"ï¼šåˆ—å€¼å³ä¸º PHR
                actual_phr = theo_phr
                if stoichiometry_list is not None and idx < len(stoichiometry_list):
                    try:
                        v = float(stoichiometry_list[idx])
                        if v > 0:
                            if stoich_mode.startswith("Resin/Hardener"):
                                # R/H -> PHR = 100 * H/R = 100 / (R/H)
                                actual_phr = 100.0 / v
                            elif stoich_mode.startswith("PHR"):
                                actual_phr = v
                            else:
                                actual_phr = v
                    except Exception:
                        pass

                # ä¸ç†è®ºé…æ¯”çš„åç¦»ï¼ˆç”¨äºåæ˜ å›ºåŒ–æ¬ é‡/è¿‡é‡ï¼‰
                stoich_ratio = (actual_phr / theo_phr) if theo_phr > 0 else 0.0
                stoich_delta = actual_phr - theo_phr
                # 2. ç”µå­æ€§è´¨ç‰¹å¾ (æ–°å¢åŠŸèƒ½ - æ¨¡æ‹ŸDFT)
                r_pos_chg, r_neg_chg, r_tpsa = self._calc_electronic_props(mol_r)
                h_pos_chg, h_neg_chg, h_tpsa = self._calc_electronic_props(mol_h)

                features = {
                    'EEW': eew,
                    'AHEW': ahew,
                    'Resin_Functionality': f_epoxy,
                    'Hardener_Functionality': f_amine,
                    'Theoretical_PHR': theo_phr,
                    'Actual_PHR': actual_phr,
                    'Stoich_Ratio': stoich_ratio,
                    'Stoich_Delta': stoich_delta,
                    # æ–°å¢ç‰¹å¾åˆ—
                    'Resin_Max_Pos_Charge': r_pos_chg,
                    'Resin_Max_Neg_Charge': r_neg_chg,
                    'Resin_TPSA': r_tpsa,
                    'Hardener_Max_Pos_Charge': h_pos_chg,
                    'Hardener_TPSA': h_tpsa
                }

                features_list.append(features)
                valid_indices.append(idx)

            except Exception:
                continue

        if not features_list:
            return pd.DataFrame(), []

        return pd.DataFrame(features_list), valid_indices


class FingerprintExtractor:
    """åˆ†å­æŒ‡çº¹æå–å™¨ï¼šæ”¯æŒ MACCS Keys å’Œ Morgan Fingerprints (æ”¯æŒåŒç»„åˆ†æ‹¼æ¥)"""

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… rdkit")

    def _gen_fp_array(self, mol, fp_type, n_bits, radius):
        """è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆå•ä¸ªåˆ†å­çš„æŒ‡çº¹æ•°ç»„"""
        if fp_type == 'MACCS':
            return np.array(MACCSkeys.GenMACCSKeys(mol))
        elif fp_type == 'Morgan':
            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)
            return np.array(fp)
        return np.array([])

    def smiles_to_fingerprints(self, smiles_list, smiles_list_2=None, fp_type='MACCS', n_bits=2048, radius=2):
        """
        æå–åˆ†å­æŒ‡çº¹ã€‚
        Args:
            smiles_list: æ ‘è„‚/ç¬¬ä¸€ç»„åˆ† SMILES
            smiles_list_2: (å¯é€‰) å›ºåŒ–å‰‚/ç¬¬äºŒç»„åˆ† SMILESã€‚å¦‚æœæä¾›ï¼Œå°†æ‹¼æ¥ä¸¤ä¸ªæŒ‡çº¹ã€‚
        """
        all_fps = []
        valid_indices = []

        # åˆ¤æ–­æ˜¯å¦éœ€è¦åŒç»„åˆ†æ‹¼æ¥
        is_dual = smiles_list_2 is not None and len(smiles_list_2) == len(smiles_list)

        desc_str = f"æå– {fp_type} æŒ‡çº¹"
        if is_dual:
            desc_str += " (åŒç»„åˆ†æ‹¼æ¥: Resin + Hardener)"

        print(f"\nğŸ‘† {desc_str}")

        for idx, smi1 in enumerate(tqdm(smiles_list, desc="æŒ‡çº¹æå–")):
            try:
                # 1. å¤„ç†ç¬¬ä¸€ä¸ªåˆ†å­
                mol1 = Chem.MolFromSmiles(str(smi1))
                if mol1 is None:
                    continue

                feat_dict = {}

                # ç”ŸæˆæŒ‡çº¹ 1
                fp1_arr = self._gen_fp_array(mol1, fp_type, n_bits, radius)
                for i, val in enumerate(fp1_arr):
                    # ç‰¹å¾ååŠ å‰ç¼€åŒºåˆ†
                    feat_dict[f"Resin_{fp_type}_{i}"] = val

                # 2. å¤„ç†ç¬¬äºŒä¸ªåˆ†å­ (å¦‚æœæœ‰)
                if is_dual:
                    smi2 = smiles_list_2[idx]
                    mol2 = Chem.MolFromSmiles(str(smi2))
                    if mol2 is None:
                        # å¦‚æœå›ºåŒ–å‰‚SMILESæ— æ•ˆï¼Œæ‚¨å¯ä»¥é€‰æ‹©è·³è¿‡è¯¥æ ·æœ¬ï¼Œæˆ–è€…å¡«0
                        # è¿™é‡Œé€‰æ‹©è·³è¿‡ï¼Œä¿è¯æ•°æ®è´¨é‡
                        continue

                        # ç”ŸæˆæŒ‡çº¹ 2
                    fp2_arr = self._gen_fp_array(mol2, fp_type, n_bits, radius)
                    for i, val in enumerate(fp2_arr):
                        feat_dict[f"Hardener_{fp_type}_{i}"] = val

                all_fps.append(feat_dict)
                valid_indices.append(idx)

            except Exception as e:
                continue

        if not all_fps:
            return pd.DataFrame(), []

        # è½¬ä¸º DataFrame å¹¶ä¼˜åŒ–å†…å­˜
        df = pd.DataFrame(all_fps)
        df = df.astype(np.uint8)

        # ç§»é™¤å…¨ä¸º0çš„åˆ— (æ— ä¿¡æ¯é‡çš„ä½)
        df = df.loc[:, (df != 0).any(axis=0)]

        return df, valid_indices

# =============================================================================
# [æ–°å¢] MACCS é”®å®šä¹‰å­—å…¸ (ç”¨äºè§£é‡Šå™¨)
# =============================================================================
MACCS_DEFINITIONS = {
    1: "ISOTOPE", 2: "Atomic no > 103", 3: "Group IVa,Va,VIa Rows 4-6", 4: "Actinides", 
    5: "Group IIIA,IVA", 6: "Lanthanides", 7: "Group VA,VIA Rows 4-6", 8: "QAAA@1", 
    9: "Group VIII (Fe...)", 10: "Group IIA", 11: "4M Ring", 12: "Group IB,IIB", 
    13: "ON(C)C", 14: "S-S", 15: "OC(O)O", 16: "Q:Q", 17: "C#C", 18: "Group IIIA", 
    19: "7M Ring", 20: "Si", 21: "C=C(Q)Q", 22: "3M Ring", 23: "NC(O)O", 24: "N-O", 
    25: "NC(N)N", 26: "C$=C($)C($)C", 27: "I", 28: "QCH2Q", 29: "P", 30: "CQ(C)(C)A", 
    31: "QX", 32: "CSN", 33: "NS", 34: "CH2=A", 35: "Group IA", 36: "S Heterocycle", 
    37: "NC(O)N", 38: "NC(C)N", 39: "OS(O)O", 40: "S-O", 41: "C#N", 42: "F", 43: "QHAQH", 
    44: "Other", 45: "C=CN", 46: "Br", 47: "SAN", 48: "OQ(O)O", 49: "C=C", 50: "C=C(C)C", 
    51: "CSO", 52: "NN", 53: "CN(C)C", 54: "C=C(O)C", 55: "OSO", 56: "ON(O)C", 
    57: "O Heterocycle", 58: "QSQ", 59: "Snot%A%A", 60: "S=O", 61: "AS(A)A", 
    62: "A$A!A$A", 63: "N=O", 64: "A-S", 65: "C%N", 66: "CC(C)(C)C", 67: "QSQ", 
    68: "QHQH (&...)", 69: "QQH", 70: "Q-N-Q", 71: "NO", 72: "O-A", 73: "S=A", 
    74: "CH3ACH3", 75: "A!N$A", 76: "C=C(O)O", 77: "NAN", 78: "C=N", 79: "N$A$N", 
    80: "NAAAN", 81: "SA(A)A", 82: "ACH2QA", 83: "QAA@1", 84: "NH2", 85: "CN(C)Q", 
    86: "CH2QCH2", 87: "X!A$A", 88: "S", 89: "OAAAO", 90: "QHAAQH", 91: "QHAAQH", 
    92: "OC(N)C", 93: "QCH3", 94: "QN", 95: "NAAO", 96: "5M Ring", 97: "N A A O", 
    98: "QAAAA@1", 99: "C=C", 100: "ACH2N", 101: "8M Ring", 102: "QO", 103: "Cl", 
    104: "QA(Q)Q", 105: "A$A($)A", 106: "QA(Q)Q", 107: "X (Halogen)", 108: "CH3AAACH2", 
    109: "ACH2O", 110: "NCO", 111: "NAAOH", 112: "AA(A)(A)A", 113: "Onot%A%A", 
    114: "CH3CH2A", 115: "CH3ACH2", 116: "CH3AAO", 117: "NAO", 118: "ACH2CH2A > 1", 
    119: "N=A", 120: "Heterocyclic atom > 1", 121: "N Heterocycle", 122: "AN(A)A", 
    123: "OCO", 124: "QQ", 125: "Aromatic Ring > 1", 126: "A!O!A", 127: "A$A!O > 1", 
    128: "ACH2A > 1", 129: "ACH2A", 130: "QQ > 1", 131: "QH > 1", 132: "OH > 1", 
    133: "A@A!A", 134: "X (Halogen)", 135: "Nnot%A%A", 136: "O=A > 1", 137: "Heterocycle", 
    138: "QCH2Q > 1", 139: "OH", 140: "O > 3", 141: "CH3 > 2", 142: "N > 1", 
    143: "A$A!A$A", 144: "Anot%A%A", 145: "6M ring > 1", 146: "O > 2", 147: "ACH2CH2A", 
    148: "AQ(A)A", 149: "CH3 > 1", 150: "A!A$A!A", 151: "NH", 152: "OC(C)C", 
    153: "QCH2Q", 154: "C=O", 155: "A!CH2!A", 156: "NA(A)A", 157: "C-O", 158: "C-N", 
    159: "O > 1", 160: "CH3", 161: "N", 162: "Aromatic", 163: "6M Ring", 164: "O", 
    165: "Ring", 166: "Fragments"
}

def get_maccs_description(key_idx):
    """æ ¹æ®é”®ç´¢å¼•è·å– MACCS æè¿°"""
    try:
        idx = int(key_idx)
        return MACCS_DEFINITIONS.get(idx, "Unknown Fragment")
    except:
        return "Invalid Key"


class FGDFeatureExtractor:
    """
    [å¢å¼ºç‰ˆ] FGD (Functional Group Distinction) ç‰¹å¾æå–å™¨
    é’ˆå¯¹ç”¨æˆ·æ•°æ®é›†è¿›è¡Œäº†å®šåˆ¶ä¼˜åŒ–ï¼šå¢åŠ äº†ç¡«é†‡ã€é…°è‚¼ã€äºŒè‹¯ç”²é…®ç­‰è¯†åˆ«è§„åˆ™ã€‚
    """

    def __init__(self):
        if not RDKIT_AVAILABLE:
            raise ImportError("FGD æå–éœ€è¦ RDKit æ”¯æŒã€‚")

        # 1. å®šä¹‰éª¨æ¶ (Substrates) - ä¼˜å…ˆçº§ï¼šç»“æ„è¶Šç‰¹å¼‚ï¼Œè¶Šé å‰
        self.substrates = {
            # --- [æ–°å¢] é’ˆå¯¹æ‚¨æ•°æ®ä¸­çš„äºŒè‹¯ç”²é…®ç¯æ°§ ---
            "Benzophenone": "c1ccc(cc1)C(=O)c2ccc(cc2)",

            "DGEBA": "c1ccc(cc1)C(C)(C)c2ccc(cc2)",  # åŒé…šAå‹
            "DGEBF": "c1ccc(cc1)Cc2ccc(cc2)",  # åŒé…šFå‹ (ä¹ŸåŒ¹é… DDM å›ºåŒ–å‰‚éª¨æ¶)
            "Novolac": "c1ccc(O)c(c1)Cc2ccccc2",  # é…šé†›éª¨æ¶
            "TDE-85 (Ester)": "C(=O)OC",  # é…¯ç¯æ—/é€šç”¨é…¯é”®
            "Cycloaliphatic": "C1CCCCC1",  # è„‚ç¯æ— (å…­å…ƒç¯)
            "Isocyanurate": "N1C(=O)NC(=O)NC1=O",  # å¼‚æ°°å°¿é…¸é…¯ (TGICç­‰)
            "Aliphatic Chain": "[CX4,CX3]~[CX4,CX3]~[CX4,CX3]~[CX4,CX3]",  # é•¿é“¾è„‚è‚ªæ—
            "Benzene Ring": "c1ccccc1"  # ç®€å•è‹¯ç¯ (å…œåº•)
        }

        # 2. å®šä¹‰å®˜èƒ½å›¢ (Groups) - å†³å®šååº”æœºç†
        self.groups = {
            "Epoxide": "C1OC1",  # ç¯æ°§åŸº
            "Anhydride": "C(=O)OC(=O)",  # é…¸é… (å¦‚ MTHPA)

            # --- [æ–°å¢] é’ˆå¯¹æ‚¨æ•°æ®ä¸­çš„ NNC(=O) ---
            "Hydrazide": "[NX3][NX3]C(=O)",  # é…°è‚¼ (æ½œä¼æ€§å›ºåŒ–å‰‚)

            # --- [æ–°å¢] é’ˆå¯¹æ‚¨æ•°æ®ä¸­çš„ SCC... ---
            "Thiol": "[#16X2H]",  # å·¯åŸº/ç¡«é†‡ (-SH)

            "Methacrylate": "CC(=C)C(=O)O",  # ç”²åŸºä¸™çƒ¯é…¸é…¯
            "Acrylate": "C=CC(=O)O",  # ä¸™çƒ¯é…¸é…¯
            "Amine (Primary)": "[NX3;H2]",  # ä¼¯èƒº (å¦‚ DDM)
            "Amine (Secondary)": "[NX3;H1]",  # ä»²èƒº
            "Hydroxyl": "[OX2H]",  # ç¾ŸåŸº
            "Vinyl": "C=C",  # ä¹™çƒ¯åŸº (å…œåº•)
        }

        # é¢„ç¼–è¯‘ pattern
        self._sub_pats = {}
        for k, v in self.substrates.items():
            try:
                self._sub_pats[k] = Chem.MolFromSmarts(v)
            except:
                pass

        self._grp_pats = {}
        for k, v in self.groups.items():
            try:
                self._grp_pats[k] = Chem.MolFromSmarts(v)
            except:
                pass

    def _clean_smiles(self, text):
        """æ¸…æ´—æ··åˆç‰©SMILESï¼Œå¤„ç†åˆ†å·ç­‰éæ ‡å‡†åˆ†éš”ç¬¦"""
        if pd.isna(text): return None
        s = str(text).strip()
        # å°†åˆ†å·æ›¿æ¢ä¸º RDKit å¯è¯†åˆ«çš„ç‚¹å· (è¡¨ç¤ºéé”®è¿æ··åˆç‰©)
        s = s.replace(';', '.').replace('ï¼›', '.')
        return s

    def categorize_smiles(self, smiles_list):
        """
        è¾“å…¥ SMILES åˆ—è¡¨ï¼Œè¿”å› DataFrame åŒ…å« 'FGD_Substrate' å’Œ 'FGD_Group'
        """
        results = []
        valid_indices = []

        print(f"\nğŸ“‘ æ­£åœ¨æ‰§è¡Œ FGD å®˜èƒ½å›¢åˆ†ç±» (å¢å¼ºç‰ˆ)...")

        for idx, raw_smi in enumerate(tqdm(smiles_list, desc="FGD Classification")):
            try:
                smi = self._clean_smiles(raw_smi)
                if not smi:
                    continue

                mol = Chem.MolFromSmiles(smi)
                if mol is None:
                    continue

                # åŒ¹é…éª¨æ¶
                sub_type = "Other_Substrate"
                for name, pat in self._sub_pats.items():
                    if pat and mol.HasSubstructMatch(pat):
                        sub_type = name
                        break

                        # åŒ¹é…å®˜èƒ½å›¢
                func_group = "Other_Group"
                for name, pat in self._grp_pats.items():
                    if pat and mol.HasSubstructMatch(pat):
                        func_group = name
                        break

                results.append({
                    "FGD_Substrate": sub_type,
                    "FGD_Group": func_group
                })
                valid_indices.append(idx)

            except Exception:
                continue

        if not results:
            return pd.DataFrame(), []

        df = pd.DataFrame(results)
        return df, valid_indices
